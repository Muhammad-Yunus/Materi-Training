{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV Object Detection\n",
    "\n",
    "- Casecade Classifier\n",
    "- Casecade Classifier Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Casecade Classifier\n",
    "<img src=\"resource/lena_face.png\" style=\"width:250px\"></img><br>\n",
    "- Object Detection OpenCV is using **Haar feature-based cascade classifiers.**\n",
    "- Is an effective object detection method proposed by Paul Viola and Michael Jones in their paper, \"Rapid Object Detection using a Boosted Cascade of Simple Features\" in 2001.\n",
    "- **Haar features** just like normal convolutional kernel, <br><br>\n",
    "<img src=\"resource/haar_feature.png\"></img><br><br>\n",
    "- Each feature is a single value obtained by **subtracting** sum of pixels under the **white rectangle** from sum of pixels under the **black rectangle**. <br><br>\n",
    "<img src=\"resource/face_haar_feature.png\" style=\"width:600px\"></img><br><br>\n",
    "- `lena.jpg` convolving proses to detect face using haar feature, <br><br>\n",
    "<img src=\"resource/convolving_haar_feature.gif\" style=\"width:250px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Class `cv2.CascadeClassifier()` digunakan untuk membaca classifier file (**.xml**)\n",
    "- Pada class `cv2.CascadeClassifier()` terdapat method `.detectMultiscale()` untuk melakukan deteksi objek pada sebuah citra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Method `.detectMultiscale()` memiliki beberapa parameter input,\n",
    "    - `scaleFactor` : Ukuran seberapa besar input image direduksi agar mampu dibaca oleh detector algorithm. Hal inilah yang memungkinkan algorima dapat mendeteksi wajah dalam beragam skala gambar (multi scale image).\n",
    "    - `minNeighbors` : Ukuran minimum antara posisi face rectangle satu terhadap lainya. Hal ini berkaitan dengan method `.detectMultiscale()` yang akan melakukan sliding window terhadap image. Jika kita set ke 0, maka banyak false positive face rectangle terdeteksi. sehingga kita akan pilih nilai yang lebih tinggi. Namun jangan sampai memilih nilai yang terlalu besar, yang mengakibatkan true positive face rectangle menjadi tidak terdeteksi.\n",
    "    - `flags` : Parameter yang sama pada method cvHaarDetectObjects. Ini tidak digunakan pada Cascade Classifier terbaru.\n",
    "    - `minSize` : Ukuran object minimal. Ukuran yang lebih kecil tidak akan dimasukan kedalam detected object.\n",
    "    - `maxSize` : Ukuran object maksimal. Ukuran yang lebih besar tidak akan dimasukan kedalam detected object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Face Detection (`haarcascade_frontalface_default.xml`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "img = cv2.imread(\"lena.jpg\")\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "for (x,y,w,h) in faces:\n",
    "    img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "cv2.imshow('img',img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Eye Detection (`haarcascades/haarcascade_eye.xml`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_eye.xml')\n",
    "\n",
    "img = cv2.imread(\"eye.jpg\")\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "eye = eye_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "for (x,y,w,h) in eye:\n",
    "    img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "cv2.imshow('img',img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Face Detection (haarcascade_frontalface_default.xml)\n",
    "    - Eye Detection (`haarcascades/haarcascade_eye.xml`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_eye.xml')\n",
    "smile_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_smile.xml')\n",
    "\n",
    "img = cv2.imread(\"lena.jpg\")\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "for (x,y,w,h) in faces:\n",
    "    img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    \n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    \n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "    for (x,y,w,h) in eyes:\n",
    "        cv2.rectangle(roi_color,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        \n",
    "    smile = smile_cascade.detectMultiScale(roi_gray, 1.5, 7)\n",
    "    for (x,y,w,h) in smile:\n",
    "        cv2.rectangle(roi_color,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "\n",
    "cv2.imshow('img',img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- licence plate detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_cascade = cv2.CascadeClassifier('haarcascades/licence_plate.xml')\n",
    "\n",
    "img = cv2.imread(\"plat-nomor-1.jpg\")\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "plates = plate_cascade.detectMultiScale(gray, scaleFactor = 1.1, minNeighbors = 3, minSize=(90, 30))\n",
    "for (x,y,w,h) in plates:\n",
    "    img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    \n",
    "    img_roi = img[y:y+h, x:x+w]\n",
    "    cv2.imshow('plate',img_roi)\n",
    "\n",
    "cv2.imshow('img',img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cars detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_cascade = cv2.CascadeClassifier('haarcascades/cars.xml')\n",
    "\n",
    "img = cv2.imread(\"plat-nomor-14.jpg\")\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cars = cars_cascade.detectMultiScale(gray, scaleFactor = 1.1, minNeighbors = 5)\n",
    "for (x,y,w,h) in cars:\n",
    "    img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "cv2.imshow('img',img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Detect Cars from video (`haarcascades/cars.xml`)\n",
    "\n",
    "video source : [link](https://www.pexels.com/video/cars-on-the-road-854745/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_cascade = cv2.CascadeClassifier('haarcascades/cars.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(\"cars_video.mp4\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame = cv2.resize(frame, (0,0), fx=0.5, fy=0.5)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    cars = car_cascade.detectMultiScale(gray, 1.1, 5)\n",
    "    for (x, y, w, h) in cars:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "    cv2.imshow('Detect Cars', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vehicle Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_cascade = cv2.CascadeClassifier('haarcascades/cars.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(\"cars_video.mp4\")\n",
    "\n",
    "count = 0\n",
    "prev_y = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame = cv2.resize(frame, (0,0), fx=0.5, fy=0.5)\n",
    "    h, w, c = frame.shape\n",
    "    x1, y1, x2, y2 = int(w*0.1), int(h*0.8), int(w*0.9), int(h*0.8)\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    cars = car_cascade.detectMultiScale(gray, minNeighbors=5)\n",
    "    for (x, y, w, h) in cars:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        \n",
    "        cy = (y+h//2)\n",
    "        if (y1 - 30) < cy and (y1 + 30) > cy and abs(prev_y - cy) > 20:\n",
    "            count +=1\n",
    "            prev_y = cy\n",
    "\n",
    "    cv2.line(frame, (x1, y1), (x2, y2), (255, 0, 255), 2)\n",
    "    cv2.putText(frame, \"Vehicle Count : %d\" % count, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 1, cv2.LINE_AA)  \n",
    "    cv2.imshow('Detect Cars', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "- Ubah agar pada video dapat diketahui arah datangnya object, atas / bawah\n",
    "<img src=\"resource/vehicle_counting.png\" style=\"width:500px;\"></img>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Jawaban ------\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_cascade = cv2.CascadeClassifier('haarcascades/cars.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(\"cars_video.mp4\")\n",
    "\n",
    "count = 0\n",
    "prev_y = 0\n",
    "direction = \"\"\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame = cv2.resize(frame, (0,0), fx=0.5, fy=0.5)\n",
    "    h, w, c = frame.shape\n",
    "    x1, y1, x2, y2 = int(w*0.1), int(h*0.7), int(w*0.9), int(h*0.7)\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    cars = car_cascade.detectMultiScale(gray, minNeighbors=5)\n",
    "    for (x, y, w, h) in cars:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        cy = (y+h//2)\n",
    "        if (y1 - 30) < cy and (y1 + 30) > cy and abs(prev_y - cy) > 20:\n",
    "            count +=1\n",
    "            if prev_y > cy :\n",
    "                direction = \"up\"\n",
    "            else :\n",
    "                direction = \"down\"\n",
    "            prev_y = cy\n",
    "\n",
    "    cv2.line(frame, (x1, y1), (x2, y2), (255, 0, 255), 2)\n",
    "    cv2.putText(frame, \"Vehicle Count : %d | Direction : %s\" % (count, direction), (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 1, cv2.LINE_AA)  \n",
    "    cv2.imshow('Detect Cars', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Cascade Classifier Training\n",
    "- For training a boosted cascade of weak classifiers we need a set of **positive images** (containing actual objects you want to detect) and a set of **negative images** (containing everything you do not want to detect). \n",
    "- The set of **negative images** must be prepared manually, whereas set of positive samples is created using the `opencv_createsamples` application.\n",
    "\n",
    "#### Negative Samples\n",
    "- Negative samples are taken from arbitrary images, not containing objects you want to detect. \n",
    "- These negative images, from which the samples are generated, should be listed in a special negative image file containing one image path per line (can be absolute or relative). \n",
    "- Note that negative samples and sample images are also called background samples or background images, and are used interchangeably in this document.\n",
    "- Directory Structure :\n",
    "\n",
    "> /img <br>\n",
    ">  &emsp;img1.jpg<br>\n",
    ">  &emsp;img2.jpg<br>\n",
    "> bg.txt\n",
    "\n",
    "- File bg.txt:\n",
    "> img/img1.jpg<br>\n",
    "> img/img2.jpg\n",
    "\n",
    "#### Positive Samples\n",
    "- Positive samples are created by the `opencv_createsamples` application. \n",
    "- They are used by the boosting process to define what the model should actually look for when trying to find your objects of interest. \n",
    "- The application supports two ways of generating a positive sample dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Step \n",
    "- Original repository : [opencv-haar-classifier-training](https://github.com/mrnugget/opencv-haar-classifier-training)\n",
    "- Open **Windows powershell** (Windows OS) or **Terminal** (Ubuntu/ Debian)\n",
    "- Creeate new conda envi for this training purpose :\n",
    "> `conda create --name py27 python=2.7` <br>\n",
    "`conda activate py27`\n",
    "- Navigate to folder `haar-train/`\n",
    "> `cd <path>/<to>/<folder>/haar-train` \n",
    "- Put positive and negative image name in `.txt` file,\n",
    "- *Linux :*\n",
    "> ` find ./positive_images -iname \"*.jpg\" > positives.txt` <br>\n",
    "> `find ./negative_images -iname \"*.jpg\" > negatives.txt`\n",
    "- *Windows :*\n",
    "> `Get-ChildItem ./positive_images -Filter *.png -Recurse | % { $_.FullName } | Out-File positives.txt -encoding Utf8` <br>\n",
    "> `Get-ChildItem ./negative_images -Filter *.png -Recurse | % { $_.FullName } | Out-File negatives.txt -encoding Utf8` \n",
    "- Create positive samples with the `./createsamples.py` script and save them to the `./samples folder`:\n",
    "> ```python ./createsamples.py```\n",
    "- Use `mergevec.py` to merge the samples in `./samples` into one file (`sample.vec`):\n",
    "> `python ./tools/mergevec.py -v samples/ -o samples.vec`\n",
    "    * <i style=\"color:red\">Note: If you get the error struct.error: unpack requires a string argument of length 12 then go into your samples directory and delete all files of length 0</i>.\n",
    "- Start training the classifier with opencv_traincascade, which comes with OpenCV, and save the results to ./classifier:\n",
    "> ``` tools/opencv_traincascade -data classifier -vec samples.vec -bg negatives.txt -numStages 20 -minHitRate 0.999 -maxFalseAlarmRate 0.5 -numPos 500 -numNeg 500 -w 32 -h 32 -mode ALL -precalcValBufSize 256 -precalcIdxBufSize 256```\n",
    "- If you want to train it faster, configure feature type option with LBP:\n",
    ">  ``` tools/opencv_traincascade -data classifier -vec samples.vec -bg negatives.txt -numStages 20 -minHitRate 0.999 -maxFalseAlarmRate 0.5 -numPos 500 -numNeg 500 -w 32 -h 32 -mode ALL -precalcValBufSize 256 -precalcIdxBufSize 256 -featureType LBP```\n",
    "- After starting the training program it will print back its parameters and then start training. \n",
    "- Each stage will print out some analysis as it is trained:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "===== TRAINING 0-stage =====\n",
    "POS count : consumed   1000 : 1000\n",
    "NEG count : acceptanceRatio    600 : 1\n",
    "Precalculation time: 11\n",
    "+----+---------+---------+\n",
    "|  N |    HR   |    FA   |\n",
    "+----+---------+---------+\n",
    "|   1|        1|        1|\n",
    "+----+---------+---------+\n",
    "|   2|        1|        1|\n",
    "+----+---------+---------+\n",
    "|   3|        1|        1|\n",
    "+----+---------+---------+\n",
    "|   4|        1|        1|\n",
    "+----+---------+---------+\n",
    "|   5|        1|        1|\n",
    "+----+---------+---------+\n",
    "|   6|        1|        1|\n",
    "+----+---------+---------+\n",
    "|   7|        1| 0.711667|\n",
    "+----+---------+---------+\n",
    "|   8|        1|     0.54|\n",
    "+----+---------+---------+\n",
    "|   9|        1|    0.305|\n",
    "+----+---------+---------+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haar Training GUI Application\n",
    "\n",
    "Created by : [Amin Ahmadi - cascade-trainer-gui](https://amin-ahmadi.com/cascade-trainer-gui/)\n",
    "\n",
    "![](resource/cascade-trainer-gui-01-train-input-768x540.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Casecade Classifier Training \n",
    "- n sample : 24000\n",
    "- p sample : 5000\n",
    "- n stage : 7\n",
    "- Feature : LBP\n",
    "- HR : 0.995\n",
    "- FA : 0.2\n",
    "- WxH : 32x32\n",
    "\n",
    "![](resource/cascade-trainer-guis-02.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:opencv_env]",
   "language": "python",
   "name": "conda-env-opencv_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
