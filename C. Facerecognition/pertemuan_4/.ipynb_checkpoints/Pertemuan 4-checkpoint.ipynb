{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV Object Detection\n",
    "\n",
    "- Casecade Classifier\n",
    "- Casecade Classifier Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Casecade Classifier\n",
    "<img src=\"resource/lena_face.png\" style=\"width:250px\"></img><br>\n",
    "- Object Detection OpenCV is using **Haar feature-based cascade classifiers.**\n",
    "- Is an effective object detection method proposed by Paul Viola and Michael Jones in their paper, \"Rapid Object Detection using a Boosted Cascade of Simple Features\" in 2001.\n",
    "- **Haar features** just like normal convolutional kernel, <br><br>\n",
    "<img src=\"resource/haar_feature.png\"></img><br><br>\n",
    "- Each feature is a single value obtained by **subtracting** sum of pixels under the **white rectangle** from sum of pixels under the **black rectangle**. <br><br>\n",
    "<img src=\"resource/face_haar_feature.png\" style=\"width:600px\"></img><br><br>\n",
    "- `lena.jpg` convolving proses to detect face using haar feature, <br><br>\n",
    "<img src=\"resource/convolving_haar_feature.gif\" style=\"width:250px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Class `cv2.CascadeClassifier()` digunakan untuk membaca classifier file (**.xml**)\n",
    "- Pada class `cv2.CascadeClassifier()` terdapat method `.detectMultiscale()` untuk melakukan deteksi objek pada sebuah citra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Method `.detectMultiscale()` memiliki beberapa parameter input,\n",
    "    - `scaleFactor` : Ukuran seberapa besar input image direduksi agar mampu dibaca oleh detector algorithm. Hal inilah yang memungkinkan algorima dapat mendeteksi wajah dalam beragam skala gambar (multi scale image).\n",
    "    - `minNeighbors` : Ukuran minimum antara posisi face rectangle satu terhadap lainya. Hal ini berkaitan dengan method `.detectMultiscale()` yang akan melakukan sliding window terhadap image. Jika kita set ke 0, maka banyak false positive face rectangle terdeteksi. sehingga kita akan pilih nilai yang lebih tinggi. Namun jangan sampai memilih nilai yang terlalu besar, yang mengakibatkan true positive face rectangle menjadi tidak terdeteksi.\n",
    "    - `flags` : Parameter yang sama pada method cvHaarDetectObjects. Ini tidak digunakan pada Cascade Classifier terbaru.\n",
    "    - `minSize` : Ukuran object minimal. Ukuran yang lebih kecil tidak akan dimasukan kedalam detected object.\n",
    "    - `maxSize` : Ukuran object maksimal. Ukuran yang lebih besar tidak akan dimasukan kedalam detected object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Face Detection (`haarcascade_frontalface_default.xml`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "img = cv2.imread(\"lena.jpg\")\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "for (x,y,w,h) in faces:\n",
    "    img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "cv2.imshow('img',img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Eye Detection (`haarcascades/haarcascade_eye.xml`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_eye.xml')\n",
    "\n",
    "img = cv2.imread(\"eye.jpg\")\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "eye = eye_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "for (x,y,w,h) in eye:\n",
    "    img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "cv2.imshow('img',img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Face Detection (haarcascade_frontalface_default.xml)\n",
    "    - Eye Detection (`haarcascades/haarcascade_eye.xml`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_eye.xml')\n",
    "smile_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_smile.xml')\n",
    "\n",
    "img = cv2.imread(\"lena.jpg\")\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "for (x,y,w,h) in faces:\n",
    "    img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    \n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    \n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "    for (x,y,w,h) in eyes:\n",
    "        cv2.rectangle(roi_color,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        \n",
    "    smile = smile_cascade.detectMultiScale(roi_gray, 1.5, 7)\n",
    "    for (x,y,w,h) in smile:\n",
    "        cv2.rectangle(roi_color,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "\n",
    "cv2.imshow('img',img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Detect Face from Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        cv2.imshow('Detect Face', frame)\n",
    "        if cv2.waitKey(25) == ord('q'):\n",
    "            break\n",
    "    else :\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using custom box (`draw_ped()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_ped(img, label, x0, y0, xt, yt, color=(255,127,0), text_color=(255,255,255)):\n",
    "\n",
    "    (w, h), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "    cv2.rectangle(img,\n",
    "                  (x0, y0 + baseline),  \n",
    "                  (max(xt, x0 + w), yt), \n",
    "                  color, \n",
    "                  2)\n",
    "    cv2.rectangle(img,\n",
    "                  (x0, y0 - h),  \n",
    "                  (x0 + w, y0 + baseline), \n",
    "                  color, \n",
    "                  -1)  \n",
    "    cv2.putText(img, \n",
    "                label, \n",
    "                (x0, y0),                   \n",
    "                cv2.FONT_HERSHEY_SIMPLEX,     \n",
    "                0.5,                          \n",
    "                text_color,                \n",
    "                1,\n",
    "                cv2.LINE_AA) \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Apply to Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "img = cv2.imread(\"family.jpg\")\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "for (x,y,w,h) in faces:\n",
    "    img = draw_ped(img, \"human face\", x, y, x + w, y + h)\n",
    "\n",
    "cv2.imshow('img',img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
    "        for (x, y, w, h) in faces:\n",
    "            frame = draw_ped(frame, \"human face\", x, y, x + w, y + h)\n",
    "        cv2.imshow('Detect Face', frame)\n",
    "    else :\n",
    "        break\n",
    "    if cv2.waitKey(25) == ord('q'):\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cars detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_cascade = cv2.CascadeClassifier('haarcascades/cars.xml')\n",
    "\n",
    "img = cv2.imread(\"cars2.jpg\")\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cars = cars_cascade.detectMultiScale(gray, scaleFactor = 1.1, minNeighbors = 2)\n",
    "for (x,y,w,h) in cars:\n",
    "    img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "img = cv2.resize(img, (0,0), fx=0.5, fy=0.5)\n",
    "cv2.imshow('img',img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Detect Cars from video (`haarcascades/cars.xml`)\n",
    "\n",
    "video source : [link](https://www.pexels.com/video/cars-on-the-road-854745/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_cascade = cv2.CascadeClassifier('haarcascades/cars_v2.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(\"cars_video.mp4\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        frame = cv2.resize(frame, (0,0), fx=0.5, fy=0.5)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        cars = car_cascade.detectMultiScale(gray, 1.1, 5)\n",
    "        for (x, y, w, h) in cars:\n",
    "            cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "            \n",
    "        cv2.imshow('Detect Cars', frame)\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "    else :\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Full Body detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_body_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_fullbody.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(\"pedestrians.mp4\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret:\n",
    "        \n",
    "        frame = cv2.resize(frame, (0,0), fx=0.4, fy=0.4)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        full_bodies = full_body_cascade.detectMultiScale(gray, 1.1, 5)\n",
    "        for (x, y, w, h) in full_bodies:\n",
    "            frame = draw_ped(frame, \"full body\", x, y, x + w, y + h)\n",
    "            \n",
    "        cv2.imshow('Detect Cars', frame)\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "    else :\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Cascade Classifier Training\n",
    "- For training a boosted cascade of weak classifiers we need a set of **positive images** (containing actual objects you want to detect) and a set of **negative images** (containing everything you do not want to detect). \n",
    "- The set of **negative images** must be prepared manually, whereas set of positive samples is created using the `opencv_createsamples` application.\n",
    "\n",
    "#### Negative Samples\n",
    "- Negative samples are taken from arbitrary images, not containing objects you want to detect. \n",
    "- These negative images, from which the samples are generated, should be listed in a special negative image file containing one image path per line (can be absolute or relative). \n",
    "- Note that negative samples and sample images are also called background samples or background images, and are used interchangeably in this document.\n",
    "- Directory Structure :\n",
    "\n",
    "> /img <br>\n",
    ">  &emsp;img1.jpg<br>\n",
    ">  &emsp;img2.jpg<br>\n",
    "> bg.txt\n",
    "\n",
    "- File bg.txt:\n",
    "> img/img1.jpg<br>\n",
    "> img/img2.jpg\n",
    "\n",
    "#### Positive Samples\n",
    "- Positive samples are created by the `opencv_createsamples` application. \n",
    "- They are used by the boosting process to define what the model should actually look for when trying to find your objects of interest. \n",
    "- The application supports two ways of generating a positive sample dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haar Training GUI Application\n",
    "\n",
    "Created by : [Amin Ahmadi - cascade-trainer-gui](https://amin-ahmadi.com/cascade-trainer-gui/)\n",
    "\n",
    "![](resource/cascade-trainer-gui-01-train-input-768x540.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Casecade Classifier Training \n",
    "- n sample : 24000\n",
    "- p sample : 5000\n",
    "- n stage : 7\n",
    "- Feature : LBP\n",
    "- HR : 0.995\n",
    "- FA : 0.2\n",
    "- WxH : 32x32\n",
    "\n",
    "![](resource/cascade-trainer-guis-02.png)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "===== TRAINING 0-stage =====\n",
    "POS count : consumed   1000 : 1000\n",
    "NEG count : acceptanceRatio    600 : 1\n",
    "Precalculation time: 11\n",
    "+----+---------+---------+\n",
    "|  N |    HR   |    FA   |\n",
    "+----+---------+---------+\n",
    "|   1|        1|        1|\n",
    "+----+---------+---------+\n",
    "|   2|        1|        1|\n",
    "+----+---------+---------+\n",
    "|   3|        1|        1|\n",
    "+----+---------+---------+\n",
    "|   4|        1|        1|\n",
    "+----+---------+---------+\n",
    "|   5|        1|        1|\n",
    "+----+---------+---------+\n",
    "|   6|        1|        1|\n",
    "+----+---------+---------+\n",
    "|   7|        1| 0.711667|\n",
    "+----+---------+---------+\n",
    "|   8|        1|     0.54|\n",
    "+----+---------+---------+\n",
    "|   9|        1|    0.305|\n",
    "+----+---------+---------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:opencv_env]",
   "language": "python",
   "name": "conda-env-opencv_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
