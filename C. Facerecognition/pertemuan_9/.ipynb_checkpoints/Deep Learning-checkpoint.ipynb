{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Satet-Of-The-Art Deep Learning for Face Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MTCNN (Multi Task Cascade Convolution Neural Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *“Multi-Task Cascaded Convolutional Neural Network,”* or MTCNN for short, described by Kaipeng Zhang, et al. in the 2016 paper titled *“Joint Face Detection and Alignment Using Multitask Cascaded Convolutional Networks.”*\n",
    "- The MTCNN is popular because it achieved then **state-of-the-art** results on a range of benchmark datasets, and because it is capable of also recognizing other **facial features** such as **eyes** and **mouth**, called **landmark detection**.\n",
    "- The network uses a cascade structure with three networks; \n",
    "    - first the image is rescaled to a range of different sizes (called an **image pyramid**), \n",
    "    - then the first model (Proposal Network or **P-Net**) proposes **candidate facial regions**, \n",
    "    - the second model (Refine Network or **R-Net**) **filters the bounding boxes**, and \n",
    "    - the third model (Output Network or **O-Net**) proposes **facial landmarks**.\n",
    "    \n",
    "<img src=\"resource/mtcnnmodel.png\" style=\"width:400px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- install **pre-trained** model in library `mtcnn` created by *ipazc/MTCNN*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install mtcnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- detect face on **image** using `mtcnn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "\n",
    "detector_mtcnn = MTCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"lena.jpg\")\n",
    "faces = detector_mtcnn.detect_faces(img)\n",
    "for face in faces:\n",
    "    print(face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"lena.jpg\")\n",
    "faces = detector_mtcnn.detect_faces(img)\n",
    "for face in faces:\n",
    "    x, y, w, h = face['box']\n",
    "    cv2.rectangle(img, (x,y), (x+w, y+h), (0,255,255), 2)\n",
    "    print(\"confidence : %.2f%%\" % (face['confidence']*100))\n",
    "\n",
    "plt.imshow(img[:,:,::-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **IMPORANT NOTICE** : *MTCNN required image in 3D shape (its means we doesn't need to convert data to grayscale before)*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- detect face on **video frame** using `mtcnn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_ped(img, label, x0, y0, xt, yt, color=(255,127,0), text_color=(255,255,255)):\n",
    "\n",
    "    (w, h), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "    cv2.rectangle(img,\n",
    "                  (x0, y0 + baseline),  \n",
    "                  (max(xt, x0 + w), yt), \n",
    "                  color, \n",
    "                  2)\n",
    "    cv2.rectangle(img,\n",
    "                  (x0, y0 - h),  \n",
    "                  (x0 + w, y0 + baseline), \n",
    "                  color, \n",
    "                  -1)  \n",
    "    cv2.putText(img, \n",
    "                label, \n",
    "                (x0, y0),                   \n",
    "                cv2.FONT_HERSHEY_SIMPLEX,     \n",
    "                0.5,                          \n",
    "                text_color,                \n",
    "                1,\n",
    "                cv2.LINE_AA) \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret:\n",
    "        faces = detector_mtcnn.detect_faces(frame)\n",
    "        for face in faces:\n",
    "            x, y, w, h = face['box']\n",
    "            label_text = \"face (%.2f %%)\" % (face['confidence']*100)\n",
    "            frame = draw_ped(frame, label_text, x, y, x + w, y + h, color=(0,255,255), text_color=(50,50,50))\n",
    "            \n",
    "        cv2.imshow(\"Face detection MTCNN\", frame)\n",
    "        \n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "    else :\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:GPU_ENV]",
   "language": "python",
   "name": "conda-env-GPU_ENV-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
