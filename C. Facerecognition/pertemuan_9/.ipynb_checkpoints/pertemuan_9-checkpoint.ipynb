{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pertemuan 9\n",
    "- Intro OpenCV DNN\n",
    "- Convert Keras Model (.h5) to Tensorflow (.pb)\n",
    "- Optimize Model (.pb) using Tensorboard & Tensorflow\n",
    "- Stream Video OpenCV DNN to Flask \n",
    "    - Basic Flask Route & Templating\n",
    "    - Flask - OpenCV MJPEG Stream\n",
    "    - Flask - OpenCV Facedetection MJPEG Stream\n",
    "    - Flask - OpenCV Facerecognition MJPEG Stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 OpenCV DNN\n",
    "\n",
    "- Compatibility : > OpenCV 3.3\n",
    "- Wiki : https://github.com/opencv/opencv/wiki/Deep-Learning-in-OpenCV\n",
    "- Since OpenCV 3.1 there is DNN module in the library that implements **forward pass** (inferencing) with deep networks, **pre-trained**using some popular deep learning frameworks.\n",
    "- The supported frameworks:\n",
    "    - Caffe\n",
    "    - TensorFlow\n",
    "    - Torch\n",
    "    - Darknet (Yolo)\n",
    "    - Models in ONNX format </br>\n",
    "    \n",
    "#### 1.1 OpenCV DNN workflow\n",
    "![](resource/opencv_dnn_01.png)\n",
    "\n",
    "#### 1.2 Model Preparation for OpenCV DNN\n",
    "![](resource/opencv_dnn_03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Convert Keras (.h5) to Tensorflow (.pb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n",
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "print(keras.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- load keras model (.h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model-cnn-facerecognition.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- save model as a folder `'tf_model/'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\yunus\\Anaconda3\\envs\\CVDL\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: tf_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"tf_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 6622-681D\n",
      "\n",
      " Directory of C:\\Users\\yunus\\Documents\\GitHub\\Materi-Training\\C. Facerecognition\\pertemuan_9\\tf_model\n",
      "\n",
      "12/28/2020  11:42 PM    <DIR>          .\n",
      "12/28/2020  11:42 PM    <DIR>          ..\n",
      "12/28/2020  11:42 PM    <DIR>          assets\n",
      "12/28/2020  11:42 PM           200,562 saved_model.pb\n",
      "12/28/2020  11:42 PM    <DIR>          variables\n",
      "               1 File(s)        200,562 bytes\n",
      "               4 Dir(s)  254,368,636,928 bytes free\n"
     ]
    }
   ],
   "source": [
    "! dir tf_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 View Input & Output model graph (.pb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "importer = tf.saved_model.load(\"tf_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer = importer.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_5_input Placeholder\n",
      "statefulpartitionedcall_args_11 Const\n",
      "statefulpartitionedcall_args_13 Const\n",
      "statefulpartitionedcall_args_9 Const\n",
      "statefulpartitionedcall_args_14 Const\n",
      "statefulpartitionedcall_args_5 Const\n",
      "statefulpartitionedcall_args_2 Const\n",
      "statefulpartitionedcall_args_3 Const\n",
      "statefulpartitionedcall_args_4 Const\n",
      "statefulpartitionedcall_args_1 Const\n",
      "statefulpartitionedcall_args_6 Const\n",
      "statefulpartitionedcall_args_7 Const\n",
      "statefulpartitionedcall_args_10 Const\n",
      "statefulpartitionedcall_args_12 Const\n",
      "statefulpartitionedcall_args_8 Const\n",
      "Func/StatefulPartitionedCall/input_control_node/_0 NoOp\n",
      "Func/StatefulPartitionedCall/input/_1 Identity\n",
      "Func/StatefulPartitionedCall/input/_2 Identity\n",
      "StatefulPartitionedCall/sequential_3/conv2d_5/Conv2D/ReadVariableOp Identity\n",
      "StatefulPartitionedCall/sequential_3/conv2d_5/Conv2D Conv2D\n",
      "Func/StatefulPartitionedCall/input/_3 Identity\n",
      "StatefulPartitionedCall/sequential_3/conv2d_5/BiasAdd/ReadVariableOp Identity\n",
      "StatefulPartitionedCall/sequential_3/conv2d_5/BiasAdd BiasAdd\n",
      "StatefulPartitionedCall/sequential_3/conv2d_5/Relu Relu\n",
      "Func/StatefulPartitionedCall/input/_4 Identity\n",
      "StatefulPartitionedCall/sequential_3/conv2d_6/Conv2D/ReadVariableOp Identity\n",
      "StatefulPartitionedCall/sequential_3/conv2d_6/Conv2D Conv2D\n",
      "Func/StatefulPartitionedCall/input/_5 Identity\n",
      "StatefulPartitionedCall/sequential_3/conv2d_6/BiasAdd/ReadVariableOp Identity\n",
      "StatefulPartitionedCall/sequential_3/conv2d_6/BiasAdd BiasAdd\n",
      "StatefulPartitionedCall/sequential_3/conv2d_6/Relu Relu\n",
      "StatefulPartitionedCall/sequential_3/max_pooling2d_3/MaxPool MaxPool\n",
      "Func/StatefulPartitionedCall/input/_6 Identity\n",
      "StatefulPartitionedCall/sequential_3/conv2d_7/Conv2D/ReadVariableOp Identity\n",
      "StatefulPartitionedCall/sequential_3/conv2d_7/Conv2D Conv2D\n",
      "Func/StatefulPartitionedCall/input/_7 Identity\n",
      "StatefulPartitionedCall/sequential_3/conv2d_7/BiasAdd/ReadVariableOp Identity\n",
      "StatefulPartitionedCall/sequential_3/conv2d_7/BiasAdd BiasAdd\n",
      "StatefulPartitionedCall/sequential_3/conv2d_7/Relu Relu\n",
      "Func/StatefulPartitionedCall/input/_8 Identity\n",
      "StatefulPartitionedCall/sequential_3/conv2d_8/Conv2D/ReadVariableOp Identity\n",
      "StatefulPartitionedCall/sequential_3/conv2d_8/Conv2D Conv2D\n",
      "Func/StatefulPartitionedCall/input/_9 Identity\n",
      "StatefulPartitionedCall/sequential_3/conv2d_8/BiasAdd/ReadVariableOp Identity\n",
      "StatefulPartitionedCall/sequential_3/conv2d_8/BiasAdd BiasAdd\n",
      "StatefulPartitionedCall/sequential_3/conv2d_8/Relu Relu\n",
      "StatefulPartitionedCall/sequential_3/max_pooling2d_4/MaxPool MaxPool\n",
      "StatefulPartitionedCall/sequential_3/flatten_2/Reshape/shape Const\n",
      "StatefulPartitionedCall/sequential_3/flatten_2/Reshape Reshape\n",
      "Func/StatefulPartitionedCall/input/_10 Identity\n",
      "StatefulPartitionedCall/sequential_3/dense_8/MatMul/ReadVariableOp Identity\n",
      "StatefulPartitionedCall/sequential_3/dense_8/MatMul MatMul\n",
      "Func/StatefulPartitionedCall/input/_11 Identity\n",
      "StatefulPartitionedCall/sequential_3/dense_8/BiasAdd/ReadVariableOp Identity\n",
      "StatefulPartitionedCall/sequential_3/dense_8/BiasAdd BiasAdd\n",
      "StatefulPartitionedCall/sequential_3/dense_8/Relu Relu\n",
      "Func/StatefulPartitionedCall/input/_12 Identity\n",
      "StatefulPartitionedCall/sequential_3/dense_9/MatMul/ReadVariableOp Identity\n",
      "StatefulPartitionedCall/sequential_3/dense_9/MatMul MatMul\n",
      "Func/StatefulPartitionedCall/input/_13 Identity\n",
      "StatefulPartitionedCall/sequential_3/dense_9/BiasAdd/ReadVariableOp Identity\n",
      "StatefulPartitionedCall/sequential_3/dense_9/BiasAdd BiasAdd\n",
      "StatefulPartitionedCall/sequential_3/dense_9/Relu Relu\n",
      "Func/StatefulPartitionedCall/input/_14 Identity\n",
      "StatefulPartitionedCall/sequential_3/dense_10/MatMul/ReadVariableOp Identity\n",
      "StatefulPartitionedCall/sequential_3/dense_10/MatMul MatMul\n",
      "Func/StatefulPartitionedCall/input/_15 Identity\n",
      "StatefulPartitionedCall/sequential_3/dense_10/BiasAdd/ReadVariableOp Identity\n",
      "StatefulPartitionedCall/sequential_3/dense_10/BiasAdd BiasAdd\n",
      "StatefulPartitionedCall/sequential_3/activation_3/Softmax Softmax\n",
      "StatefulPartitionedCall/Identity Identity\n",
      "Func/StatefulPartitionedCall/output/_16 Identity\n",
      "Func/StatefulPartitionedCall/output_control_node/_17 NoOp\n",
      "Identity Identity\n"
     ]
    }
   ],
   "source": [
    "f = convert_variables_to_constants_v2(infer)\n",
    "graph_def = f.graph.as_graph_def()\n",
    "\n",
    "for n in graph_def.node:\n",
    "    print( n.name, n.op)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 Convert Model (.pb) to frozen model graph (.pb) & Optimize for Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.tools import optimize_for_inference_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = convert_variables_to_constants_v2(infer)\n",
    "graph_def = f.graph.as_graph_def()\n",
    "\n",
    "graph_def = optimize_for_inference_lib.optimize_for_inference(graph_def,\n",
    "                                                              ['conv2d_5_input'],\n",
    "                                                              ['Identity'],\n",
    "                                                              tf.float32.as_datatype_enum)\n",
    "\n",
    "with tf.io.gfile.GFile('frozen_graph.pb', 'wb') as f:\n",
    "    f.write(graph_def.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6 Inference model using OpenCV DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.5.0'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.6.A Load Model using OpenCV DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Ariel_Sharon',\n",
    "          'Colin_Powell',\n",
    "          'Donald_Rumsfeld',\n",
    "          'George_W_Bush',\n",
    "          'Gerhard_Schroeder',\n",
    "          'Hugo_Chavez',\n",
    "          'Jacques_Chirac',\n",
    "          'Jean_Chretien',\n",
    "          'John_Ashcroft',\n",
    "          'Junichiro_Koizumi',\n",
    "          'Serena_Williams',\n",
    "          'Tony_Blair',\n",
    "          'Yunus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "facerecognition_model = \"frozen_graph.pb\"\n",
    "net = cv2.dnn.readNet(facerecognition_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `cv2.dnn.readNet(model, configration)` \n",
    "- where :\n",
    "    - `model` :\n",
    "        - `*.caffemodel` (Caffe, http://caffe.berkeleyvision.org/)\n",
    "        - `*.pb` (TensorFlow, https://www.tensorflow.org/)\n",
    "        - `*.t7` | `*.net` (Torch, http://torch.ch/)\n",
    "        - `*.weights` (Darknet, https://pjreddie.com/darknet/)\n",
    "        - `*.bin` (DLDT, https://software.intel.com/openvino-toolkit)\n",
    "    - `configuration` :\n",
    "        - `*.prototxt` (Caffe, http://caffe.berkeleyvision.org/)\n",
    "        - `*.pbtxt` (TensorFlow, https://www.tensorflow.org/)\n",
    "        - `*.cfg` (Darknet, https://pjreddie.com/darknet/)\n",
    "        - `*.xml` (DLDT, https://software.intel.com/openvino-toolkit)\n",
    "- This function automatically detects an origin framework of trained model and calls an appropriate function such \n",
    "    - `cv2.dnn.readNetFromCaffe` \n",
    "    - `cv2.dnn.readNetFromTensorflow`\n",
    "    - `cv2.dnn.readNetFromTorch` \n",
    "    - `cv2.dnn.readNetFromDarknet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set backend & target OpenCV DNN\n",
    "\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "layerOutput = net.getUnconnectedOutLayersNames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['StatefulPartitionedCall/sequential_3/activation_3/Softmax']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layerOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.6.B Predict Image Face using OpenCV DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face(img):\n",
    "    img = img[70:195,78:172]\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.resize(img, (50, 50))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Colin_Powell_0008.jpg',\n",
       " 'Donald_Rumsfeld_0009.jpg',\n",
       " 'George_W_Bush_0016.jpg',\n",
       " 'Gerhard_Schroeder_0012.jpg',\n",
       " 'Tony_Blair_0012.jpg']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"test_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"test_data/Donald_Rumsfeld_0009.jpg\")\n",
    "\n",
    "img = detect_face(img)\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(img, 1.0, (50, 50), (0, 0, 0), swapRB=True, crop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50, 50), (1, 1, 50, 50))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape, blob.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cv2.dnn.blobFromImage(img,scalefactor = 1.0,output_size, mean_channel,swapRB = false,crop = false,ddepth = cv2.CV_32F)`\n",
    "\n",
    "- `image`\tinput image (with 1-, 3- or 4-channels).\n",
    "- `size`\tspatial size for output image\n",
    "- `mean`\tscalar with mean values which are subtracted from channels. Values are intended to be in (mean-R, mean-G, mean-B) order if image has BGR ordering and swapRB is true.\n",
    "- `scalefactor`\tmultiplier for image values.\n",
    "- `swapRB`\tflag which indicates that swap first and last channels in 3-channel image is necessary.\n",
    "- `crop`\tflag which indicates whether image will be cropped after resize or not\n",
    "- `ddepth`\tDepth of output blob. Choose cv2.CV_32F or cv2.CV_8U."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Set blob to input network using `.setInput()` on `net` object\n",
    "- Do forward pass and get output using `.forward()` on `net` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.setInput(blob)\n",
    "output = net.forward(layerOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = output[0].argmax(axis=1)[0]\n",
    "\n",
    "confidence = output[0].max(axis=1)[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARcAAAEICAYAAAB1U7CaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAtgUlEQVR4nO2de7QfVZXnPzuXAIEEIQ/yJrwCbeQh0xmaEVcPozgCooCrtcXWwZYZtKe7BdoHoCwfq7vt9LQ69mp72U2rA0grg6JCYzNjmpZhHHkFeScIgZCEcElCSCC8HznzR1VC1bf2vXXu5VZ+9172Z6277u/Ur06dXafqt391vr999rGUEkEQBCPNhF4bEATB+CScSxAEnRDOJQiCTgjnEgRBJ4RzCYKgE8K5BEHQCeFcgiDohFbnYmYPm9nxOQczs2RmBw/HkNdSt5eY2XFm9sgg719sZn+2M20aLmY208xuMLOtZvbVln33L6/ZLgO8/0Uzu6wbS/Mws9PMbK2ZPW1mR5nZvWZ23AD7Dnodg6EzLp5cSgf4XPmh2GJmvzSzj5vZmDi/8sbeVn4ItprZr83s93tgylnA48BeKaVP9qD9keYrwB+llCanlG5PKb0ppXR9r40aCcxsVzP7YXnvJ3WaVvCXZrap/PtvZmaV9/c3s5+b2bNmdl/1AcLMjiwd8eNmdm5l+0Qzu9nM5ufYOCY+fJm8O6U0BVgALAHOA77dW5OGxKMppcnAXsC5wD+Y2aE72YYFwPI0fsK2FwD39tqIDvkF8CHgMee9s4BTgSOBI4CTgY9V3v8+cDswDfgc8EMzm1G+9xfAp8q6F5rZrHL7nwBXppTWZlmXUhr0D3gYOL58fTRwI7AF6Ae+Aexa2TcBnwAeovgG/CtgQuX9jwIrgM3A/wYWSN2D2+xps7Gy7WhgG3BYWX4DcCmwEVgNXLjdNuAjFBfqK6Vtq4ATK8f6/dLureW5fazy3nHAI5XyUcCvyn3/J3A58Gct9teOUW7bALyvfH1x9RhOmw8DnwbuAp6hcKozgWtLO/4F2Kfcd3fgMmBTeR1vLfe9GHgJeBF4Gjie4svnfODBcv8rgKnlcfYvr9kuZfkA4P+U7S0t743LMq9fH/DZsp2twG3A/PK9t5Q2Pln+f0ul3vXAnwL/r6z3M2A6sFt5Dqnsjwede3lSec6bgeVl/1X7dA5wJcX9sgr4ROW9L5Z9cWnZ7r3A4sr784EflXU3Ad/I+QwM9w94BDhOtv0SOKtSPhO4qXx9CPACMKXy/v8FPl6+XgHsVr6+ieKztB9wCzAx264hOpffBI4BdilvrhXAOeIgfg5MLY25H/jP5XunAiuBN5b1LwR+meNcKG7wa4biXMrta4A/KF9fClwFTCltvx84s+JcXgL+C8WN/gfAo4CV778LOAgw4N8DzwL/Rj/owK4UjutcYCLwO+Vxs50LxQf6PRSO8aghOJebKJzEXArH9CsKR7cb8K/AF8p9Pwb8E7BHea6/STEM8to5pzzuvPI4fw98fwDnciPwtXK/36b40OU6l08DdwOHln18JMU36lSKD+GHy3vm9LI8reJcHqT4sEwqy0sGuqeo38tLKD5QUymcwT1yDW4DPl9e0wMpvlTeWXEuzwMnlX34F7z6we0D7gT+O7AnhTN/a85nwOmXu4APDtO5PAn8VqW8GNhavj4NWCH7fwP4m/L1D4B3l9f9sfJa/ETbGFHn4rx3DvBjuZgnVMr/FbiufH0t5Ye5cgGfpfTceiMM6SQGdi43UTzy9VF46kWV9z4GXF9xLisr7+1R2jNrgPZ+ApztOIbfpuKUym2/JM+5bKN4kngBeIW6076Ydufye5XylcA3K+U/Bn5Svv5oadMRjh3azgrg7ZXybApnuf3LJZWv9wNeBvas7Ps98p3Lr4FTnO0fBm6RbTcCHylfXw9cKPfb/5L7cSDn8pDcq2dVruNvAWuk3QuA/1G+/iLwL5X3FgHPla//HcUTyy7O+Qz6GRjuH75zeQX4jUp5YdkfVvbrTbL/nwMXl68XAP9M8QV1OsWX3XfL63wVxRPq+9rscpX+gTCzQyi+nRZTfAB3ofDwVarjsdUUj5fbDf5r+RXCKL5pVw/FjiEwF3iC4lF5+1NF1ba5lfKOcWtK6dlS+5oMYGYnAl+g+IacQHHudzvtzQHWpfIKVdrJ4dGU0jwz243iW/VtwNcz6wKsr7x+zilPLl9/l+Kb+nIz25tiiPS5lNJLzjEXAD82s22Vba9QPCFVmQNsTik9U9m2umwnh/kUTyDKHJr9N+B1o/igTiaPOTTv1e0sAOaY2ZbKtj6KJ52B2t29/OVsPrA6pfSy0+bO/Aw8TaHfbWcv4OmUUjIzfW/7+1sBUkqrKZ7KMLM9KL6M3gn8DcVQ/6fAPWZ2XUrpiYEMGKqg+03gPmBhSmkvinGyyT7VG2o/im9yKC7kx1JKe1f+JqWUfjlEG7Iws39LcdF+QaH/vERxcau2rcs4zm4UTwJfAWamlPam8Op63lDoUHOrqnzZTjYppRcoxOjDzezUcvMzFA5tO7O03hCO/1JK6UsppUUUesbJwH8aYPe1FNpT9ZrtnlLSfusH9jGzPSvbhnLeaymGncqj1K/Z9uO2XrcM+mneq1V7Vsl5T0kpnZRx3LXAfgP8RL8zPwP3Ugwvt3Mkr4rb9wIHmtmUAd6v8nngWyml9cDhwLKU0pMUT0uDho4M1blMAZ4Cnjaz36DQJpRPm9k+5c9VZ1N4OoC/Ay4wszcBmNkbzOx9Q2y/FTPby8xOphBSL0sp3Z1SeoVCgPtzM5tiZgsolO+cOIxdKXSEjcDL5VPMfxxg3xsphgefMLNdzOy9FGLYkEgpvQh8leLCAtwBnGRmU0vl/pyhHnM7ZvYfzOxwM+ujuJYvUTyNePwdRZ8tKOvOMLNTHHtXA8uAL5U/kb6VYsxebfdhM/vIAO18C/hTM1tY/oR6hJlNo3Dih5jZB8v+/F2KIcg1Qz7xJldQ3I/7mNk8iqHjdm4BnjKz88xskpn1mdlh5RdWG7dQOK4lZranme1uZseW743oZ8DMdjOz3cvirmVb27/YLgX+xMzmmtkc4JMUw15SSvdT3FNfKOucRvGL0pVy/EUUQ/BvlptWAW8zs5kUw6w1g9k3VOfyKeCDFI9P/8CrjqPKVRRDpTsoHp++XZ7Qj4G/pHgcf4pCQDsxp1Ez+6yZXduy2z+Z2VaKb4fPUQzfqrEif0zxBPAQxdPM94DvtLWdUtpK8QvYFRRi4geBqwfY90XgvRQazmbgdyl+NRgO36H4Bnw3xVDmTgrN4Gf4/Z7LLOCHFI5lBcX4eSAn+9cU5/qzsm9votAjPD5YvvcExRDy0u1vmNmuFKLgTQPU/RpF//6stOvbwKSU0iaKJ6tPUvzq8hng5JTS4zkn2sKXKIYiq8p2v7v9jfLL6N3Am8v3H6dwgG9oO2il7sEUH75HKO6DIX8GyliT3xukuV9TDHnnUvzy9ByvPun9PYVwf3fZzk/Lbdv5AIW8sZliGP47KaWNcvy/pdAWt3/5XEDxWbgX+HJKyfsJ/FX76/JAEIw85ZPMH6aUTu+1LcHOI5xLEASdMJ4idEc15dDuaeevbbgXBGOSEX1yMbMTKMbpfRQK85IRO3gQBGOKEXMu5a8P9wPvoBCxbgVOTyktH6jOlClT0owZMwZ6G4AJEwZ/uKr/6ptXJwfvuLptJNrpihz7u0LvqZx7TPfZtm1b6z5KzvV45ZX6D2NeO7pPDm32e8fUOrvs0h52psd58cUXB91/69atPP/88zvnwgtDCqJr4WiKKNeHAMzscuAUinkbLjNmzODLX/7yjrJ380yaNKlW1hvIu6H22GOPWtn7UGlbepxdd921UWfixIm18m677dbajm7Tdr06emMOx4l59vf19Q163JdfbsZ9aZ0cR/HSS/V4PO+4bXWeeeaZ1n3UFr3uHlu3bh207LWd4/j0Q//cc8/Vyps3b27U0fOZNm1aYx/t/yeeqMesrV3bnENYtfeqq65qvL+zGMmv3rnUIx4foR5JGQTB64iRdC7eo1fja87MzjKzZWa2zPvWCIJgfDCSw6JHqIdTz+PV0P8dpJQuAi4COOigg1J1nOk9yuvjpbLnnns2tukjqg5nAHbfffdaOUePaBtW6PvecbWsj8becbVfvPG7HjfHFsUb87cNQz1bdNiQM5RS7cC7rrqP3hvevdI2pPGGOG3XzLufXnjhhVpZ+1KH0NC8Rp79OtTTIaY3fKzqmL3UBUey5VuBhWZ2QBmR+QEGiGQNgmD8M2JPLimll83sjyjCkPuA76SUxnMWsCAIBmEkh0WklP6ZYrJZEASvc0ZvoEYQBGOaEX1yGSoTJkyoCV2eoJsjVLaRIyjmBDC17ZMTT6Nl75zbUDF6uLQJl9DsbxVwPUFXRUTtN09E1X7w9tHjaD9411lFYLXNq6PtPP3004PaCu2xPJ6gq7Y8//zzjX1U5NUfAN7whuZE7eo+vZw7GE8uQRB0QjiXIAg6IZxLEASd0FPNBerjfC8gyAumquIFoalO4GklbQFlXqBUWzseOhbXsXfOfJicdrUdr1/0nFVL8PpJ7c2Z29UWqObpAKrdeNfH0y2GikaF58ztapvf5qF96Wkyes4aiAfw7LPP1spbtmypldeta6YTXrx48Y7XOfdxV8STSxAEnRDOJQiCTgjnEgRBJ/RUc9m2bVttnDmcmI/Jk5trYKlO48VM5NimtI1fvffVFh2/e6gmodqI147qMDkxNzn93aaX5GgWOYmTFNUaoKlbaD94WojGuehxPU1P9RKt4/WbXtecpFRPPvnkoO3m4MW5LF/+agqltom/XRJPLkEQdEI4lyAIOiGcSxAEnRDOJQiCTuipoGtmNRFuONnpvToqYnkialtbw8kkn5OIOidoTsVZFR0921UMzMk2n5NIW4VIbccLiGsTcL2M9cMRivU4Xh09R703PBFVfyTQCZKe/TrpMCfYUIMCPaFexXztg6lTpzbqVAXo4Uz0HSniySUIgk4I5xIEQSeEcwmCoBN6qrmklNwJdlV0TKzlnMXLcrSc4aymqONf71x0LK6TMz09SPWHnHGz6hqeltAW2JUTeNd2vbx9coIY2xY887bpcb1+Ul1jypQprba0JZjytJE2nclrd6+99qqVN23a1Gqb6m/e9ahm/x9OYN5IEU8uQRB0QjiXIAg6IZxLEASdEM4lCIJO6Kmg29fXV5vV6YlTGtilApUnvLZl3PfqaRYwLwitbQlYT1BsC7TzZv+2Zaj3zllFRi+rWVuGvpylWUcCr59UmPcC1fS8cwRpPce99967VvYy7ms7eo28PtHrqtfMux7a39511cx52vY+++zTqFMVikPQDYJg3BHOJQiCTgjnEgRBJ/Q8+38Vb/yrgUYaRJST2T8nW35OcJ5u03ZyJvENJ2Ncm9YATb0qp19yJlq2BRPmTJDMWfVP+9azXycdqi7j1dHjatm753ICBZW2jH2ebWq/Z4tu0/tfNRmo32M5Wf+6Ip5cgiDohHAuQRB0QjiXIAg6oecTF6tjQm9835acyJtEpuNMbwyt++Rkwm9LTuRpO2pfTlIktUXH855WkqNzeGP6Nlu0/3WfnDF9TqxMzsTRNr3K65e2a6SxS9BM0KR4tum2nERiOcmuFJ0A6U12XL9+/aDt7iziySUIgk4I5xIEQSeEcwmCoBOG7FzM7DtmtsHM7qlsm2pmS83sgfJ/c8JDEASvK4Yj6F4MfAO4tLLtfOC6lNISMzu/LJ/XdiAzqwmGOqkMmkJZzsQ/Fe08obVtcqAnQqpIp8f1RNS2JUe9Oiro5ojY2g8555wTeKf9rbZppjevnZylTXMC11TMVAE0Z0Kh9ouXCbDNFk8k1b5TodjrWxWOvcma2r85K1tUz3E4K2qMFEN+ckkp3QA8IZtPAS4pX18CnPrazAqCYKwzUprLzJRSP0D5f9+BdjSzs8xsmZkt04W4gyAYP+x0QTeldFFKaXFKaXE1l0sQBOOLkQqiW29ms1NK/WY2G9iQUymlVBtnegl1dOyqekNO4JQX6KXHaZuUuN3ewcqeFqLH1fPxdALdR+3XFQSguZJjTkBiji2qA+RMFlRdQ3UDT9Nom5To1dN+8O6ftkmg3v2j+2g7ns6n7ag+5K20uWXLlkHL0NRUdCLv5s2bG3Wq/Z2zikVXjFTLVwNnlK/PAK4aoeMGQTBGGc5P0d8HbgQONbNHzOxMYAnwDjN7AHhHWQ6C4HXMkIdFKaXTB3jr7a/RliAIxhGjKlmUtyqdjmV18p03llXtw9MF2saiOasc6jFy9Ae1P2fFRdUjvH5SjcjTf5566qlaWRMNeTpTW1LynPgUbTdnH09zUU3liSfqERGrVq1q1FFNQo+hyZcAJk+eXCtPnTq1VvbOWY+7YUNddpwzZ06jjv6gUZ1wuJ22CZ3efVy9x7pIsJ5LhP8HQdAJ4VyCIOiEcC5BEHRCOJcgCDqh54JuVbz0RDwNctKAspyM715wVdvkupwJhVpuy2AGTbHQy97ethJBzsS/nEzyihdQ1jZx0Qvo06A5PUfvOus5Pfroo419Hn744Vp59erVtbJ3zebNmzdo2RPHtS9V1PbaUeFY66jt0AyI8yaBtgUgegGi1SC/EHSDIBh3hHMJgqATwrkEQdAJPddc2oLVdJLYtGnTWutr0JmnJejYVSeNecFJGvSk4921a9c26ui2nOA8DezSdr3ALw308rLat00o9FZA0DG76jbe+eg1Uy3K06Y0iE6D0KB5Tscee2ytPHPmzEYd7TsNuvQ0Lz3nHM1I29E+8CY76n3q3XMaRNfL5E9DJZ5cgiDohHAuQRB0QjiXIAg6oecrLlb1EB2DQnMcmpMUe+PGjbWyN4lPY19UP/HGvzpu1hgPT39QLURt8ZL9qP6g7Xrno5P4tN2BtlXxzlknVuo5evqJahSqZ3kT9HTbgQce2Nhn7ty5tbL2/yOPPNKoc+utt9bKbfEo0NSitF1Pm1ItZ8aMGa11tJ+8flFtMCepevVeyFkRsyviySUIgk4I5xIEQSeEcwmCoBPCuQRB0Ak9D6Jrm1jVNmmvv7+/UUcDjbygJ92m7XirP2rbGszmiWu6LUdgUwFUhcvHHnusUUeDzrwMfWq/F1yoqL3at95kSLVFJ+15mdw0ONJb00pFa+3bRYsWNeqoAK19qeI/NCdEzp8/v1b2fkRQAfctb3lLreyJ5dpPa9asaeyzadOmWllFYM/+6jXxJu3uLOLJJQiCTgjnEgRBJ4RzCYKgE3qquUyYMKGWPMkbv+tYVYOevCVhVU/xxruatEk1Fy9jvQaUqS5w9913N+po0qPly5fXyp62o8Fumjl++vTpjTo6ac+bKLdy5cpaecGCBY19FNVutA88/UHH+WqLahjQ7H9Pm1L9RMveZMd9960vW67aiNeXjz/+eK2s94K3MqKe80MPPVQr6/0GzcRVais07zH9jHiBd1X7vSRVO4t4cgmCoBPCuQRB0AnhXIIg6ISex7lUx9Ze3IVqLKqneDEsqgtoImRoTwh98803t9ZRvcebeHnwwQfXyqqneGNxnZio2oKnM+k+3gp/69atq5VVJ7jnnnsadVTLUZ3Ai81QXUknFGoMCDT1Kk/L8c6pipdISbWbthUwvba9iaKKxuloDI6n+6me5U0CbUsu5p1zdeJlL5NLxZNLEASdEM4lCIJOCOcSBEEnhHMJgqATeiroPvPMM7VMYZ7o1Zax3puYpYFSXnCSosFIhx12WGOfWbNm1coqHHvZxlQw1Ilm3iRET6Su4gWY6cqBS5cubeyjwWy6MsHHP/7xRh0VUVXc9ALx2iYLanY4aIruXiY67Re1JSe4TUXUnIl9+qPC7NmzG/vodfbuhTbbPOFY+0X70rsXqrZ4wvjOIp5cgiDohHAuQRB0wpCdi5nNN7Ofm9kKM7vXzM4ut081s6Vm9kD5f5+RNzcIgrHCcDSXl4FPppR+ZWZTgNvMbCnwEeC6lNISMzsfOB84b7AD7bbbbuy///47yt44Vbfts0/dZ3kr5mkwnqdhaMCSBkFpO9CeKMkLyFKNSAPtVLfxtukxPDQB08KFCxv7qOai+3i26HHbkkdBs/91oqIXLKk6hhc8ptdIAxC9TP6q4+m94CUr0+PqMTwdQ/ulbdVJzxbv/lEtTcsaGAl1LactGVuXDPnJJaXUn1L6Vfl6K7ACmAucAlxS7nYJcOoI2RgEwRjkNWkuZrY/cBRwMzAzpdQPhQMC2n+iCYJg3DJs52Jmk4ErgXNSSs3kJwPXO8vMlpnZMi9nShAE44NhORczm0jhWP4xpfSjcvN6M5tdvj8baGbuAVJKF6WUFqeUFnsTCoMgGB8MWdC1QsH7NrAipfS1yltXA2cAS8r/V7Udq6+vrzZL2BPxdAZwTlCQzuT1AqU0c78e18tQr0FOKsh5tqmAq+2qQOe1k4OKvp6AqJnoVLTOmVWsAqF3ziqI6jXULP6Qlz1Q7w8VoL2sclpHz8f7EaEt4513P+n9ov3i9ZNuywnC9O7LwWzpZRDdcH4tOhb4MHC3md1RbvsshVO5wszOBNYA7xsRC4MgGJMM2bmklH4BDJQk4u2vzZwgCMYLEaEbBEEn9HTiYkqpNtb2srJpwJVm+FINA5pjYk9LUF0jJ/u86g2ql3grLmrbqo14QU5tkzW9sbkGE3pjbdU+VHPxgrjaztmrowFkqqd4AYpax/slUffR/vbuH70/9Lp6+pb2r56jF5Sp2pra5gX46b3h3Quqsei97WUlrNri3ZM7i3hyCYKgE8K5BEHQCeFcgiDohJ5rLlVNJUd/0PGwNwlOx+vehDwdA+s+Xh2vrSqe/qD250wka9ODdBU+aJ6zN6FTtQ7VcrzxuZ6zaguenqXb9Hy8VRI0EZdni/ZDmx7h7aPX1YunUXQfT49TtN+GU8fD6zulqglFsqggCMYd4VyCIOiEcC5BEHRCOJcgCDqh58u5tgmcbaKdJ7zuvffetbInpqnomDNxUUVGPa4X0NS2nKgn4mnbOZPVtB+9oC3dR8VBT/xTMVZFYE8QVeFYj+tdj82bN9fKXkCcrurQJlBD8xw1AM4TpLWftA+866z3oU7O1Kz9kCf2648Eev979081Y18E0QVBMO4I5xIEQSeEcwmCoBN6rrlUx53emFPHlKoleAmmciYhtk3AyxmrDkc/US3B0znUftU1vERQ2nfe5Dq1bzgBZKpreP2vAXyqWXg6mWoJXqCgnrdeV10dEpoTF/V8vOvcdo95wZKq3QxnImxOgjK1TVcKhbom5GlKO4t4cgmCoBPCuQRB0AnhXIIg6ISeT1ysjjO9MaeOGXXM7I35c3SBNi3Ei5nQtnVc7ekcbXE8OfEoGjPh6RGqc3hjbT1nPUdP/9FzypmApzqHahRe3+o5VxO3b0ft37ChvsCEl0Tr8ccfr5X1GuoqjtC8F1SX8bSqtomKXh3tF29SYs4Kl0q1rdBcgiAYd4RzCYKgE8K5BEHQCeFcgiDohJ4H0VWFME98UiFMhTMvoEnZY489Gts0OCknQ5wKlSoUe+KsBoepaOdluddgMRVaPUFXxUxP3NR+aOtbr209Z50kCs1z1n7zBN01a9bUyp79uvyvCrqeoK7XRK/zqlWrGnX0nHSionedFbXfywyofeutZKH19LheX46WFRfjySUIgk4I5xIEQSeEcwmCoBN6qrls27atNj73xsxenSo6ARGa40wvK7zqCxo45ekPuuJfWyIlaI6Ztbxp06ZGnbZJk975qA7g6VfaVxqUljOJT3UbT3Pp7++vlXOy2us5eRPy2laI9PqlTTPy7h+9znqNvAA/7Rdt1+tbbccLIlV79T71NLtqv4TmEgTBuCOcSxAEnRDOJQiCTuh5nEsVLwmS/vav49KcSWTeuFo1iRxdoA1v/KuJmTdu3Fgra+wGNM9JdSavjuoPXr/oBEiNLfFiMebPn18rH3DAAbWy6gbQ1D7U/rVr1zbqqF7lxblo/2rCbm9SpdZRbcTTplTnUL1k3bp1jTpqf1tM1ED2KqqZaL94ycLbYsd2FvHkEgRBJ4RzCYKgE8K5BEHQCUN2Lma2u5ndYmZ3mtm9ZvalcvtUM1tqZg+U//dpO1YQBOOX4Qi6LwBvSyk9bWYTgV+Y2bXAe4HrUkpLzOx84HzgvMEOZGY1scwL+FEBN2eCoR7Hy/DVhie2qUiqWc68IK7HHnusVtYALE+4VBFYgwu9YD3Fs2X69OmD2uIJ6itXrqyVb7vttlr5sMMOa9RRe1VI9oIlNRjPEyJVvNRrlLN6hLbtBbdpHb1GGswH7YF33mRHvU+966pt6cqUXhBjtR88IXlnMeQnl1Sw/S6cWP4l4BTgknL7JcCpI2FgEARjk2FpLmbWZ2Z3ABuApSmlm4GZKaV+gPL/vgPUPcvMlpnZMu+nzyAIxgfDci4ppVdSSm8G5gFHm1nz2XjguhellBanlBZ78SdBEIwPXlMQXUppi5ldD5wArDez2SmlfjObTfFUMyhmVpv85wV+tWXcz0Ene3nHzQnOU01Cy96TmI6ZdbXBnOA91Qk8bUqP6yUeUh1DNYtZs2a12qJagmoy0AxUU63Es011Jk9zUd1Ck2Z5mktbQizVg2B410i1G7VFJ7lC3uqhuq1tBUmo33M5K4d2xXB+LZphZnuXrycBxwP3AVcDZ5S7nQFcNUI2BkEwBhmOW5sNXGJmfRTO6YqU0jVmdiNwhZmdCawB3jeCdgZBMMYYsnNJKd0FHOVs3wS8fSSMCoJg7BMRukEQdMKomhXtibUqhKmY6YmbKqZ5gpxuUwHRE9dUzNR2Zs6c2aijQvGWLVtqZS+4qi1DXE5glCdu6nFyZuXOnTu3VlZx3LO/bflTL8CvbSY4NK+Z3htecJ7eH7qPF2Cp7aiImrNKhd7L3n2qs9s9cVavUc45V9uOWdFBEIw7wrkEQdAJ4VyCIOiEnmsu1TGhp43omFEDnDx07JqTAV3H3jmrGuqkMQ0Eg6YmobZ4dRTVMLxx9HDG1mqbl31e+1In12k2OGj2pdrvrYCpdXKumV4PT6dRjUvP0dOvdB9d2XHatGmNOnpO2reeNqXbPM1FJ0Tm6GbVcwrNJQiCcUc4lyAIOiGcSxAEndBTzSWlVBvfeuPfNo3F02naVgyA5vhWx/xeJv/99tuvVtYYA2/MrJqKF+Oh6DnpONtLKqT6g9eXOdqN0rZCoTcxTjUJ1a88nUlt8WxTTUUnjnqTELW/tawrIEBzouXChQtrZe+c2yaO5sTGeDEreu/qveFpLtV9cpKrdUU8uQRB0AnhXIIg6IRwLkEQdEI4lyAIOqHngm5VfPIELRWkcibtqQjmBTDpcXVCnifOtgXAeeJaW4Z6TxzUbV6/tLWTI9a2TZCE9mAwbzlXDVzTsieWaxa/HPsPP/zwWtnL9qbneOONN9bKc+bMadRZvXp1raz3hjfBVq+r3j85gY+e/W1L43r3dvW4Yyr7fxAEQQ7hXIIg6IRwLkEQdEJPNZdt27bVxuxeQJwGJ2kAmaeN6D7eJDgdi+rEM09L0OOoRuElHtIV8vr7+2vldevWNeocffTRtfK8efNqZW+VPd1n1apVjX10TK8T8g455JBGHc3ur6sZeAFxeh3f+MY31soHHXRQo87y5ctb99H+1evs9aWuiqkBftoH0JyMqRqLt3qB3qeqgeVk4c/RHPV+9zSV6j4xcTEIgnFHOJcgCDohnEsQBJ3Q8ziXahyCN0lR4xR0H2/MqWNzb8VF1R90LOslBGpLguSNmXWy47771pfQPvjggxt1VEtQXcOLbdBJe14SJz0nPY5XR/tbk0p72pROVMyZrDl9+vRa2dNyVPNav379oMeA5v2juoxOfgTYf//9a2W9xzxtUM9RtQ5Pp9HzydFHdB/v3q7qNKG5BEEw7gjnEgRBJ4RzCYKgE8K5BEHQCT0VdF955ZVakJknVGoA0/PPP18re5O9dJsnwLWJdF6G+raM9J4gqsfV89GsZ9AMvFPh2Aui8ybTKY899tigba9du7b1uCrgeoKu2q8isCfWTp06tVZWsRbagwAffPDBRh09J72uKrDnkLPKZ45Yq/t4QZgqOOsPD96PIFVxOQTdIAjGHeFcgiDohHAuQRB0Qk81lxdffLE2JtZJcdAcU7ZlxofmONPL/q/jXc1q7wXnaSCU7uO1o2iiJNWQwNdUqtx///2Nbdovnpag9uqkPi97vvaljvk9+1Ub0eN6elZOoJ1qNdqOp78tWrSoVs5ZscFL+lXF01zUNg1ua1sZ0bPNs08/I56msnHjxkHb3VnEk0sQBJ0QziUIgk4YtnMxsz4zu93MrinLU81sqZk9UP5vjnGCIHjd8Fo0l7OBFcD2IIbzgetSSkvM7PyyfN5gB3jyySf56U9/uqPsaQ065sxJKp2zep+Om1Wz8Ma/GvOh+3ixJtqO6g3e6oltq+x58TQaI+RpRm2r7+mEPWiek9qvMSzQHOdrrIanWeg5e/uovpOzSqZeI70XcmzR88lZMVKvmacpqf1ezJBqN21JqQAeffTRHa9zdMCuGNaTi5nNA94FfKuy+RTgkvL1JcCpr8myIAjGNMMdFn0d+AxQ/SqcmVLqByj/u6GPZnaWmS0zs2W9XMc2CIJuGbJzMbOTgQ0ppduG02BK6aKU0uKU0mLvZ8AgCMYHw9FcjgXeY2YnAbsDe5nZZcB6M5udUuo3s9lAM/NxEASvG4bsXFJKFwAXAJjZccCnUkofMrO/As4AlpT/r2o71ssvv8ymTZt2lH/wgx809nn/+99fK6vo6GUSU2HYEx1VTFPhzxN09bhtExmhfcVIT5BrExQ9cVDb8QLK2p4UZ86c2dimkxu17ZwgLT1nzVTn7ePZ37Z6Zdvqg9AUTT2xX0VT/dHA63+1V231gg1zVtL0JiZW8QIf77rrrh2vvcmQO4uRHJcsAd5hZg8A7yjLQRC8TnlN4f8ppeuB68vXm4C3v3aTgiAYD4SiGgRBJ/R04iLUx82efnLttdfWyieccEKtfMABBzTq6CRETxtpS2DkjcV1Hx2Le/qDbmsLtgI/AK6Kp0dosFtOQqOcVSbbNJUcbUT7zdMaVGfyjqv1tO9yVsnUshf42DYhNUdn0jpeMJteDy9xmE6W3bJlS628YsWKRp2HH354x+ucCaFdEU8uQRB0QjiXIAg6IZxLEASd0FPNZZdddqklZn7Tm97U2Ecn6a1cubJW9jQLHad6yYl0Hx3je1MTtC2tk5MM2bNX0bY1RsKL51AdwNtH41y0na1btzbqqM6hEy29c9Z21Bavb/U4XnyGairajjeJVe339lH0GqltOf2v2o6nM+k+mqQcmtdEE5ffc889jTrHHHPMjtd33nln4/2dRTy5BEHQCeFcgiDohHAuQRB0QjiXIAg6oaeC7qRJkzjyyCN3lBcsWNDYRwPiqlm2wA9o6u/vr5VVvIWmMKnBVN5xVYDTwChvYqCKl1onR9zUbGQ5AXKegKhCZE6WMg3a0gAzvT7QFE21X3Ky5+cEqqnQ7YnlbZM1cwIfVbj3+q1toqJn27x582plr19UwL3hhhtq5eOPP75Rp7qyZo6A3RXx5BIEQSeEcwmCoBPCuQRB0Ak91VwmTpzI9OnTd5RnzZrV2Ee1Aw2umj17dqNONQEVwLRp0xr7qMZStQP8rPxqi469vYAy3aaahae56Nhbx81enbYJktAMQvMSGCmqWaj+4I3pdR+dkOoFNWp/D2fCndcver9o8qWca5aTSEy3qS3eCph6PTZsaCZvvPXWW2vl0047rVb2Vildvnz5jtc5QZtdEU8uQRB0QjiXIAg6IZxLEASdEM4lCIJO6Kmg29fXV8uo7wllt99+e6181FFH1cqeiHfooYfWyhpUB00xU4/jLZmqYqyKZV4mdg0yG46g2yYWQvusXG+bl4WtDbXfy5qn7WgQYE4QWls2Pg/v/lEBN0fg1H20vzdv3tyoo+d84IEH1speMF812A1g6dKljX0uvPDCWll/wLj//vsbdapCcS8XHownlyAIOiGcSxAEnRDOJQiCTuip5jJhwoTapEJvLL548eJa+fTTT6+VvUxbGzdurJV1/AvNDF/VwCNoTiqDZsBSTvZ8bUcnUXrBeooGdXl1dEzvBaHlrBCg6GRH1TA8WzSITnUnDXKEPF1JJzfq/eIF9LUFF3oZ77TvVGPx2jn44INrZdVt7rvvvkYd1Vy++tWvNvbR/te2vez/Odd1ZxBPLkEQdEI4lyAIOiGcSxAEndBTzcXMamP2devWNfY58cQTa2WNmXjnO9/ZqPO9732vVva0kGp8jVf2JvWpfao/qG0eOjnNW1lQj6vjbm9MrWNx77g5SZsU1VRyVjzQfTT+x4v5UPtzEj+pLuNpIVpHdRtPm1LNTo+73377Neqotvbggw/Wyp42de6559bKOnkWmlqU6j9PPfVUo061/3NWpOiKeHIJgqATwrkEQdAJ4VyCIOiEcC5BEHRCTwXdlFJNsPIExiOOOKJRp4oXkPXRj360Vr788ssb+6hopwFy3tKaKg6q6KiZ8j1799prr1rZmzyotukkPi/7mAaq5Qh5elyvTttqBV4Qmoqbeo5esGRb9jpo9reKpDmrIqigu2bNmkYdFWz1XvDE/gceeKBWXrhwYa2swZ/QPJ+c1SPuuuuuWtlbvSAE3SAIxjXhXIIg6IRwLkEQdIL1cpKTmW0EVgPTgcd7ZsjQGUv2jiVbYWzZOxZsXZBSamY+2wn01LnsMMJsWUppcfueo4OxZO9YshXGlr1jydZeEMOiIAg6IZxLEASdMFqcy0W9NmCIjCV7x5KtMLbsHUu27nRGheYSBMH4Y7Q8uQRBMM4I5xIEQSf03LmY2Qlm9mszW2lm5/fanipm9h0z22Bm91S2TTWzpWb2QPm/OdGnB5jZfDP7uZmtMLN7zezscvtotXd3M7vFzO4s7f1SuX1U2gtgZn1mdruZXVOWR62to4GeOhcz6wP+FjgRWAScbmaLemmTcDFwgmw7H7gupbQQuK4sjwZeBj6ZUnojcAzwh2VfjlZ7XwDellI6EngzcIKZHcPotRfgbKCabn8029pzev3kcjSwMqX0UErpReBy4JQe27SDlNINgK7RegpwSfn6EuDUnWnTQKSU+lNKvypfb6X4EMxl9NqbUkrbpz5PLP8So9ReM5sHvAv4VmXzqLR1tNBr5zIXWFspP1JuG83MTCn1Q/GBBvbtsT0NzGx/4CjgZkaxveUw4w5gA7A0pTSa7f068BmgmgNhtNo6Kui1c/GSTcRv468BM5sMXAmck1JqZm8eRaSUXkkpvRmYBxxtZof12CQXMzsZ2JBSuq3Xtowleu1cHgHmV8rzgEd7ZEsu681sNkD5f0PL/jsNM5tI4Vj+MaX0o3LzqLV3OymlLcD1FPrWaLT3WOA9ZvYwxdD9bWZ2GaPT1lFDr53LrcBCMzvAzHYFPgBc3WOb2rgaOKN8fQZwVQ9t2YEVKce+DaxIKX2t8tZotXeGme1dvp4EHA/cxyi0N6V0QUppXkppf4p79F9TSh9iFNo6qkgp9fQPOAm4H3gQ+Fyv7RHbvg/0Ay9RPGWdCUyj+GXggfL/1F7bWdr6Vooh5V3AHeXfSaPY3iOA20t77wE+X24flfZW7D4OuGYs2Nrrvwj/D4KgE3o9LAqCYJwSziUIgk4I5xIEQSeEcwmCoBPCuQRB0AnhXIIg6IRwLkEQdML/By8K6RsDb6yJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.title(\"label : %s, confidence : %2.f%%\" % (labels[idx], confidence))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.6.C Apply to Video frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_ped(img, label, x0, y0, xt, yt, color=(255,127,0), text_color=(255,255,255)):\n",
    "\n",
    "    (w, h), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "    cv2.rectangle(img,\n",
    "                  (x0, y0 + baseline),  \n",
    "                  (max(xt, x0 + w), yt), \n",
    "                  color, \n",
    "                  2)\n",
    "    cv2.rectangle(img,\n",
    "                  (x0, y0 - h),  \n",
    "                  (x0 + w, y0 + baseline), \n",
    "                  color, \n",
    "                  -1)  \n",
    "    cv2.putText(img, \n",
    "                label, \n",
    "                (x0, y0),                   \n",
    "                cv2.FONT_HERSHEY_SIMPLEX,     \n",
    "                0.5,                          \n",
    "                text_color,                \n",
    "                1,\n",
    "                cv2.LINE_AA) \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- load Haar Cascade model -------------\n",
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "# --------- load tensorflow optimized model ---------\n",
    "facerecognition_model = \"frozen_graph.pb\"\n",
    "net = cv2.dnn.readNet(facerecognition_model)\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
    "layerOutput = net.getUnconnectedOutLayersNames()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened() :\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
    "        for (x, y, w, h) in faces:\n",
    "            \n",
    "            face_img = gray[y:y+h, x:x+w]\n",
    "            face_img = cv2.resize(face_img, (50, 50))\n",
    "            \n",
    "            blob = cv2.dnn.blobFromImage(face_img, 1.0, (50, 50), (0, 0, 0), swapRB=True, crop=False)\n",
    "            net.setInput(blob)\n",
    "            output = net.forward(layerOutput)\n",
    "            idx = output[0].argmax(axis=1)[0]\n",
    "            confidence = output[0].max(axis=1)[0]*100\n",
    "            \n",
    "            if confidence > 70:\n",
    "                label_text = \"%s (%.2f %%)\" % (labels[idx], confidence)\n",
    "            else :\n",
    "                label_text = \"N/A\"\n",
    "            frame = draw_ped(frame, label_text, x, y, x + w, y + h, color=(0,255,255), text_color=(50,50,50))\n",
    "       \n",
    "        cv2.imshow('Face Recognition', frame)\n",
    "    else :\n",
    "        break\n",
    "    if cv2.waitKey(10) == ord('q'):\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Flask & OpenCV - MJPEG Stream\n",
    "- **MJPEG stream** working using **Server Push** mechanism.\n",
    "- Server push is a simple way of **sending file updates to a browser**.\n",
    "- Most major browsers, and some minor browsers support it for images, with one important exception.\n",
    "- How it works ?\n",
    "    - Browser requests a file (typically an image)\n",
    "    - The server responds with a **multipart mixed-replace** content type header, </br>\n",
    "        ```\n",
    "        Content-Type: multipart/x-mixed-replace;boundary=frame\n",
    "        ```</br>\n",
    "    - Image from the server is always continue sending image data to browser (client)\n",
    "    - Image is sender as byte format :</br>\n",
    "        ```\n",
    "        --frame\n",
    "        Content-Type: image/jpeg\n",
    "        6A3D 5671 55CA 66B7\n",
    "        611A A10B 1408 246A\n",
    "        ....\n",
    "        ....\n",
    "        ```</br>\n",
    "<img src=\"resource/server-toclient.png\" style=\"width:300px\"></img></br>\n",
    "source : [http://www.howtocreate.co.uk/Server Push](http://www.howtocreate.co.uk/php/serverpushdemo.php)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flask\n",
      "  Using cached Flask-1.1.2-py2.py3-none-any.whl (94 kB)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in c:\\users\\yunus\\anaconda3\\envs\\cvdl\\lib\\site-packages (from flask) (0.16.1)\n",
      "Collecting click>=5.1\n",
      "  Using cached click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting itsdangerous>=0.24\n",
      "  Using cached itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting Jinja2>=2.10.1\n",
      "  Using cached Jinja2-2.11.2-py2.py3-none-any.whl (125 kB)\n",
      "Collecting MarkupSafe>=0.23\n",
      "  Using cached MarkupSafe-1.1.1-cp36-cp36m-win_amd64.whl (16 kB)\n",
      "Installing collected packages: MarkupSafe, Jinja2, itsdangerous, click, flask\n",
      "Successfully installed Jinja2-2.11.2 MarkupSafe-1.1.1 click-7.1.2 flask-1.1.2 itsdangerous-1.1.0\n"
     ]
    }
   ],
   "source": [
    "! pip install flask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Basic Flask : Route & Template\n",
    "    - run `python 1_Basic_Flask/app.py` in console (cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Flask & OpenCV : mjpeg stream\n",
    "    - run `python 2_Mjpeg_Stream/app.py` in console (cmd) </br>\n",
    "![](resource/opencv_dnn_04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Facedetection Mjpeg Stream\n",
    "    - run `python 3_Facedetect_Mjpeg_Stream/app.py` in console (cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Facerecognition Mjpeg Stream\n",
    "    - run `python 4_Facerecognition_Mjpeg_Stream/app.py` in console (cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Modular Version Facerecognition\n",
    "    - create `labels.csv` to hold all labels data presitent\n",
    "    - run `python 5_Modular_Version/app.py` on console (cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save labels to CSV file\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "labels = ['Ariel_Sharon',\n",
    "          'Colin_Powell',\n",
    "          'Donald_Rumsfeld',\n",
    "          'George_W_Bush',\n",
    "          'Gerhard_Schroeder',\n",
    "          'Hugo_Chavez',\n",
    "          'Jacques_Chirac',\n",
    "          'Jean_Chretien',\n",
    "          'John_Ashcroft',\n",
    "          'Junichiro_Koizumi',\n",
    "          'Serena_Williams',\n",
    "          'Tony_Blair',\n",
    "          'Yunus']\n",
    "\n",
    "labels_df = pd.DataFrame(labels)\n",
    "\n",
    "labels_df.to_csv(\"5_Modular_Version/labels.csv\",  index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:CPU_ENV]",
   "language": "python",
   "name": "conda-env-CPU_ENV-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
