{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pertemuan 9\n",
    "- Intro OpenCV DNN\n",
    "- Convert Keras Model (.h5) to Tensorflow (.pb)\n",
    "- Optimize Model (.pb) using Tensorboard & Tensorflow\n",
    "- Stream Video OpenCV DNN to Flask \n",
    "    - Basic Flask Route & Templating\n",
    "    - Flask - OpenCV MJPEG Stream\n",
    "    - Flask - OpenCV Facedetection MJPEG Stream\n",
    "    - Flask - OpenCV Facerecognition MJPEG Stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 OpenCV DNN\n",
    "\n",
    "- Compatibility : > OpenCV 3.3\n",
    "- Wiki : https://github.com/opencv/opencv/wiki/Deep-Learning-in-OpenCV\n",
    "- Since OpenCV 3.1 there is DNN module in the library that implements **forward pass** (inferencing) with deep networks, **pre-trained**using some popular deep learning frameworks.\n",
    "- The supported frameworks:\n",
    "    - Caffe\n",
    "    - TensorFlow\n",
    "    - Torch\n",
    "    - Darknet (Yolo)\n",
    "    - Models in ONNX format </br>\n",
    "    \n",
    "#### 1.1 OpenCV DNN workflow\n",
    "![](resource/opencv_dnn_01.png)\n",
    "\n",
    "#### 1.2 Model Preparation for OpenCV DNN\n",
    "![](resource/opencv_dnn_03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Convert Keras (.h5) to Tensorflow (.pb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n",
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "print(keras.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- load keras model (.h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model-cnn-facerecognition.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- save model as a folder `'tf_model/'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\yunus\\Anaconda3\\envs\\CPU_ENV\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: tf_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"tf_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 6622-681D\n",
      "\n",
      " Directory of C:\\Users\\yunus\\Documents\\GitHub\\Materi-Training\\C. Facerecognition\\pertemuan_9\\tf_model\n",
      "\n",
      "12/30/2020  07:55 PM    <DIR>          .\n",
      "12/30/2020  07:55 PM    <DIR>          ..\n",
      "12/28/2020  11:42 PM    <DIR>          assets\n",
      "12/30/2020  07:55 PM           204,089 saved_model.pb\n",
      "12/30/2020  07:55 PM    <DIR>          variables\n",
      "               1 File(s)        204,089 bytes\n",
      "               4 Dir(s)  252,846,452,736 bytes free\n"
     ]
    }
   ],
   "source": [
    "! dir tf_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 View Input & Output model graph (.pb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "importer = tf.saved_model.load(\"tf_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer = importer.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_5_input Placeholder\n",
      "statefulpartitionedcall_args_7 Const\n",
      "statefulpartitionedcall_args_10 Const\n",
      "statefulpartitionedcall_args_1 Const\n",
      "statefulpartitionedcall_args_8 Const\n",
      "statefulpartitionedcall_args_12 Const\n",
      "statefulpartitionedcall_args_9 Const\n",
      "statefulpartitionedcall_args_14 Const\n",
      "statefulpartitionedcall_args_11 Const\n",
      "statefulpartitionedcall_args_6 Const\n",
      "statefulpartitionedcall_args_3 Const\n",
      "statefulpartitionedcall_args_2 Const\n",
      "statefulpartitionedcall_args_4 Const\n",
      "statefulpartitionedcall_args_13 Const\n",
      "statefulpartitionedcall_args_5 Const\n",
      "Func/StatefulPartitionedCall/input_control_node/_0 NoOp\n",
      "Func/StatefulPartitionedCall/input/_1 Identity\n",
      "Func/StatefulPartitionedCall/input/_2 Identity\n",
      "StatefulPartitionedCall/sequential_3/conv2d_5/Conv2D/ReadVariableOp Identity\n",
      "StatefulPartitionedCall/sequential_3/conv2d_5/Conv2D Conv2D\n",
      "Func/StatefulPartitionedCall/input/_3 Identity\n",
      "StatefulPartitionedCall/sequential_3/conv2d_5/BiasAdd/ReadVariableOp Identity\n",
      "StatefulPartitionedCall/sequential_3/conv2d_5/BiasAdd BiasAdd\n",
      "StatefulPartitionedCall/sequential_3/conv2d_5/Relu Relu\n",
      "Func/StatefulPartitionedCall/input/_4 Identity\n",
      "StatefulPartitionedCall/sequential_3/conv2d_6/Conv2D/ReadVariableOp Identity\n",
      "StatefulPartitionedCall/sequential_3/conv2d_6/Conv2D Conv2D\n",
      "Func/StatefulPartitionedCall/input/_5 Identity\n",
      "StatefulPartitionedCall/sequential_3/conv2d_6/BiasAdd/ReadVariableOp Identity\n",
      "StatefulPartitionedCall/sequential_3/conv2d_6/BiasAdd BiasAdd\n",
      "StatefulPartitionedCall/sequential_3/conv2d_6/Relu Relu\n",
      "StatefulPartitionedCall/sequential_3/max_pooling2d_3/MaxPool MaxPool\n",
      "Func/StatefulPartitionedCall/input/_6 Identity\n",
      "StatefulPartitionedCall/sequential_3/conv2d_7/Conv2D/ReadVariableOp Identity\n",
      "StatefulPartitionedCall/sequential_3/conv2d_7/Conv2D Conv2D\n",
      "Func/StatefulPartitionedCall/input/_7 Identity\n",
      "StatefulPartitionedCall/sequential_3/conv2d_7/BiasAdd/ReadVariableOp Identity\n",
      "StatefulPartitionedCall/sequential_3/conv2d_7/BiasAdd BiasAdd\n",
      "StatefulPartitionedCall/sequential_3/conv2d_7/Relu Relu\n",
      "Func/StatefulPartitionedCall/input/_8 Identity\n",
      "StatefulPartitionedCall/sequential_3/conv2d_8/Conv2D/ReadVariableOp Identity\n",
      "StatefulPartitionedCall/sequential_3/conv2d_8/Conv2D Conv2D\n",
      "Func/StatefulPartitionedCall/input/_9 Identity\n",
      "StatefulPartitionedCall/sequential_3/conv2d_8/BiasAdd/ReadVariableOp Identity\n",
      "StatefulPartitionedCall/sequential_3/conv2d_8/BiasAdd BiasAdd\n",
      "StatefulPartitionedCall/sequential_3/conv2d_8/Relu Relu\n",
      "StatefulPartitionedCall/sequential_3/max_pooling2d_4/MaxPool MaxPool\n",
      "StatefulPartitionedCall/sequential_3/flatten_2/Const Const\n",
      "StatefulPartitionedCall/sequential_3/flatten_2/Reshape Reshape\n",
      "Func/StatefulPartitionedCall/input/_10 Identity\n",
      "StatefulPartitionedCall/sequential_3/dense_8/MatMul/ReadVariableOp Identity\n",
      "StatefulPartitionedCall/sequential_3/dense_8/MatMul MatMul\n",
      "Func/StatefulPartitionedCall/input/_11 Identity\n",
      "StatefulPartitionedCall/sequential_3/dense_8/BiasAdd/ReadVariableOp Identity\n",
      "StatefulPartitionedCall/sequential_3/dense_8/BiasAdd BiasAdd\n",
      "StatefulPartitionedCall/sequential_3/dense_8/Relu Relu\n",
      "Func/StatefulPartitionedCall/input/_12 Identity\n",
      "StatefulPartitionedCall/sequential_3/dense_9/MatMul/ReadVariableOp Identity\n",
      "StatefulPartitionedCall/sequential_3/dense_9/MatMul MatMul\n",
      "Func/StatefulPartitionedCall/input/_13 Identity\n",
      "StatefulPartitionedCall/sequential_3/dense_9/BiasAdd/ReadVariableOp Identity\n",
      "StatefulPartitionedCall/sequential_3/dense_9/BiasAdd BiasAdd\n",
      "StatefulPartitionedCall/sequential_3/dense_9/Relu Relu\n",
      "Func/StatefulPartitionedCall/input/_14 Identity\n",
      "StatefulPartitionedCall/sequential_3/dense_10/MatMul/ReadVariableOp Identity\n",
      "StatefulPartitionedCall/sequential_3/dense_10/MatMul MatMul\n",
      "Func/StatefulPartitionedCall/input/_15 Identity\n",
      "StatefulPartitionedCall/sequential_3/dense_10/BiasAdd/ReadVariableOp Identity\n",
      "StatefulPartitionedCall/sequential_3/dense_10/BiasAdd BiasAdd\n",
      "StatefulPartitionedCall/sequential_3/activation_3/Softmax Softmax\n",
      "StatefulPartitionedCall/Identity Identity\n",
      "Func/StatefulPartitionedCall/output/_16 Identity\n",
      "Func/StatefulPartitionedCall/output_control_node/_17 NoOp\n",
      "Identity Identity\n"
     ]
    }
   ],
   "source": [
    "f = convert_variables_to_constants_v2(infer)\n",
    "graph_def = f.graph.as_graph_def()\n",
    "\n",
    "for n in graph_def.node:\n",
    "    print( n.name, n.op)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 Convert Model (.pb) to frozen model graph (.pb) & Optimize for Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.tools import optimize_for_inference_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\yunus\\Anaconda3\\envs\\CPU_ENV\\lib\\site-packages\\tensorflow_core\\python\\tools\\strip_unused_lib.py:88: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "WARNING:tensorflow:From C:\\Users\\yunus\\Anaconda3\\envs\\CPU_ENV\\lib\\site-packages\\tensorflow_core\\python\\tools\\optimize_for_inference_lib.py:113: remove_training_nodes (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.remove_training_nodes`\n"
     ]
    }
   ],
   "source": [
    "f = convert_variables_to_constants_v2(infer)\n",
    "graph_def = f.graph.as_graph_def()\n",
    "\n",
    "graph_def = optimize_for_inference_lib.optimize_for_inference(graph_def,\n",
    "                                                              ['conv2d_5_input'],\n",
    "                                                              ['Identity'],\n",
    "                                                              tf.float32.as_datatype_enum)\n",
    "\n",
    "with tf.io.gfile.GFile('frozen_graph.pb', 'wb') as f:\n",
    "    f.write(graph_def.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6 Inference model using OpenCV DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.5.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.6.A Load Model using OpenCV DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Ariel_Sharon',\n",
    "          'Colin_Powell',\n",
    "          'Donald_Rumsfeld',\n",
    "          'George_W_Bush',\n",
    "          'Gerhard_Schroeder',\n",
    "          'Hugo_Chavez',\n",
    "          'Jacques_Chirac',\n",
    "          'Jean_Chretien',\n",
    "          'John_Ashcroft',\n",
    "          'Junichiro_Koizumi',\n",
    "          'Serena_Williams',\n",
    "          'Tony_Blair',\n",
    "          'Yunus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "facerecognition_model = \"frozen_graph.pb\"\n",
    "net = cv2.dnn.readNet(facerecognition_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `cv2.dnn.readNet(model, configration)` \n",
    "- where :\n",
    "    - `model` :\n",
    "        - `*.caffemodel` (Caffe, http://caffe.berkeleyvision.org/)\n",
    "        - `*.pb` (TensorFlow, https://www.tensorflow.org/)\n",
    "        - `*.t7` | `*.net` (Torch, http://torch.ch/)\n",
    "        - `*.weights` (Darknet, https://pjreddie.com/darknet/)\n",
    "        - `*.bin` (DLDT, https://software.intel.com/openvino-toolkit)\n",
    "    - `configuration` :\n",
    "        - `*.prototxt` (Caffe, http://caffe.berkeleyvision.org/)\n",
    "        - `*.pbtxt` (TensorFlow, https://www.tensorflow.org/)\n",
    "        - `*.cfg` (Darknet, https://pjreddie.com/darknet/)\n",
    "        - `*.xml` (DLDT, https://software.intel.com/openvino-toolkit)\n",
    "- This function automatically detects an origin framework of trained model and calls an appropriate function such \n",
    "    - `cv2.dnn.readNetFromCaffe` \n",
    "    - `cv2.dnn.readNetFromTensorflow`\n",
    "    - `cv2.dnn.readNetFromTorch` \n",
    "    - `cv2.dnn.readNetFromDarknet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set backend & target OpenCV DNN\n",
    "\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "layerOutput = net.getUnconnectedOutLayersNames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['StatefulPartitionedCall/sequential_3/activation_3/Softmax']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layerOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.6.B Predict Image Face using OpenCV DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face(img):\n",
    "    img = img[70:195,78:172]\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.resize(img, (50, 50))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Colin_Powell_0008.jpg',\n",
       " 'Donald_Rumsfeld_0009.jpg',\n",
       " 'George_W_Bush_0016.jpg',\n",
       " 'Gerhard_Schroeder_0012.jpg',\n",
       " 'Tony_Blair_0012.jpg']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"test_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"test_data/Colin_Powell_0008.jpg\")\n",
    "\n",
    "img = detect_face(img)\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(img, 1.0, (50, 50), (0, 0, 0), swapRB=True, crop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50, 50), (1, 1, 50, 50))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape, blob.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cv2.dnn.blobFromImage(img,scalefactor = 1.0,output_size, mean_channel,swapRB = false,crop = false,ddepth = cv2.CV_32F)`\n",
    "\n",
    "- `image`\tinput image (with 1-, 3- or 4-channels).\n",
    "- `size`\tspatial size for output image\n",
    "- `mean`\tscalar with mean values which are subtracted from channels. Values are intended to be in (mean-R, mean-G, mean-B) order if image has BGR ordering and swapRB is true.\n",
    "- `scalefactor`\tmultiplier for image values.\n",
    "- `swapRB`\tflag which indicates that swap first and last channels in 3-channel image is necessary.\n",
    "- `crop`\tflag which indicates whether image will be cropped after resize or not\n",
    "- `ddepth`\tDepth of output blob. Choose cv2.CV_32F or cv2.CV_8U."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Set blob to input network using `.setInput()` on `net` object\n",
    "- Do forward pass and get output using `.forward()` on `net` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.setInput(blob)\n",
    "output = net.forward(layerOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[9.02111285e-19, 1.00000000e+00, 1.71629472e-17, 1.71595442e-17,\n",
       "         2.28430910e-18, 3.87935481e-19, 2.51645273e-25, 1.41934516e-25,\n",
       "         4.37402520e-18, 1.00205315e-25, 4.04641006e-17, 1.44863375e-11,\n",
       "         3.97063440e-29]], dtype=float32)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = output[0].argmax(axis=1)[0]\n",
    "\n",
    "confidence = output[0].max(axis=1)[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.title(\"label : %s, confidence : %2.f%%\" % (labels[idx], confidence))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.6.C Apply to Video frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_ped(img, label, x0, y0, xt, yt, color=(255,127,0), text_color=(255,255,255)):\n",
    "\n",
    "    (w, h), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "    cv2.rectangle(img,\n",
    "                  (x0, y0 + baseline),  \n",
    "                  (max(xt, x0 + w), yt), \n",
    "                  color, \n",
    "                  2)\n",
    "    cv2.rectangle(img,\n",
    "                  (x0, y0 - h),  \n",
    "                  (x0 + w, y0 + baseline), \n",
    "                  color, \n",
    "                  -1)  \n",
    "    cv2.putText(img, \n",
    "                label, \n",
    "                (x0, y0),                   \n",
    "                cv2.FONT_HERSHEY_SIMPLEX,     \n",
    "                0.5,                          \n",
    "                text_color,                \n",
    "                1,\n",
    "                cv2.LINE_AA) \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- load Haar Cascade model -------------\n",
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "# --------- load tensorflow optimized model ---------\n",
    "facerecognition_model = \"frozen_graph.pb\"\n",
    "net = cv2.dnn.readNet(facerecognition_model)\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
    "layerOutput = net.getUnconnectedOutLayersNames()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened() :\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
    "        for (x, y, w, h) in faces:\n",
    "            \n",
    "            face_img = gray[y:y+h, x:x+w]\n",
    "            face_img = cv2.resize(face_img, (50, 50))\n",
    "            \n",
    "            blob = cv2.dnn.blobFromImage(face_img, 1.0, (50, 50), (0, 0, 0), swapRB=True, crop=False)\n",
    "            net.setInput(blob)\n",
    "            output = net.forward(layerOutput)\n",
    "            idx = output[0].argmax(axis=1)[0]\n",
    "            confidence = output[0].max(axis=1)[0]*100\n",
    "            \n",
    "            if confidence > 60:\n",
    "                label_text = \"%s (%.2f %%)\" % (labels[idx], confidence)\n",
    "            else :\n",
    "                label_text = \"N/A\"\n",
    "            frame = draw_ped(frame, label_text, x, y, x + w, y + h, color=(0,255,255), text_color=(50,50,50))\n",
    "       \n",
    "        cv2.imshow('Face Recognition', frame)\n",
    "    else :\n",
    "        break\n",
    "    if cv2.waitKey(10) == ord('q'):\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Flask & OpenCV - MJPEG Stream\n",
    "- **MJPEG stream** working using **Server Push** mechanism.\n",
    "- Server push is a simple way of **sending file updates to a browser**.\n",
    "- Most major browsers, and some minor browsers support it for images, with one important exception.\n",
    "- How it works ?\n",
    "    - Browser requests a file (typically an image)\n",
    "    - The server responds with a **multipart mixed-replace** content type header, </br>\n",
    "        ```\n",
    "        Content-Type: multipart/x-mixed-replace;boundary=frame\n",
    "        ```</br>\n",
    "    - Image from the server is always continue sending image data to browser (client)\n",
    "    - Image is sender as byte format :</br>\n",
    "        ```\n",
    "        --frame\n",
    "        Content-Type: image/jpeg\n",
    "        6A3D 5671 55CA 66B7\n",
    "        611A A10B 1408 246A\n",
    "        ....\n",
    "        ....\n",
    "        ```</br>\n",
    "<img src=\"resource/server-toclient.png\" style=\"width:300px\"></img></br>\n",
    "source : [http://www.howtocreate.co.uk/Server Push](http://www.howtocreate.co.uk/php/serverpushdemo.php)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flask\n",
      "  Using cached Flask-1.1.2-py2.py3-none-any.whl (94 kB)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in c:\\users\\yunus\\anaconda3\\envs\\cvdl\\lib\\site-packages (from flask) (0.16.1)\n",
      "Collecting click>=5.1\n",
      "  Using cached click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting itsdangerous>=0.24\n",
      "  Using cached itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting Jinja2>=2.10.1\n",
      "  Using cached Jinja2-2.11.2-py2.py3-none-any.whl (125 kB)\n",
      "Collecting MarkupSafe>=0.23\n",
      "  Using cached MarkupSafe-1.1.1-cp36-cp36m-win_amd64.whl (16 kB)\n",
      "Installing collected packages: MarkupSafe, Jinja2, itsdangerous, click, flask\n",
      "Successfully installed Jinja2-2.11.2 MarkupSafe-1.1.1 click-7.1.2 flask-1.1.2 itsdangerous-1.1.0\n"
     ]
    }
   ],
   "source": [
    "! pip install flask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Basic Flask : Route & Template\n",
    "    - run `python 1_Basic_Flask/app.py` in console (cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Flask & OpenCV : mjpeg stream\n",
    "    - run `python 2_Mjpeg_Stream/app.py` in console (cmd) </br>\n",
    "![](resource/opencv_dnn_04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Facedetection Mjpeg Stream\n",
    "    - run `python 3_Facedetect_Mjpeg_Stream/app.py` in console (cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Facerecognition Mjpeg Stream\n",
    "    - run `python 4_Facerecognition_Mjpeg_Stream/app.py` in console (cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Modular Version Facerecognition\n",
    "    - create `labels.csv` to hold all labels data presitent\n",
    "    - run `python 5_Modular_Version/app.py` on console (cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save labels to CSV file\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "labels = ['Ariel_Sharon',\n",
    "          'Colin_Powell',\n",
    "          'Donald_Rumsfeld',\n",
    "          'George_W_Bush',\n",
    "          'Gerhard_Schroeder',\n",
    "          'Hugo_Chavez',\n",
    "          'Jacques_Chirac',\n",
    "          'Jean_Chretien',\n",
    "          'John_Ashcroft',\n",
    "          'Junichiro_Koizumi',\n",
    "          'Serena_Williams',\n",
    "          'Tony_Blair',\n",
    "          'Yunus']\n",
    "\n",
    "labels_df = pd.DataFrame(labels)\n",
    "\n",
    "labels_df.to_csv(\"5_Modular_Version/labels.csv\",  index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:CVDL]",
   "language": "python",
   "name": "conda-env-CVDL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
