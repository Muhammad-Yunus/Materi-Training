{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pertemuan 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Drawing Tool\n",
    "\n",
    "- Draw a **line** by using the OpenCV function `cv2.line()`\n",
    "- Draw an **ellipse** by using the OpenCV function `cv2.ellipse()`\n",
    "- Draw a **rectangle** by using the OpenCV function `cv2.rectangle()`\n",
    "- Draw a **circle** by using the OpenCV function `cv2.circle()`\n",
    "- Draw a **filled polygon** by using the OpenCV function `cv2.fillPoly()`\n",
    "- Write a **text** by using the OpenCV function `cv2.putText()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Draw Rectangle (`cv2.rectangle()`)\n",
    "\n",
    "\n",
    "- Menggunakan method `cv2.rectangle(img, (x0,y0), (xt,yt), (B, G, R), thickness, line_type)` \n",
    "- untuk :\n",
    "    - `img` : input image\n",
    "    - `(x0, y0)` : top-left-corner rectangle point (tuple)\n",
    "    - `(xt, yt)` : bottom-right-corner rectangle point (tuple)\n",
    "    - `(B, G, R)` : rectangle color (tuple)\n",
    "    - `thickness` : rectangle thickness (if negative, color will be user as fillcolor)\n",
    "    - `line_type` :\n",
    "        - `cv2.FILLED` : filled line\n",
    "        - `cv2.LINE_4` : 4-connected line\n",
    "        - `cv2.LINE_8` : 8-connected line\n",
    "        - `cv2.LINE_AA` : antialiased line\n",
    "        \n",
    "<img src=\"resource/draw-box.png\" style=\"width:700\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- draw rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = np.zeros((400, 400, 3)).astype(np.uint8)\n",
    "\n",
    "cv2.rectangle(background, # input image\n",
    "              (15,25),    # (x1, y1)\n",
    "              (200,150),  # (x2, y2)\n",
    "              (0,0,255),  # (B, G, R)\n",
    "              5)          # thickness\n",
    "\n",
    "plt.imshow(background[:,:,::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- draw filled rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = np.zeros((400, 400, 3)).astype(np.uint8)\n",
    "\n",
    "# outline color\n",
    "cv2.rectangle(background,\n",
    "              (15,25),    \n",
    "              (200,150),  \n",
    "              (0,0,255), \n",
    "              5)          \n",
    "\n",
    "# fill color\n",
    "cv2.rectangle(background,\n",
    "              (210,50),   \n",
    "              (270,270),  \n",
    "              (0,200,255),\n",
    "              -1,\n",
    "               cv2.LINE_AA)           \n",
    "\n",
    "plt.imshow(background[:,:,::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Write Text (`cv2.putText()`)\n",
    "\n",
    "\n",
    "- Menggunakan method `cv2.putText(img, text, (x,y), font_type, font_scale, (B, G, R), thickness, line_type)` \n",
    "- untuk :\n",
    "    - `img` : input image\n",
    "    - `text` : string to write in image \n",
    "    - `(x, y)` : start-left position of text (tuple)\n",
    "    - `font_type` : \n",
    "        - `cv2.FONT_HERSHEY_SIMPLEX` : size sans-serif font\n",
    "        - `cv2.FONT_HERSHEY_PLAIN` : small size sans-serif font\n",
    "        - `cv2.FONT_HERSHEY_DUPLEX` : normal size sans-serif font (more complex than FONT_HERSHEY_SIMPLEX)\n",
    "        - `cv2.FONT_HERSHEY_COMPLEX` : normal size serif font\n",
    "        - `cv2.FONT_HERSHEY_TRIPLEX` : normal size serif font (more complex than FONT_HERSHEY_COMPLEX)\n",
    "        - `cv2.FONT_HERSHEY_COMPLEX_SMALL` : smaller version of FONT_HERSHEY_COMPLEX\n",
    "        - `cv2.FONT_HERSHEY_SCRIPT_SIMPLEX` : hand-writing style font\n",
    "        - `cv2.FONT_HERSHEY_SCRIPT_COMPLEX` : more complex variant of FONT_HERSHEY_SCRIPT_SIMPLEX\n",
    "        - `cv2.FONT_ITALIC` : flag for italic font\n",
    "    - `(B, G, R)` : circle color (tuple)\n",
    "    - `thickness` : circle thickness  (if negative, color will be user as fillcolor)\n",
    "    - `line_type` :\n",
    "        - `cv2.FILLED` : filled line\n",
    "        - `cv2.LINE_4` : 4-connected line\n",
    "        - `cv2.LINE_8` : 8-connected line\n",
    "        - `cv2.LINE_AA` : antialiased line\n",
    "        \n",
    "<img src=\"resource/draw-text.png\" style=\"width:700\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- draw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = np.zeros((200, 400, 3)).astype(np.uint8)\n",
    "\n",
    "cv2.putText(background, \n",
    "            \"Hello world\", \n",
    "            (50, 50),                   \n",
    "            cv2.FONT_HERSHEY_SIMPLEX,     \n",
    "            0.7,                          \n",
    "            (0, 255, 127),                \n",
    "            1,\n",
    "            cv2.LINE_AA) \n",
    "\n",
    "plt.imshow(background[:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"lena.jpg\")\n",
    "cv2.putText(img, \n",
    "            \"Hello world\", \n",
    "            (150, 250),                   \n",
    "            cv2.FONT_HERSHEY_TRIPLEX,     \n",
    "            1.9,                          \n",
    "            (255, 127, 0),                \n",
    "            1,\n",
    "            cv2.LINE_AA) \n",
    "\n",
    "cv2.putText(img, \n",
    "            \"Hello world 2\", \n",
    "            (50, 50),                   \n",
    "            cv2.FONT_HERSHEY_SIMPLEX,     \n",
    "            1.9,                          \n",
    "            (0, 255, 127),                \n",
    "            1,\n",
    "            cv2.LINE_AA) \n",
    "\n",
    "plt.imshow(background[:,:,::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Measure Text size before drawing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- menggunakan method `cv2.getTextSize(text, fontFace, fontScale, thickness))`\n",
    "- mengembalikan dua variabel : \n",
    "    - `size` : dimensi (w, h) text \n",
    "    - `baseline` : y coord, relative to most bottom text\n",
    "    \n",
    "<img src=\"resource/text_size.png\" style=\"width:700\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.getTextSize(\"hello\", cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Draw text & Box** menggunakan (x, y) yang sama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"resource/text_n_box.png\" style=\"width:700\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = np.zeros((200, 400, 3)).astype(np.uint8)\n",
    "\n",
    "cv2.rectangle(background, # input image\n",
    "              (50,100),    # (x1, y1)\n",
    "              (200,150),  # (x2, y2)\n",
    "              (0,0,255),  # (B, G, R)\n",
    "              -1)          # thickness\n",
    "\n",
    "cv2.putText(background, \n",
    "            \"Hello world\", \n",
    "            (50, 100),                   \n",
    "            cv2.FONT_HERSHEY_SIMPLEX,     \n",
    "            0.9,                          \n",
    "            (0, 255, 127),                \n",
    "            1,\n",
    "            cv2.LINE_AA) \n",
    "\n",
    "plt.imshow(background[:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Draw text & box** menggunakan (x,y) + `cv2.textSize()`\n",
    "\n",
    "<img src=\"resource/text_n_box_2.png\" style=\"width:700\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = np.zeros((200, 400, 3)).astype(np.uint8)\n",
    "\n",
    "text = \"Hello world\"\n",
    "(w, h), baseline = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.9, 1)\n",
    "\n",
    "cv2.rectangle(background,\n",
    "              (50,100 - h),  \n",
    "              (50 + w, 100 + baseline), \n",
    "              (0,255,255), \n",
    "              -1)        \n",
    "\n",
    "cv2.putText(background, \n",
    "            text, \n",
    "            (50, 100),                   \n",
    "            cv2.FONT_HERSHEY_SIMPLEX,     \n",
    "            0.9,                          \n",
    "            (255, 0, 0),                \n",
    "            1,\n",
    "            cv2.LINE_AA) \n",
    "\n",
    "plt.imshow(background[:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Wrap text & box into **function** `draw_label_box()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_label_box(img, label, x, y):\n",
    "    (w, h), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.9, 1)\n",
    "    cv2.rectangle(img,\n",
    "                  (x, y - h),  \n",
    "                  (x + w, y + baseline), \n",
    "                  (255,0,255), \n",
    "                  -1)        \n",
    "    cv2.putText(img, \n",
    "                label, \n",
    "                (x, y),                   \n",
    "                cv2.FONT_HERSHEY_SIMPLEX,     \n",
    "                0.9,                          \n",
    "                (255, 255, 255),                \n",
    "                1,\n",
    "                cv2.LINE_AA) \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = cv2.imread('lena.jpg')#np.zeros((400, 400, 3)).astype(np.uint8)\n",
    "\n",
    "background = draw_label_box(background, \"Hello world\",10, 100)\n",
    "\n",
    "plt.imshow(background[:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Bounding Box Object Detetction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Membuat **box object detetcion**\n",
    "\n",
    "<img src=\"resource/object-detection.gif\" style=\"width:700\"></img>\n",
    "\n",
    "- atur **label**\n",
    "- atur **posisi** (`x0, y0, xt, yt`)\n",
    "- atur **warna box & text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('lena.jpg')\n",
    "\n",
    "(w, h), baseline = cv2.getTextSize(\"lena.jpg\", cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "cv2.rectangle(img,\n",
    "              (50, 50 + baseline),  \n",
    "              (300, 300), \n",
    "              (255,127,0), \n",
    "              2)\n",
    "cv2.rectangle(img,\n",
    "              (50, 50 - h),  \n",
    "              (50 + w, 50 + baseline), \n",
    "              (255,127,0), \n",
    "              -1) \n",
    "cv2.putText(img, \n",
    "            \"lena.jpg\", \n",
    "            (50, 50),                   \n",
    "            cv2.FONT_HERSHEY_SIMPLEX,     \n",
    "            0.5,                          \n",
    "            (255,255,255),                \n",
    "            1,\n",
    "            cv2.LINE_AA) \n",
    "\n",
    "plt.imshow(img[:,:,::-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- wrap into **function**  `draw_ped()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_ped(img, label, x0, y0, xt, yt, color=(255,127,0), text_color=(255,255,255)):\n",
    "\n",
    "    (w, h), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "    cv2.rectangle(img,\n",
    "                  (x0, y0 + baseline),  \n",
    "                  (max(xt, x0 + w), yt), \n",
    "                  color, \n",
    "                  2)\n",
    "    cv2.rectangle(img,\n",
    "                  (x0, y0 - h),  \n",
    "                  (x0 + w, y0 + baseline), \n",
    "                  color, \n",
    "                  -1)  \n",
    "    cv2.putText(img, \n",
    "                label, \n",
    "                (x0, y0),                   \n",
    "                cv2.FONT_HERSHEY_SIMPLEX,     \n",
    "                0.5,                          \n",
    "                text_color,                \n",
    "                1,\n",
    "                cv2.LINE_AA) \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('lena.jpg')\n",
    "\n",
    "img = draw_ped(img, \"image : lena.jpg\",50, 50, 300, 300)\n",
    "\n",
    "plt.imshow(img[:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 2. Casecade Classifier\n",
    "<img src=\"resource/lena_face.png\" style=\"width:250px\"></img><br>\n",
    "- Object Detection OpenCV is using **Haar feature-based cascade classifiers.**\n",
    "- Is an effective object detection method proposed by Paul Viola and Michael Jones in their paper, \"Rapid Object Detection using a Boosted Cascade of Simple Features\" in 2001.\n",
    "- **Haar features** just like normal convolutional kernel, <br><br>\n",
    "<img src=\"resource/haar_feature.png\"></img><br><br>\n",
    "- Each feature is a single value obtained by **subtracting** sum of pixels under the **white rectangle** from sum of pixels under the **black rectangle**. <br><br>\n",
    "<img src=\"resource/face_haar_feature.png\" style=\"width:600px\"></img><br><br>\n",
    "- `lena.jpg` convolving proses to detect face using haar feature, <br><br>\n",
    "<img src=\"resource/convolving_haar_feature.gif\" style=\"width:250px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Class `cv2.CascadeClassifier()` digunakan untuk membaca classifier file (**.xml**)\n",
    "- Pada class `cv2.CascadeClassifier()` terdapat method `.detectMultiscale()` untuk melakukan deteksi objek pada sebuah citra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Method `.detectMultiscale()` memiliki beberapa parameter input,\n",
    "    - `scaleFactor` : Ukuran seberapa besar input image direduksi agar mampu dibaca oleh detector algorithm. Hal inilah yang memungkinkan algorima dapat mendeteksi wajah dalam beragam skala gambar (multi scale image).\n",
    "    - `minNeighbors` : Ukuran minimum antara posisi face rectangle satu terhadap lainya. Hal ini berkaitan dengan method `.detectMultiscale()` yang akan melakukan sliding window terhadap image. Jika kita set ke 0, maka banyak false positive face rectangle terdeteksi. sehingga kita akan pilih nilai yang lebih tinggi. Namun jangan sampai memilih nilai yang terlalu besar, yang mengakibatkan true positive face rectangle menjadi tidak terdeteksi.\n",
    "    - `flags` : Parameter yang sama pada method cvHaarDetectObjects. Ini tidak digunakan pada Cascade Classifier terbaru.\n",
    "    - `minSize` : Ukuran object minimal. Ukuran yang lebih kecil tidak akan dimasukan kedalam detected object.\n",
    "    - `maxSize` : Ukuran object maksimal. Ukuran yang lebih besar tidak akan dimasukan kedalam detected object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Face Detection (`haarcascade_frontalface_default.xml`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "img = cv2.imread(\"lena.jpg\")\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "for (x,y,w,h) in faces:\n",
    "    img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "plt.imshow(img[:,:,::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Detect Face from Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        frame = cv2.resize(frame, (0,0), fx=0.5, fy=0.5)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        cv2.imshow('Detect Face', frame)\n",
    "        if cv2.waitKey(25) == ord('q'):\n",
    "            break\n",
    "    else :\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using custom box (`draw_ped()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_ped(img, label, x0, y0, xt, yt, color=(255,127,0), text_color=(255,255,255)):\n",
    "\n",
    "    (w, h), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "    cv2.rectangle(img,\n",
    "                  (x0, y0 + baseline),  \n",
    "                  (max(xt, x0 + w), yt), \n",
    "                  color, \n",
    "                  2)\n",
    "    cv2.rectangle(img,\n",
    "                  (x0, y0 - h),  \n",
    "                  (x0 + w, y0 + baseline), \n",
    "                  color, \n",
    "                  -1)  \n",
    "    cv2.putText(img, \n",
    "                label, \n",
    "                (x0, y0),                   \n",
    "                cv2.FONT_HERSHEY_SIMPLEX,     \n",
    "                0.5,                          \n",
    "                text_color,                \n",
    "                1,\n",
    "                cv2.LINE_AA) \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Apply to Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "img = cv2.imread(\"lena.jpg\")\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "for (x,y,w,h) in faces:\n",
    "    img = draw_ped(img, \"human face\", x, y, x + w, y + h)\n",
    "\n",
    "plt.imshow(img[:,:,::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Apply to video realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
    "        for (x, y, w, h) in faces:\n",
    "            frame = draw_ped(frame, \"human face\", x, y, x + w, y + h, color=(0,255,255), text_color=(50,50,50))\n",
    "        cv2.imshow('Detect Face', frame)\n",
    "    else :\n",
    "        break\n",
    "    if cv2.waitKey(25) == ord('q'):\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- apply facedetection for all image dataset\n",
    "    - read, detect face, crop, resize & convert to gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "image_list = []\n",
    "labels = []\n",
    "\n",
    "for folder in os.listdir(\"lfw_dataset\"):\n",
    "    for file in os.listdir(\"lfw_dataset/\" + folder):\n",
    "        img = cv2.imread(\"lfw_dataset/\" + folder + \"/\" + file)\n",
    "        \n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        faces = face_cascade.detectMultiScale(img_gray, 1.3, 5)\n",
    "        for (x, y, w, h) in faces:\n",
    "            img_face = img_gray[y:y+h, x:x+w]  # crop face image \n",
    "            img_resize = cv2.resize(img_face, (100, 100)) # resize to 100 x 100 pixel\n",
    "            \n",
    "            image_list.append(img_resize)\n",
    "            labels.append(folder) # append label (name) of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(image_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- show detected face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,16))\n",
    "for i in range(len(image_list)):\n",
    "    \n",
    "    img = image_list[i]\n",
    "    plt.subplot(4, 5, i + 1)\n",
    "    plt.title(labels[i])\n",
    "    plt.imshow(img, cmap=\"gray\") # doesn't need reverse matrix, since image_list only 2D (grayscale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- save detected face into folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"croped_face\") :\n",
    "    os.mkdir(\"croped_face\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_folder = \"croped_face\"\n",
    "for i in range(len(image_list)):\n",
    "    \n",
    "    # get image\n",
    "    img = image_list[i]\n",
    "    \n",
    "    # check if folder exist. if not, create that folder    \n",
    "    folder_path = os.path.join(face_folder, labels[i])\n",
    "    if not os.path.exists(folder_path) :\n",
    "        os.mkdir(folder_path)\n",
    "        \n",
    "    # remove image if exist\n",
    "    file_name = labels[i] + \"_%4d.jpg\" % i\n",
    "    file_path = os.path.join(*[face_folder, labels[i], file_name])\n",
    "    if os.path.exists(file_path) :\n",
    "        os.remove(file_path) # remove file using os.remove\n",
    "        \n",
    "    # save image\n",
    "    cv2.imwrite(file_path, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# 3. Eigenface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- install library Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Eigenface Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Merupakan sekumpulan **eigenvectors** yang digunakan pada computer vision untuk kebutuhan **face recognition**. \n",
    "- **Eigenvectors** diturunkan dari **covariance matrix** dari probability distribution pada **high-dimensional vector space** gambar wajah. \n",
    "- Eigenfaces sendiri membentuk basis set semua gambar yang digunakan untuk membangun **covariance matrix**. \n",
    "- Ini akan **mereduksi dimensi** gambar wajah menjadi kumpulan gambar yang lebih kecil yang dapat mewakili gambar aslinya pada training dataset.<br><br>\n",
    "![](resource/eigenface.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pada praktiknya untuk mendapatkan Eigenface digunakan teknik seperti **PCA (Principal Component Analysis)**. \n",
    "- PCA merupakan teknik **dimentionality reduction** yang dapat menghasilkan output data dengan dimensi rendah dari input data berdimensi tinggi seperti gambar wajah."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PCA dihitung dalam dua langkah sebagai berikut :\n",
    "    - Menghitung **covariance matrix** dari input gambar (original image)\n",
    "    - Melakukan **eigenvalue decomposition** pada covariance matrix yang didapatkan<br><br><br>\n",
    "![](resource/eigenface2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Calculate Eigenface using Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[ 0.5,  0.8,  1.5, -2.4], \n",
    "              [-1.9, -8.7,  0.02, 4.9], \n",
    "              [ 5.5,  6.1, -8.1,  3.0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculate Center of data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x - x.mean(axis=0) # Center data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Calculate Covariance Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Covariance Matrix : \n",
    "    - Covariance Matrix provides the a measure of **strength of correlation between two variable or more** set of variables. \n",
    "    - The covariance matrix element `Cij` is the covariance of `xi` and `xj`. \n",
    "        - If `COV(xi, xj)` = 0 then variables are uncorrelated\n",
    "        - If `COV(xi, xj)` > 0 then variables positively correlated\n",
    "        - If `COV(xi, xj)` < 0 then variables negatively correlated\n",
    "    - it is a symmetric, **dxd** matrix (where **d** is the number of **features**).\n",
    "    - number of feature is `min(sample_dimension, number_of_samples)`\n",
    "    - in this case, `sample_dimension` is 10000 (flatten vector for 100x100 pixel face grayscaled data)\n",
    "![](resource/sample.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculate Covariance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = np.cov(X.T) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `np.cov` is equal to dot operation of matrix with the transposed matrix * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(X.T, X) * 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Concept Eigenvalue and Eigenvector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Eigenvalue Decomposition of covariance matrix <br>\n",
    "![](resource/eigenvalue.png)\n",
    "- where :\n",
    "    - **λ** : Eigenvalue\n",
    "    - **v** : Eigenvector\n",
    "    - **A** : Input Matrix (in this case would be Covariance Matrix from pre. step)\n",
    "- Can be stated equivalently as, <br>\n",
    "![](resource/eigenvalue2.png)\n",
    "- where ***I*** is the matrix identity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Contoh Soal : <br>\n",
    "![](resource/eigen1.jpg)<br>\n",
    "- Jawaban : <br>\n",
    "![](resource/eigen11.jpg)\n",
    "- Detail contoh persoalan Nilai Eigen : https://istanamengajar.wordpress.com/2014/01/28/soal-dan-pembahasan-nilai-dan-vektor-eigen-suatu-matriks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Calculate Eigenvalue and Eigenvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals, evecs = np.linalg.eigh(cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Flip sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evecs = np.negative(evecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sort Eigenvalue as descending (largest to small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = evals.argsort()[::-1] # Sort descending and get sorted indices\n",
    "evals = evals[idx] \n",
    "evecs = evecs[:,idx] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Eigen Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evecs[:, :K].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Projecting Input to PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.dot(evecs[:, :K])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Calculate PCA using Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 2\n",
    "pca = PCA(n_components=K).fit(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Eigenvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evecs = pca.components_\n",
    "\n",
    "evecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Projecting Input to PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Calculate PCA using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- calculate PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 2\n",
    "\n",
    "mean, eigen_vec = cv2.PCACompute(x, mean=None, maxComponents=K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Eigenvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Projecting Input to PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x - mean\n",
    "np.dot(X, eigen_vec.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Apply PCA to All Face Croped Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_faces= []\n",
    "labels = []\n",
    "\n",
    "for folder in os.listdir(\"croped_face\"):\n",
    "    for file in os.listdir(\"croped_face/\" + folder):\n",
    "        img = cv2.imread(\"croped_face/\" + folder + \"/\" + file, 0)\n",
    "        flatten_vector = img.flatten() \n",
    "        image_faces.append(flatten_vector)\n",
    "        labels.append(folder) # append label (name) of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_faces[0].shape # 1D vector from 100x100 pixel face image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculate PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = 100, 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "pca = PCA(n_components=K).fit(image_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Show Eigenface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenfaces = pca.components_.reshape((K, h, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.unique(labels).shape[0]\n",
    "c = int(len(labels)/rows)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 15))\n",
    "for i in range(K):\n",
    "    plt.subplot(r, c, i + 1)\n",
    "    plt.imshow(eigenfaces[i], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Projecting Input data to PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_face = pca.transform(image_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each image vector with size 10000 is represent by PCA transform output of size 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_face[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_face[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Recomended Method\n",
    "- Using Scikit-Learn : \n",
    "    - Provide method `.fit()`, `.transform()`. Important part when talking about splitting dataset\n",
    "    - Saved PCA state ada **pickle object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pickle-mixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- save PCA object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_pca_model(model, filename, path=\"\"): \n",
    "    with open(os.path.join(path, filename), 'wb') as out_name:\n",
    "        pickle.dump(model, out_name, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def read_pca_model(filename, path=\"\"):\n",
    "    with open(os.path.join(path, filename), 'rb') as in_name:\n",
    "        model = pickle.load(in_name)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pca_model(pca, \"pca_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- load PCA object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "loaded_pca = read_pca_model(\"pca_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"lena.jpg\")\n",
    "plt.title(\"lena.jpg\")\n",
    "plt.imshow(img[:,:,::-1])\n",
    "plt.show()\n",
    "    \n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(img_gray, 1.3, 5)\n",
    "for (x, y, w, h) in faces:\n",
    "    img_face = img_gray[y:y+h, x:x+w]\n",
    "    \n",
    "    img_resize = cv2.resize(img_face, (100,100))\n",
    "    flatten_vector = img_resize.flatten()\n",
    "\n",
    "    print(\"Projection Input into PCA :\")\n",
    "    print(pca.transform([image_faces[0]]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:opencv_env]",
   "language": "python",
   "name": "conda-env-opencv_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
