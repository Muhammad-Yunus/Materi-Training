{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV ML \n",
    "\n",
    "- Intro Machine Learning\n",
    "- Intro OpenCV ML & Scikit-Learn\n",
    "- Intro K - Nearest Neighbour (KNN) Algorithm\n",
    "- Simple Implementation KNN\n",
    "- KNN + Eigenface For Facerecognition \n",
    "- SVM + Eigenface For Facerecognition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "##  1. Intro Machine Learning\n",
    "- The study of computer algorithms that improve automatically through experience.[1][2]\n",
    "- It is seen as a subset of **artificial intelligence**. \n",
    "- Machine learning algorithms build a **mathematical model** based on **sample data**, known as \"training data\".\n",
    "- Machine learning is closely related to **computational statistics**, which focuses on making predictions using computers. \n",
    "\n",
    "> *Machine learning provides systems the ability to **automatically learn** and **improve from experience** without being **explicitly programmed**.*\n",
    "\n",
    "![](resource/machine_learning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Dataset\n",
    "- In the case of tabular data, a data set corresponds to one or more database **tables**, where every **column** of a table represents a particular **variable/fature**, and each row corresponds to a **instance** data. <br>\n",
    "- Tabular dataset : <br>\n",
    "<img src=\"resource/text_dataset.png\" style=\"width:400px\"></img><br>\n",
    "- Image Dataset :<br>\n",
    "<img src=\"resource/image_dataset.png\" style=\"width:500px\"></img><br><br><br>\n",
    "- Dataset Proportion :<br>\n",
    "<img src=\"resource/dataset_proportion.jpeg\" style=\"width:500px\"></img>\n",
    "    - **Training set** : is used in training phase,\n",
    "    - **Validation set** : is used for validationg model during training, for example Cross Validation.\n",
    "    - **Test set** : is used in testing phase (after training model finish).\n",
    "- Common portion :\n",
    "    - Trainig set : 50%\n",
    "    - Validation set : 25%\n",
    "    - Test set : 25%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Machine Learning Algorithm\n",
    "<img src=\"resource/ml_algorithm.png\" style=\"width:500px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Supervised Machine Learning\n",
    "- **Classification**: Relates to **categorical data output**, such as whether it is red or not, whether the weather is sunny or cloudy, healthy or sick.\n",
    "- **Regression**: Relates to **continuous data output**, such as length, weight, velocity\n",
    "<img src=\"resource/supervised_learning.png\" style=\"width:500px\"></img>\n",
    "- Algorithm :\n",
    "    - Support Vector Machine (SVM)\n",
    "    - Linear Regression\n",
    "    - Logistic Regression\n",
    "    - Naive Bayes\n",
    "    - Linear Discriminant Analysis (LDA)\n",
    "    - Decision Tree\n",
    "    - K-nearest Neighbor\n",
    "    - Neural Network (Multilayer Perceptron)\n",
    "    - Similarity Learning\n",
    "    - Etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 2. Intro OpenCV ML & Scikit-Learn\n",
    "\n",
    "### 2.1 OpenCV ML\n",
    "- Main Doc : https://docs.opencv.org/master/dc/dd6/ml_intro.html\n",
    "- List of Machine Learning Algorithm on OpenCV ML :\n",
    "    - Normal Bayes Classifier\n",
    "    - K-Nearest Neighbors (KNN)\n",
    "    - Support Vector Machines (SVM)\n",
    "    - Decision Trees\n",
    "    - Variable Importance\n",
    "    - Boosting\n",
    "    - Random Trees\n",
    "    - Expectation Maximization\n",
    "    - Neural Networks\n",
    "    - Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Scikit-Learn\n",
    "- Main Doc : https://scikit-learn.org/stable/\n",
    "- List od Machine Learning Algorithm on Scikit-Learn :\n",
    "    - K-Nearest Neighbors\n",
    "    - Support Vector Machines\n",
    "    - Decision Tree\n",
    "    - Random Forests\n",
    "    - Naive Bayes\n",
    "    - Logistic Regression\n",
    "    - Neural Networks\n",
    "    - Ada Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 3. Intro K - Nearest Neighbour (KNN) Algorithm\n",
    "\n",
    "- K-nearest neighbor classifier is one of the introductory supervised classifier. \n",
    "- **Fix** & **Hodges** proposed K-nearest neighbor classifier algorithm in the year of 1951 for performing pattern classification task.\n",
    "- The principle behind **nearest neighbor** methods is to find a predefined number of training samples **closest** in **distance** to the new point, and **predict** the label from these. \n",
    "- The **distance** can, in general, be any metric measure: standard **Euclidean distance** is the most common choice.\n",
    "- other distance : <br>\n",
    "|name|desc|distance function &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; |\n",
    "|----------|----------|-------------------- |\n",
    "|“euclidean”|Euclidean Distance|$\\sqrt{\\sum{{(x - y)}^2}}$|\n",
    "|“manhattan”|Manhattan Distance|$\\sum{|x - y|}$|\n",
    "|“chebyshev”|Chebyshev Distance|$\\max{|x - y|}$|\n",
    "|“minkowski”|Minkowski Distance|${(\\sum{|x - y|^p})}^{1/p}$|\n",
    "|“wminkowski”|W Minkowski Distance|$\\sum{(|w(x - y)|^p)}^{1/p}$|\n",
    "|“seuclidean”|S Euclidean Distance|$\\sqrt{\\frac{\\sum{(x - y)^2}}{V}}$|\n",
    "|“mahalanobis”|Mahalanobis Distance|$\\sqrt{(x - y)'V^{-1} (x-y)}$|\n",
    "- How KNN works : <br>\n",
    "    - define number of nearest neighbour that we want to calculate. Denote as **k**.\n",
    "    - calculate distance from one-point sample to other dataset. \n",
    "    - sort the disatance from nearest to furthest.\n",
    "    - take the **k** closest neighbors,\n",
    "    - get the most class data from **k** closest neighbors\n",
    "\n",
    "![](resource/knn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How to choose number of **k**:\n",
    "    - Selecting the value of **k** in K-nearest neighbor is the most critical problem. \n",
    "    - A small value of **k** means that **noise** will have a higher influence on the result.\n",
    "    - A large value of **k** makes it computationally expensive and defeats the basic idea behind KNN (*that points that are near might have similar classes*). \n",
    "    - A simple approach to select $k$ is $k = n^{\\frac{1}{2}}$, where $n$ is number of sample.\n",
    "- source : [link](https://medium.com/@sonish.sivarajkumar/k-nearest-neighbours-knn-algorithm-9900c1427726)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 4. Simple Implementation KNN\n",
    "### 4.1 Prepare Dummy Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- generate random data (dummy dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randint(0, 100, (25,2)).astype(np.float32)\n",
    "y = np.random.randint(0, 2, (25,1)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"x1 \\t x1 \\t y\\n\")\n",
    "for (x1, x2), y1 in zip(X, y):\n",
    "    print(\"%.1f \\t %.1f \\t %.1f\" % (x1, x2, y1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- prepare test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.random.randint(0,100, (1,2)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_test[:,0], X_test[:,1], 80, 'g', 'o')\n",
    "\n",
    "red = X[y.ravel()==0]\n",
    "plt.scatter(red[:,0], red[:,1], 80, 'r', '^')\n",
    "\n",
    "blue = X[y.ravel()==1]\n",
    "plt.scatter(blue[:,0], blue[:,1], 80, 'b', 's')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Implementation From Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculate Euclidean Distance\n",
    "    - $\\sqrt{\\sum{{(x - y)}^2}}$\n",
    "- sort the distance\n",
    "- find ***k*** closest neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = np.repeat(X_test, X.shape[0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = np.sqrt(np.sum(np.power((X - xt), 2), axis=1))\n",
    "idx = np.argsort(distance)\n",
    "sorted_distance = distance[idx][:k]\n",
    "\n",
    "print(sorted_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbours = y[idx][:k][:,0]\n",
    "print(\"Neighbours : \", neighbours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.bincount(neighbours.astype(np.int64)).argmax()\n",
    "print(\"y pred : \", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 OpenCV Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train k-NN model\n",
    "    - k-NN in OpenCV ML only support Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3 # number of neighbour item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = cv2.ml.KNearest_create()\n",
    "knn.train(X, cv2.ml.ROW_SAMPLE, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- predict `y` for the `X_test` data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, results, neighbours, dist = knn.findNearest(X_test, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y pred : \", results)\n",
    "print(\"Neighbours : \", neighbours)\n",
    "print(\"Distance : \", dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Scikit-Learn Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train k-NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3 # number of neighbour item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = KNeighborsClassifier(metric='euclidean', n_neighbors=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `y` part on Scikit-Learn implementation must in 1D shape array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh.fit(X, y.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- predict `y` for the `X_test` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = neigh.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist, idx = neigh.kneighbors(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y pred : \", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbours =  [int(y[i][0]) for i in idx[0]]\n",
    "print(\"Neighbours : \", neighbours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Distance : \", dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. k-NN + Eigenface For Facerecognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.0 Preprocessing Dataset (pertemuan 5)\n",
    "- Predic Face, Crop, Resize & Conver to Grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "image_list = []\n",
    "labels = []\n",
    "\n",
    "for folder in os.listdir(\"lfw_dataset\"):\n",
    "    for file in os.listdir(\"lfw_dataset/\" + folder):\n",
    "        img = cv2.imread(\"lfw_dataset/\" + folder + \"/\" + file)\n",
    "        \n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        faces = face_cascade.detectMultiScale(img_gray, 1.3, 5)\n",
    "        for (x, y, w, h) in faces:\n",
    "            img_face = img_gray[y:y+h, x:x+w]  # crop face image \n",
    "            img_resize = cv2.resize(img_face, (100, 100)) # resize to 100 x 100 pixel\n",
    "            \n",
    "            image_list.append(img_resize)\n",
    "            labels.append(folder) # append label (name) of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(image_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- save detected face into folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"croped_face\") :\n",
    "    os.mkdir(\"croped_face\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_folder = \"croped_face\"\n",
    "for i in range(len(image_list)):\n",
    "    \n",
    "    # get image\n",
    "    img = image_list[i]\n",
    "    \n",
    "    # check if folder exist. if not, create that folder    \n",
    "    folder_path = os.path.join(face_folder, labels[i])\n",
    "    if not os.path.exists(folder_path) :\n",
    "        os.mkdir(folder_path)\n",
    "        \n",
    "    # remove image if exist\n",
    "    file_name = labels[i] + \"_%4d.jpg\" % i\n",
    "    file_path = os.path.join(*[face_folder, labels[i], file_name])\n",
    "    if os.path.exists(file_path) :\n",
    "        os.remove(file_path) # remove file using os.remove\n",
    "        \n",
    "    # save image\n",
    "    cv2.imwrite(file_path, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Load Croped Face Dataset (pertemuan 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_faces= []\n",
    "labels = []\n",
    "\n",
    "for folder in os.listdir(\"croped_face\"):\n",
    "    for file in os.listdir(\"croped_face/\" + folder):\n",
    "        img = cv2.imread(\"croped_face/\" + folder + \"/\" + file, 0)\n",
    "        flatten_vector = img.flatten() \n",
    "        image_faces.append(flatten_vector)\n",
    "        labels.append(folder) # append label (name) of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_faces[0].shape # 1D vector from 100x100 pixel face image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Label Encoding (Scikit-Learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "le.fit(labels)\n",
    "\n",
    "label_name = le.classes_\n",
    "print(label_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_vec = le.transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Split dataset (75% train, 25% test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(image_faces, dtype=np.float32),    # input data\n",
    "                                                    np.array(labels_vec),                    # target/output data \n",
    "                                                    test_size=0.30,                          # split ratio test (25%)\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape, X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Calculate Eigenface using PCA (pertemuan 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = 100, 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 233\n",
    "pca = PCA(n_components=K).fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Show Eigenface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenfaces = pca.components_.reshape((K, h, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(K)[:20]: # display 20 eigenface\n",
    "    plt.subplot(4, 5, i + 1)\n",
    "    plt.imshow(eigenfaces[i], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Projecting Input data to PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- save PCA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_model(model, filename, path=\"\"): \n",
    "    with open(os.path.join(path, filename), 'wb') as out_name:\n",
    "        pickle.dump(model, out_name, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def read_model(filename, path=\"\"):\n",
    "    with open(os.path.join(path, filename), 'rb') as in_name:\n",
    "        model = pickle.load(in_name)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(pca, \"pca_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Apply to k-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train k-NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = KNeighborsClassifier(metric='euclidean', n_neighbors=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `y` part on Scikit-Learn implementation must in 1D shape array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- predict `y` for the `X_test` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = neigh.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(neigh, \"k-NN_scikit_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred, labels=np.unique(labels_vec))\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(cnf_matrix, classes=label_name,normalize=False,\n",
    "                      title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, \n",
    "                            y_pred, \n",
    "                            target_names=label_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare with Eigenface Facerecognizer Implementation OpenCV Contrib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- install OpenCV Contrib (extra module OpenCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Eigenface using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv2.face.EigenFaceRecognizer_create(num_components=233)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [model.predict(img)[0] for img in X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred, labels=np.unique(labels_vec))\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(cnf_matrix, classes=label_name,normalize=False,\n",
    "                      title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, \n",
    "                            y_pred, \n",
    "                            target_names=label_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Support Vector Machines\n",
    "- Are supervised learning models with associated learning algorithms that analyze data used for **classification** and **regression analysis**.\n",
    "- Support Vector Machines is a **discriminative classifier** formally defined by a **separating hyperplane**. In other words, given labeled training data (supervised learning), the algorithm outputs an **optimal hyperplane** which categorizes new examples.\n",
    "- Developed at AT&T Bell Laboratories by Vapnik with colleagues (Boser et al., 1992, Guyon et al., 1993, Vapnik et al., 1997).\n",
    "- One of the most robust prediction methods, based on the statistical learning framework or VC theory proposed by Vapnik and Chervonenkis (1974) and Vapnik (1982, 1995).\n",
    "\n",
    "#### Linearly Separable Data\n",
    "- H1 does not separate the classes. \n",
    "- H2 does, but only with a small margin. \n",
    "- H3 separates them with the **maximal margin**.<br>\n",
    "\n",
    "<img src=\"resource/lineary_sparable.png\" style=\"width:250px\"></img>\n",
    "\n",
    "- **Maximum-margin hyperplane** and **margins** for an SVM trained with samples from two classes. \n",
    "- Samples on the margin are called the **support vectors**. <br>\n",
    "<img src=\"resource/SVM_margin.png\" style=\"width:250px\"></img>\n",
    "- Multiclass Dataset :<br>\n",
    "<img src=\"resource/multicalss_svm.png\" style=\"width:500px\"></img>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. SVM Implementation\n",
    "### 8. OpenCV Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `cv.ml.SVM_create()` : create empty model SVM\n",
    "- method `.setType(svm_type)` :\n",
    "    - where `svm_type` :\n",
    "        - `cv2.ml.SVM_C_SVC` : $C$-Support Vector Classification. n-class classification (n ≥ 2), allows imperfect separation of classes.\n",
    "        - `cv2.ml.SVM_NU_SVC` : $ν$-Support Vector Classification. n-class classification with imperfect separation. Parameter $ν$ (0..1).\n",
    "        - `cv2.ml.SVM_ONE_CLASS` : Distribution Estimation (One-class SVM). \n",
    "        - `cv2.ml.SVM_EPS_SVR` : $ϵ$-Support Vector Regression. \n",
    "        - `cv2.ml.SVM_NU_SVR` : $ν$-Support Vector Regression. \n",
    "    - `svm_type` parameter :\n",
    "        - set $C$ (regularization parameter) if using C-SVC/NU-SVR/EPS-SVR : `.setC()`\n",
    "        - set $ϵ$ (epsilon) if using EPS-SVR : `.setP()`\n",
    "        - set $ν$ (nu) if using NU-SVC/NU-SVR/SVM-ONE_CLASS : `.setNU()`\n",
    "- method `.setKernel(kernel_type)` :\n",
    "    - where `kernel_type` :\n",
    "        - `cv2.ml.SVM_LINEAR` : Linear kernel, It is the fastest option\n",
    "        - `cv2.ml.SVM_POLY` : Polynomial kernel\n",
    "        - `cv2.ml.SVM_RBF` : Radial basis function (RBF), a good choice in most cases\n",
    "        - `cv2.ml.SVM_SIGMOID` : Sigmoid kernel\n",
    "    - Kernel Parameter :\n",
    "        - **linear** &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;: $\\langle x, x'\\rangle$\n",
    "        - **polynomial** &nbsp;&nbsp;&nbsp;&nbsp;: $(\\gamma \\langle x, x'\\rangle + r)^d$ , where $d$ is specified by parameter `degree`, $r$ by `coef0`.\n",
    "        - **rbf**&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;: $\\exp(-\\gamma \\|x-x'\\|^2)$, where $\\gamma$ is specified by parameter `gamma`, must be greater than `0`.\n",
    "        - **sigmoid**&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;: $\\tanh(\\gamma \\langle x,x'\\rangle + r)$, where $r$ is specified by `coef0`.\n",
    "    - Set kernel parameter :\n",
    "        - set `degree` :  use method `.setDegree()`\n",
    "        - set `gamma` : use method `.setGamma()`\n",
    "        - set `coef0` : use method `.setCoef0()`\n",
    "- method `.setTermCriteria(criteria_type, maxCount, epsilon)`:\n",
    "    - where `criteria_type` :\n",
    "        - `cv2.TERM_CRITERIA_MAX_ITER` : the maximum number of iterations or elements to compute\n",
    "        - `cv2.TERM_CRITERIA_EPS` : the desired accuracy or change in parameters at which the iterative algorithm stops\n",
    "        - `cv2.TERM_CRITERIA_MAX_ITER` + `cv2.TERM_CRITERIA_EPS`\n",
    "        - `maxCount` and `epsilon` is termination value for each selected createria by `criteria_type` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = cv2.ml.SVM_create()\n",
    "svm_model.setType(cv2.ml.SVM_C_SVC)\n",
    "svm_model.setKernel(cv2.ml.SVM_LINEAR)\n",
    "svm_model.setC(100) \n",
    "svm_model.setGamma(0.001) \n",
    "svm_model.setTermCriteria((cv2.TERM_CRITERIA_MAX_ITER, 100, 0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model.train(X_train_pca, cv2.ml.ROW_SAMPLE, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- predict result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_model.predict(np.float32(X_test_pca))[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- save model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model.save(\"SVM_OpenCV_model.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred, labels=np.unique(labels_vec))\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(cnf_matrix, classes=label_name,normalize=False,\n",
    "                      title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, \n",
    "                            y_pred, \n",
    "                            target_names=label_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Scikit-Learn Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='linear', C=100, gamma=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- predict result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(svm, \"SVM_scikit_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred, labels=np.unique(labels_vec))\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(cnf_matrix, classes=label_name,normalize=False,\n",
    "                      title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, \n",
    "                            y_pred, \n",
    "                            target_names=label_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:opencv_env]",
   "language": "python",
   "name": "conda-env-opencv_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
