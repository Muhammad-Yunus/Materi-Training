{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Pertemuan 11 (Feature Extraction)\n",
    "\n",
    "- Statistical Feature \n",
    "- Gray Level Co-occurance Matrix (GLCM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library \n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### 0. Final Class Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing : \n",
    "    def __init__(self, DATASET_FOLDER = \"Dataset_Tomat/\"):\n",
    "        self.labels = []\n",
    "        self.image_list = []\n",
    "        self.image_range = []\n",
    "        self.image_edged = []\n",
    "        self.contours_list = []\n",
    "        self.filtered_contours_list = []\n",
    "        self.image_croped = []\n",
    "        self.image_resized = []\n",
    "        self.DATASET_FOLDER = DATASET_FOLDER\n",
    "        \n",
    "        # define range of red color in HSV\n",
    "        self.lower_red = np.array([-10, 75, 50])\n",
    "        self.upper_red = np.array([10, 255, 255])\n",
    "\n",
    "        # define range of green color in HSV\n",
    "        self.lower_green = np.array([35, 100, 50])\n",
    "        self.upper_green = np.array([70, 255, 255])\n",
    "        \n",
    "        # define range of yellow color in HSV\n",
    "        self.lower_yellow = np.array([10, 125, 50])\n",
    "        self.upper_yellow = np.array([35, 255, 255])\n",
    "        \n",
    "        # define range of black color in HSV\n",
    "        self.lower_black = np.array([0, 0, 0])\n",
    "        self.upper_black = np.array([255, 255, 50])\n",
    "        \n",
    "    def ImageRead(self):\n",
    "        for folder in os.listdir(self.DATASET_FOLDER):\n",
    "            for file in os.listdir(self.DATASET_FOLDER + folder):\n",
    "                img = cv2.imread(self.DATASET_FOLDER + folder + \"/\" + file)\n",
    "                self.image_list.append(img)\n",
    "                self.labels.append(folder) # append label (name) of image\n",
    "                            \n",
    "    def RangeTresholding(self):\n",
    "        for img in self.image_list :          \n",
    "            # convert to hsv\n",
    "            hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "            # apply range thresholding\n",
    "            mask_green = cv2.inRange(hsv.copy(), self.lower_green, self.upper_green)\n",
    "            mask_red = cv2.inRange(hsv.copy(), self.lower_red, self.upper_red)\n",
    "            mask_yellow = cv2.inRange(hsv.copy(), self.lower_yellow, self.upper_yellow)\n",
    "            mask_black = cv2.inRange(hsv.copy(), self.lower_black, self.upper_black)\n",
    "\n",
    "            mask = mask_green + mask_red + mask_yellow + mask_black \n",
    "            res = cv2.bitwise_and(img, img, mask= mask)\n",
    "            self.image_range.append(res)\n",
    "            \n",
    "    def EdgeDetection(self):\n",
    "        for img in self.image_range :\n",
    "            edged = cv2.Canny(img, 200, 210)\n",
    "            self.image_edged.append(edged)\n",
    "            \n",
    "    def FindContour(self):\n",
    "        for img in self.image_edged:\n",
    "            # find contour\n",
    "            contours, hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "            self.contours_list.append(contours)\n",
    "        \n",
    "    def FilterContour(self, min_area=50, min_w=10, min_h=10):\n",
    "        for contours in self.contours_list:\n",
    "            filtered_contours = []\n",
    "            for cnt in contours:\n",
    "                x, y, w, h = cv2.boundingRect(cnt)\n",
    "                area = w*h\n",
    "                if not (area < min_area or w < min_w or h < min_h) :\n",
    "                    filtered_contours.append(cnt)\n",
    "            self.filtered_contours_list.append(filtered_contours)\n",
    "\n",
    "    def CropByContour(self):\n",
    "        for i in range(len(self.image_range)): # crop all removed background image by contour \n",
    "            img = self.image_range[i]\n",
    "            cnt = np.concatenate(self.filtered_contours_list[i], axis=0) # concate all remaining contour each image\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            roi = img[y:y+h, x:x+w]\n",
    "            self.image_croped.append(roi)\n",
    "                \n",
    "    def Resize(self, size=(172,172)):\n",
    "        for img in self.image_croped:\n",
    "            resized = cv2.resize(img, (size[0], size[1]))\n",
    "            self.image_resized.append(resized)\n",
    "            \n",
    "    def SaveAllImage(self, RESIZED_FOLDER = \"resized_tomato/\"):\n",
    "        if not os.path.exists(RESIZED_FOLDER) :\n",
    "            os.mkdir(RESIZED_FOLDER)\n",
    "            \n",
    "        for i in range(len(self.image_resized)):\n",
    "\n",
    "            # get image\n",
    "            img = self.image_resized[i]\n",
    "\n",
    "            # check if folder exist. if not, create that folder    \n",
    "            folder_path = RESIZED_FOLDER + self.labels[i] + \"/\"\n",
    "            if not os.path.exists(folder_path) :\n",
    "                os.mkdir(folder_path)\n",
    "\n",
    "            # save image\n",
    "            file_name = self.labels[i] + \"_%03d.jpg\" % i\n",
    "            file_path = RESIZED_FOLDER + self.labels[i] + \"/\" + file_name\n",
    "\n",
    "            cv2.imwrite(file_path, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prepro = Preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prepro.ImageRead()\n",
    "Prepro.RangeTresholding()\n",
    "Prepro.EdgeDetection()\n",
    "Prepro.FindContour()\n",
    "Prepro.FilterContour()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all Range Thresholded Image\n",
    "\n",
    "rows = 2\n",
    "cols = 5\n",
    "plt.figure(figsize=(20,7))\n",
    "for i in range(len(Prepro.image_range)):\n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    plt.title(Prepro.labels[i])\n",
    "    plt.imshow(Prepro.image_range[i][:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all edged Image\n",
    "\n",
    "rows = 2\n",
    "cols = 5\n",
    "plt.figure(figsize=(20,7))\n",
    "for i in range(len(Prepro.image_edged)):\n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    plt.title(Prepro.labels[i])\n",
    "    plt.imshow(Prepro.image_edged[i], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Prepro.CropByContour()\n",
    "Prepro.Resize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all Resized Image\n",
    "\n",
    "rows = 2\n",
    "cols = 5\n",
    "plt.figure(figsize=(20,7))\n",
    "for i in range(len(Prepro.image_resized)):\n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    plt.title(Prepro.labels[i])\n",
    "    plt.imshow(Prepro.image_resized[i][:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prepro.SaveAllImage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Install library scipy & scikit-image\n",
    "`conda install scipy`\\\n",
    "`conda install scikit-image`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### 1. Statistical Feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Color Mean\n",
    "- Color Mean are extracted from each color channel.<br>\n",
    "<img src=\"resource/Color Mean.png\" ></img><br>\n",
    "<img src=\"resource/mean.gif\" ></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"Tomat.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blue channel\n",
    "img_blue = img[:,:,0]\n",
    "\n",
    "# green channel\n",
    "img_green = img[:,:,1]\n",
    "\n",
    "# red channel\n",
    "img_red = img[:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,6))\n",
    "plt.subplot(1,3,1)\n",
    "plt.title(\"Blue channel\")\n",
    "plt.imshow(img_blue, cmap=\"gray\")\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.title(\"Green channel\")\n",
    "plt.imshow(img_green, cmap=\"gray\")\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.title(\"Red channel\")\n",
    "plt.imshow(img_red, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate color mean\n",
    "\n",
    "color_mean_blue = img_blue.mean()\n",
    "color_mean_green = img_green.mean()\n",
    "color_mean_red = img_red.mean()\n",
    "\n",
    "\n",
    "print(\"Color Mean -> B: %.2f, G: %.2f, R: %.2f\" % (color_mean_blue, color_mean_green, color_mean_red))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Standard Deviation\n",
    "- Standard Deviation are extracted from each color channel. \\\n",
    "<img src=\"resource/Standard Deviation.png\" > </img><br>\n",
    "<img src=\"resource/std.png\" ></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate standard deviation\n",
    "\n",
    "std_blue = img_blue.std()\n",
    "std_green = img_green.std()\n",
    "std_red = img_red.std()\n",
    "\n",
    "\n",
    "print(\"Color Standard Deviation -> B: %.2f, G: %.2f, R: %.2f\" % (std_blue, std_green, std_red))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Skewness\n",
    "- Skewness are extracted from each color channel. <br>\n",
    "<img src=\"resource/Skewness.png\" > </img><br>\n",
    "<img src=\"resource/skew.png\" > </img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "\n",
    "# calculate skewness\n",
    "\n",
    "skew_blue = skew(img_blue.reshape(-1))\n",
    "skew_green = skew(img_green.reshape(-1))\n",
    "skew_red = skew(img_red.reshape(-1))\n",
    "\n",
    "print(\"Color Skewness -> B: %.2f, G: %.2f, R: %.2f\" % (skew_blue, skew_green, skew_red))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **note** : `.reshape(-1)` akan memuad 2D matrix menjadi 1D matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Calculate Mean, STD & Skewness from Background Removed Image (Range Tresholding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define range of red color in HSV\n",
    "lower_red = np.array([-10, 50, 50])\n",
    "upper_red = np.array([10, 255, 255])\n",
    "\n",
    "# define range of green color in HSV\n",
    "lower_green = np.array([30, 25, 25])\n",
    "upper_green = np.array([70, 255, 255])\n",
    "\n",
    "# define range of black color in HSV\n",
    "lower_black = np.array([0, 0, 0])\n",
    "upper_black = np.array([255, 255, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "img = cv2.imread('Tomat.jpg')\n",
    "\n",
    "# convert to hsv\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# apply range thresholding\n",
    "mask_green = cv2.inRange(hsv.copy(), lower_green, upper_green)\n",
    "mask_red = cv2.inRange(hsv.copy(), lower_red, upper_red)\n",
    "mask_black = cv2.inRange(hsv.copy(), lower_black, upper_black)\n",
    "\n",
    "mask = mask_green + mask_red + mask_black \n",
    "res = cv2.bitwise_and(img, img, mask= mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(res[:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blue channel from background removed image\n",
    "img_blue = res[:,:,0]\n",
    "\n",
    "# green channel from background removed image\n",
    "img_green = res[:,:,1]\n",
    "\n",
    "# red channel from background removed image\n",
    "img_red = res[:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate color mean from background removed image\n",
    "\n",
    "color_mean_blue = img_blue.mean()\n",
    "color_mean_green = img_green.mean()\n",
    "color_mean_red = img_red.mean()\n",
    "\n",
    "\n",
    "print(\"Color Mean -> B: %.2f, G: %.2f, R: %.2f\" % (color_mean_blue, color_mean_green, color_mean_red))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate standard deviation from background removed image\n",
    "\n",
    "std_blue = img_blue.std()\n",
    "std_green = img_green.std()\n",
    "std_red = img_red.std()\n",
    "\n",
    "\n",
    "print(\"Color Standard Deviation -> B: %.2f, G: %.2f, R: %.2f\" % (std_blue, std_green, std_red))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate skewness from background removed image\n",
    "\n",
    "skew_blue = skew(img_blue.reshape(-1))\n",
    "skew_green = skew(img_green.reshape(-1))\n",
    "skew_red = skew(img_red.reshape(-1))\n",
    "\n",
    "print(\"Color Skewness -> B: %.2f, G: %.2f, R: %.2f\" % (skew_blue, skew_green, skew_red))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Create class **FeatureExtraction** to calculate Statistical Feature for All Image\n",
    "- Statistical Feature saved as list of dictionary data \n",
    "```\n",
    "[\n",
    "    {\n",
    "    'b' : {\n",
    "            'mean' : xxx,\n",
    "            'std' : xxx,\n",
    "            'skewness` : xxx\n",
    "        },\n",
    "    'g' : {\n",
    "            'mean' : xxx,\n",
    "            'std' : xxx,\n",
    "            'skewness` : xxx\n",
    "        },\n",
    "    'r' : {\n",
    "            'mean' : xxx,\n",
    "            'std' : xxx,\n",
    "            'skewness` : xxx\n",
    "        }\n",
    "    },\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtraction : \n",
    "    def __init__(self, PREPROCESSED_DATASET_FOLDER = \"resized_tomato/\"):\n",
    "        self.labels = []\n",
    "        self.image_list = []\n",
    "        self.statistical_features = []\n",
    "        self.color_ch = ['b', 'g', 'r']\n",
    "        self.PREPROCESSED_DATASET_FOLDER = PREPROCESSED_DATASET_FOLDER\n",
    "        \n",
    "    def ImageRead(self):\n",
    "        for folder in os.listdir(self.PREPROCESSED_DATASET_FOLDER):\n",
    "            for file in os.listdir(self.PREPROCESSED_DATASET_FOLDER + folder):\n",
    "                img = cv2.imread(self.PREPROCESSED_DATASET_FOLDER + folder + \"/\" + file)\n",
    "                self.image_list.append(img)\n",
    "                self.labels.append(folder) # append label (name) of image\n",
    "                \n",
    "    def CalcStatisticalFeature(self):\n",
    "        for img  in self.image_list:\n",
    "            feature_ch = {}\n",
    "            for i in range(len(color_ch)):\n",
    "                feature_ch[color_ch[i]] = {\n",
    "                    'mean' : res[:,:,i].mean(),\n",
    "                    'std' : res[:,:,i].std(),\n",
    "                    'skewness' : skew(res[:,:,i].reshape(-1))\n",
    "                }\n",
    "            \n",
    "            \n",
    "            self.statistical_features.append(feature_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature = FeatureExtraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature.ImageRead()\n",
    "Feature.CalcStatisticalFeature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature.statistical_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature.statistical_features[0]['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature.statistical_features[0]['b']['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature.statistical_features[0]['b']['skewness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# 2. Gray Level Co-occurance Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original Source : [Feature Extraction : Gray Level Co-occurrence Matrix (GLCM)](https://yunusmuhammad007.medium.com/feature-extraction-gray-level-co-occurrence-matrix-glcm-10c45b6d46a1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ilustrasi tekstur pada citra dengan distribusi 50% hitam dan 50% putih. <br>\n",
    "<img src=\"resource/texture.png\"></img><br>\n",
    "- Kalkulasi statistik seperti *mean, median, maupun standar deviasi* tidak akan mampu membedakan ke-3 gambar diatas.\n",
    "- Gray-Level Co-occurrence matrix (GLCM) merupakan teknik analisis **tekstur** pada citra. \n",
    "- GLCM merepresentasikan **hubungan antara 2 pixel** yang bertetanggaan (neighboring pixels) yang memiliki **intensitas keabuan** (grayscale intensity), **jarak** dan **sudut**. \n",
    "- Terdapat 8 sudut yang dapat digunakan pada GLCM, diantaranya sudut 0°, 45°, 90°, 135°, 180°, 225°, 270°, atau 315°.<br>\n",
    "<img src=\"resource/glcm_angel.png\"></img><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Langkah Pembuatan GLCM Matrix\n",
    "- Pembuatan *framework matrix*\n",
    "- Pembuatan *co-occurrence matrix* (mengisi framework matrix)\n",
    "- Pembuatan *symmetric matrix* (penjumlahan co-occurrence matrix dengan transpose matrix)\n",
    "- *Matrix normalization* yang akan menghasilkan nilai matrix antara 0–1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Pembuatan framework matrix**\n",
    "- Misalkan kita memiliki **grayscale matrix** dengan ukuran 3x3, dengan **gray tone 0–3** seperti berikut,<br>\n",
    "<img src=\"resource/gray_matrix.png\"></img><br>\n",
    "- Define **framework matrix** bernilai 0 dengan dimensi 4x4, ukuran ini didapatkan dari **quantization level** matrix diatas,<br>\n",
    "`Quantization level = count(gray tone)`\n",
    "- Sehingga untuk gray tone 0–3 kita mendapatkan **quantization level = 4**, dengan seperti ini kita harusmembuat framework matrix dengan size 4x4,<br>\n",
    "<img src=\"resource/framework_matrix.png\"></img><br>\n",
    "- Tiap posisi pada *framework matrix* merupakan kombinasi nilai pixel pada matrix input 3x3,<br>\n",
    "<img src=\"resource/framework_matrix_pad.png\"></img><br>\n",
    "- Pada **citra digital 8-bit** akan memiliki **quantization level 256**, mengingat gray tone-nya antara 0-255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Pembuatan co-occurrence matrix (mengisi framework matrix)**\n",
    "- Selanjutnya kita akan menggunakan **distance =1** dan **angel =0°** , untuk membentuk *co-occurrence matrix*,<br>\n",
    "<img src=\"resource/gif_glcm.gif\"></img><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Pembuatan symmetric matrix (penjumlahan co-occurrence matrix dengan transpose matrix)**\n",
    "- Setelah itu buatlah *symmetric matrix* dengan **menjumlahkan** GLCM matrix dengan hasil **transpose-nya**,<br>\n",
    "<img src=\"resource/sym_matrix.png\"></img><br>\n",
    "- Hasil penjumlahan GLCM matrix dan hasil transpose-nya,<br>\n",
    "<img src=\"resource/re_sym_matrix.png\"></img><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Matrix normalization yang akan menghasilkan nilai matrix antara 0–1**\n",
    "- lakukan *matrix normalization* pada *symmetric matrix* dengan formula,<br>\n",
    "<img src=\"resource/norm_matrix.png\"></img><br>\n",
    "- Sehingga dihasilkan matrix hasil normalisasinya sebagai berikut,<br>\n",
    "<img src=\"resource/norm_matrix_2.png\"></img><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 GLCM Texture Feature\n",
    "- GLCM texture feature :\n",
    "    - contrast,\n",
    "    - correlation, \n",
    "    - energy,\n",
    "    - homogeneity\n",
    "- The four texture features are extracted from **each color channel** using gray level co-occurrence matrix (GLCM) of the image.<br>\n",
    "<img src=\"resource/GLCM_metric.png\" style=\"width:400px\"></img><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 GLCM implementation using Scikit-Image\n",
    "- Scikit-Image memiliki library untuk perhitungan GLCM pada `skimage.feature` yaitu module `greycomatrix` untuk mendapatkan GLCM matrix, dan `greycoprops` untuk menghitung texture feature pada GLCM,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import greycomatrix, greycoprops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- simple GLCM calculation for 3x3 grayscale image with gray tone 0-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_matrix = np.array([[0, 0, 1],\n",
    "                          [1, 2, 3],\n",
    "                          [2, 3, 2]])\n",
    "\n",
    "glcm = greycomatrix(input_matrix, \n",
    "                    distances=[1],  # distance 1 pixel\n",
    "                    angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],  # angel 0, 45, 90, 135 degre\n",
    "                    levels=4, # number of grey-levels counted\n",
    "                    symmetric=True, \n",
    "                    normed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glcm matrix for angel 0 degre\n",
    "\n",
    "print(glcm[:, :, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glcm matrix for angel 45 degre\n",
    "\n",
    "print(glcm[:, :, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glcm matrix for angel 90 degre\n",
    "\n",
    "print(glcm[:, :, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glcm matrix for angel 135 degre\n",
    "\n",
    "print(glcm[:, :, 0, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculate GLCM feature from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"Tomat.jpg\")\n",
    "\n",
    "# grab blue channel\n",
    "blue = img[:,:,0]\n",
    "\n",
    "# calculate GLCM \n",
    "glcm_img = greycomatrix(blue, \n",
    "                    distances=[1],  # distance 1 pixel\n",
    "                    angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],  # angel 0, 45, 90, 135 degre\n",
    "                    levels=256, # number of grey-levels counted in 8 bit grayscale image\n",
    "                    symmetric=True, \n",
    "                    normed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glcm matrix for angel 0 degre\n",
    "\n",
    "print(glcm_img[:, :, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glcm_img[:, :, 0, 0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 GLCM Texture Feature using Scikit-Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texture_feature_labels = ['correlation', 'homogeneity', 'contrast', 'energy']\n",
    "texture_feature_outputs = []\n",
    "for feature in texture_feature_labels:\n",
    "    out = greycoprops(glcm_img, feature)[0]\n",
    "    texture_feature_outputs.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texture_feature_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLCM texture correlation feature for angel 0, 45, 90, 135 degre\n",
    "texture_feature_outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLCM texture homogeneity feature for angel 0, 45, 90, 135 degre\n",
    "texture_feature_outputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Calculate GLCM Matrix Feature for All Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load croped with background removed image\n",
    "image_list = []\n",
    "labels = []\n",
    "PREPROCESSED_DATASET_FOLDER = \"resized_tomato/\"\n",
    "\n",
    "for folder in os.listdir(PREPROCESSED_DATASET_FOLDER):\n",
    "    for file in os.listdir(PREPROCESSED_DATASET_FOLDER + folder):\n",
    "        img = cv2.imread(PREPROCESSED_DATASET_FOLDER + folder + \"/\" + file)\n",
    "        image_list.append(img)\n",
    "        labels.append(folder) # append label (name) of image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GLCM Matrix saved as list of dictionary data \n",
    "```\n",
    "[\n",
    "    {\n",
    "        'b' : <256x256 glcm matrix>,\n",
    "        'g' : <256x256 glcm matrix>,\n",
    "        'r` : <256x256 glcm matrix>\n",
    "    },\n",
    "    {\n",
    "        'b' : <256x256 glcm matrix>,\n",
    "        'g' : <256x256 glcm matrix>,\n",
    "        'r` : <256x256 glcm matrix>\n",
    "    },\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glcm_matrix_list = []\n",
    "color_ch = ['b', 'g', 'r']\n",
    "\n",
    "for img in image_list:\n",
    "    matrix_ch = {}\n",
    "    for i in range(len(color_ch)):\n",
    "        # grab r, g, b channel\n",
    "        img_ch = img[:,:,i]\n",
    "        \n",
    "        # calculate GLCM \n",
    "        glcm_img = greycomatrix(img_ch, \n",
    "                            distances=[1],  # distance 1 pixel\n",
    "                            angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],  # angel 0, 45, 90, 135 degre\n",
    "                            levels=256, # number of grey-levels counted in 8 bit grayscale image\n",
    "                            symmetric=True, \n",
    "                            normed=True)\n",
    "        \n",
    "        matrix_ch[color_ch[i]] = glcm_img\n",
    "        \n",
    "    glcm_matrix_list.append(matrix_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "glcm_matrix_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "glcm_matrix_list[0]['r']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Calculate GLCM Texture Feature for All GLCM Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GLCM Texture Feature saved as list of dictionary data \n",
    "```\n",
    "[\n",
    "    {\n",
    "    'b' : {\n",
    "            'correlation' : <feature output in angel 0, 45, 90, 135 degre>,\n",
    "            'homogeneity' : <feature output in angel 0, 45, 90, 135 degre>,\n",
    "            'contrast` : <feature output in angel 0, 45, 90, 135 degre>,\n",
    "            'energy' : <feature output in angel 0, 45, 90, 135 degre>\n",
    "        },\n",
    "    'g' : {\n",
    "            'correlation' : <feature output in angel 0, 45, 90, 135 degre>,\n",
    "            'homogeneity' : <feature output in angel 0, 45, 90, 135 degre>,\n",
    "            'contrast` : <feature output in angel 0, 45, 90, 135 degre>,\n",
    "            'energy' : <feature output in angel 0, 45, 90, 135 degre>\n",
    "        },\n",
    "    'r' : {\n",
    "            'correlation' : <feature output in angel 0, 45, 90, 135 degre>,\n",
    "            'homogeneity' : <feature output in angel 0, 45, 90, 135 degre>,\n",
    "            'contrast` : <feature output in angel 0, 45, 90, 135 degre>,\n",
    "            'energy' : <feature output in angel 0, 45, 90, 135 degre>\n",
    "        }\n",
    "    },\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proceed all GLCM matrix feature to produce GLCM Texture Feature\n",
    "color_ch = ['b', 'g', 'r']\n",
    "glcm_feature_list = []\n",
    "texture_feature_labels = ['correlation', 'homogeneity', 'contrast', 'energy']\n",
    "\n",
    "for glcm_matrix in glcm_matrix_list:\n",
    "    feature_ch = {}\n",
    "    for ch in color_ch:\n",
    "        feature_item = {}\n",
    "        for feature in texture_feature_labels:\n",
    "            out = greycoprops(glcm_matrix[ch], feature)[0]\n",
    "            feature_item[feature] = out\n",
    "        feature_ch[ch] = feature_item\n",
    "    glcm_feature_list.append(feature_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result of all GLCM feature for single image\n",
    "\n",
    "glcm_feature_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result of all GLCM feature for single channel in one image\n",
    "\n",
    "glcm_feature_list[0]['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result of GLCM correlation feature for single channel in one image\n",
    "\n",
    "glcm_feature_list[0]['b']['correlation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result of GLCM correlation feature for single channel in one image for specific angel (e.g 0 degre)\n",
    "\n",
    "glcm_feature_list[0]['b']['correlation'][1] # correlation feature in 45 degree angel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "- Tambahkan method **CalcGLCMMatrix** ke class FeatureExtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtraction : \n",
    "    def __init__(self, PREPROCESSED_DATASET_FOLDER = \"resized_tomato/\"):\n",
    "        self.labels = []\n",
    "        self.image_list = []\n",
    "        self.statistical_features = []\n",
    "        self.glcm_matrix_list = []\n",
    "        self.color_ch = ['b', 'g', 'r']\n",
    "        self.PREPROCESSED_DATASET_FOLDER = PREPROCESSED_DATASET_FOLDER\n",
    "        \n",
    "    def ImageRead(self):\n",
    "        for folder in os.listdir(self.PREPROCESSED_DATASET_FOLDER):\n",
    "            for file in os.listdir(self.PREPROCESSED_DATASET_FOLDER + folder):\n",
    "                img = cv2.imread(self.PREPROCESSED_DATASET_FOLDER + folder + \"/\" + file)\n",
    "                self.image_list.append(img)\n",
    "                self.labels.append(folder) # append label (name) of image\n",
    "                \n",
    "    def CalcStatisticalFeature(self):\n",
    "        for img  in self.image_list:\n",
    "            # r, g, b channel from background removed image\n",
    "            img_blue = res[:,:,0]\n",
    "            img_green = res[:,:,1]\n",
    "            img_red = res[:,:,2]\n",
    "\n",
    "            feature = {}\n",
    "            \n",
    "            # calculate color mean from background removed image\n",
    "            feature['mean'] = {\n",
    "                'b' : img_blue.mean(),\n",
    "                'g' : img_green.mean(),\n",
    "                'r' : img_red.mean()\n",
    "            }\n",
    "            \n",
    "            # calculate standard deviation from background removed image\n",
    "            feature['std'] = {\n",
    "                'b' : img_blue.std(),\n",
    "                'g' : img_green.std(),\n",
    "                'r' : img_red.std()\n",
    "            }\n",
    "            \n",
    "            # calculate skewness from background removed image\n",
    "            feature['skewness'] = {\n",
    "                'b' : skew(img_blue.reshape(-1)),\n",
    "                'g' : skew(img_green.reshape(-1)),\n",
    "                'r' : skew(img_red.reshape(-1))\n",
    "            }\n",
    "            \n",
    "            self.statistical_features.append(feature)\n",
    "            \n",
    "    def CalcGLCMMatrix(self):\n",
    "        for img in self.image_list:\n",
    "            #\n",
    "            # Lengkapi bagian ini agar dapat menghitung GLCM Matrix\n",
    "            # \n",
    "            #\n",
    "\n",
    "            self.glcm_matrix_list.append(matrix_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature = FeatureExtraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature.ImageRead()\n",
    "Feature.CalcStatisticalFeature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature.CalcGLCMMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature.glcm_matrix_list[0]['g'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Home Work\n",
    "- Tambahkan Method **CalcGLCMTextureFeature** to class FeatureExtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:opencv_env]",
   "language": "python",
   "name": "conda-env-opencv_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
