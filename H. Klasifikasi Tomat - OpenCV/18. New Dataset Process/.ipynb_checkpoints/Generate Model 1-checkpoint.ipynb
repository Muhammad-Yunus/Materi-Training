{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model 1\n",
    "\n",
    "- 1 sample (6 gambar)-> feature extraction + mlp -> 1 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library \n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import skew\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create folder for original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"Original_Dataset_Tomat/\") :\n",
    "    os.mkdir(\"Original_Dataset_Tomat\")\n",
    "if not os.path.exists(\"Original_Dataset_Test/\") :\n",
    "    os.mkdir(\"Original_Dataset_Test\")\n",
    "    if not os.path.exists(\"Original_Dataset_Test/Test\"):\n",
    "        os.mkdir(\"Original_Dataset_Test/Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- move `Tomat Baik/` & `Tomat Buruk/` dataset folder to `Original_Dataset_Tomat/`\n",
    "- move `Tomat Ujicoba/` dataset folder to `Original_Dataset_Test/Test/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Resize Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = [[\"Original_Dataset_Tomat/\", \"Dataset_Tomat/\"], \n",
    "          [\"Original_Dataset_Test/\", \"Dataset_Test/\"]]\n",
    "\n",
    "for DATASET_FOLDER, TARGET_DATASET_FOLDER in FOLDER :\n",
    "    for folder in os.listdir(DATASET_FOLDER):\n",
    "        for sample in os.listdir(DATASET_FOLDER + folder):\n",
    "            for file in os.listdir(DATASET_FOLDER + folder + \"/\" + sample) :\n",
    "                img = cv2.imread(DATASET_FOLDER + folder + \"/\" + sample + \"/\" + file)\n",
    "                h, w, c = img.shape\n",
    "                pad = (h - w)//2\n",
    "                img = img[pad : -1*pad, :, :]\n",
    "                img = cv2.resize(img, (500,500))\n",
    "                target_dir = TARGET_DATASET_FOLDER + folder + \"/\" + sample + \"/\"\n",
    "                if not os.path.exists(target_dir) :\n",
    "                    os.makedirs(target_dir)\n",
    "                cv2.imwrite(target_dir + file, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# 1. Preprocess Dataset Tomat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing : \n",
    "    def __init__(self, DATASET_FOLDER = \"Dataset_Tomat/\"):\n",
    "        self.labels = []\n",
    "        self.image_list = []\n",
    "        self.image_range = []\n",
    "        self.image_edged = []\n",
    "        self.contours_list = []\n",
    "        self.filtered_contours_list = []\n",
    "        self.image_croped = []\n",
    "        self.image_resized = []\n",
    "        self.DATASET_FOLDER = DATASET_FOLDER\n",
    "        \n",
    "        # define range of red color in HSV\n",
    "        self.lower_red = np.array([-10, 75, 50])\n",
    "        self.upper_red = np.array([10, 255, 255])\n",
    "\n",
    "        # define range of green color in HSV\n",
    "        self.lower_green = np.array([35, 100, 50])\n",
    "        self.upper_green = np.array([70, 255, 255])\n",
    "        \n",
    "        # define range of yellow color in HSV\n",
    "        self.lower_yellow = np.array([10, 125, 50])\n",
    "        self.upper_yellow = np.array([35, 255, 255])\n",
    "        \n",
    "        # define range of black color in HSV\n",
    "        self.lower_black = np.array([0, 0, 0])\n",
    "        self.upper_black = np.array([255, 255, 50])\n",
    "        \n",
    "    def ImageRead(self):\n",
    "        for folder in os.listdir(self.DATASET_FOLDER):\n",
    "            for sample in os.listdir(self.DATASET_FOLDER + folder):\n",
    "                sample_imgs = []\n",
    "                for file in os.listdir(self.DATASET_FOLDER + folder + \"/\" + sample) :\n",
    "                    img = cv2.imread(self.DATASET_FOLDER + folder + \"/\" + sample + \"/\" + file)\n",
    "                    sample_imgs.append(img)\n",
    "                self.image_list.append(sample_imgs)\n",
    "                self.labels.append(folder) # append label (name) of image\n",
    "                            \n",
    "    def RangeTresholding(self):\n",
    "        for sample_imgs in self.image_list : \n",
    "            sample_range_imgs = []\n",
    "            for img in sample_imgs :\n",
    "                # convert to hsv\n",
    "                hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "                # apply range thresholding\n",
    "                mask_green = cv2.inRange(hsv.copy(), self.lower_green, self.upper_green)\n",
    "                mask_red = cv2.inRange(hsv.copy(), self.lower_red, self.upper_red)\n",
    "                mask_yellow = cv2.inRange(hsv.copy(), self.lower_yellow, self.upper_yellow)\n",
    "                mask_black = cv2.inRange(hsv.copy(), self.lower_black, self.upper_black)\n",
    "\n",
    "                mask = mask_green + mask_red + mask_yellow + mask_black \n",
    "                res = cv2.bitwise_and(img, img, mask= mask)\n",
    "                sample_range_imgs.append(res)\n",
    "            self.image_range.append(sample_range_imgs)\n",
    "            \n",
    "    def EdgeDetection(self):\n",
    "        for sample_imgs in self.image_range :\n",
    "            sample_eged_imgs = []\n",
    "            for img in sample_imgs :\n",
    "                edged = cv2.Canny(img, 200, 210)\n",
    "                sample_eged_imgs.append(edged)\n",
    "            self.image_edged.append(sample_eged_imgs)\n",
    "            \n",
    "    def FindContour(self):\n",
    "        for sample_imgs in self.image_edged:\n",
    "            sample_contours = []\n",
    "            for img in sample_imgs:\n",
    "                # find contour\n",
    "                contours, hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "                sample_contours.append(contours)\n",
    "            self.contours_list.append(sample_contours)\n",
    "        self.image_edged = []\n",
    "        \n",
    "    def FilterContour(self, min_area=50, min_w=10, min_h=10):\n",
    "        for sample_contours in self.contours_list:\n",
    "            sample_filtered_contours = []\n",
    "            for contours in sample_contours :\n",
    "                filtered_contours = []\n",
    "                for cnt in contours:\n",
    "                    x, y, w, h = cv2.boundingRect(cnt)\n",
    "                    area = w*h\n",
    "                    if not (area < min_area or w < min_w or h < min_h) :\n",
    "                        filtered_contours.append(cnt)\n",
    "                sample_filtered_contours.append(filtered_contours)\n",
    "            self.filtered_contours_list.append(sample_filtered_contours)\n",
    "        \n",
    "    def CropByContour(self):\n",
    "        for i in range(len(self.image_range)): # crop all removed background image by contour \n",
    "            sample_roi = []\n",
    "            for j in range(len(self.image_range[i])):\n",
    "                img = self.image_range[i][j]\n",
    "                cnt = np.concatenate(self.filtered_contours_list[i][j], axis=0) # concate all remaining contour each image\n",
    "                x, y, w, h = cv2.boundingRect(cnt)\n",
    "                roi = img[y:y+h, x:x+w]\n",
    "                sample_roi.append(roi)\n",
    "            self.image_croped.append(sample_roi)\n",
    "        self.image_range = []        \n",
    "        \n",
    "    def Resize(self, size=(172,172)):\n",
    "        for sample_imgs in self.image_croped:\n",
    "            sample_resize = []\n",
    "            for img in sample_imgs :\n",
    "                resized = cv2.resize(img, (size[0], size[1]))\n",
    "                sample_resize.append(resized)\n",
    "            self.image_resized.append(sample_resize)\n",
    "        self.image_croped = []\n",
    "        \n",
    "    def SaveAllImage(self, RESIZED_FOLDER = \"resized_tomato/\"):\n",
    "        if not os.path.exists(RESIZED_FOLDER) :\n",
    "            os.mkdir(RESIZED_FOLDER)    \n",
    "            \n",
    "        try :\n",
    "            shutil.rmtree(RESIZED_FOLDER)\n",
    "            os.mkdir(RESIZED_FOLDER)\n",
    "        except Exception as e:\n",
    "            print(\"[ERROR] \", e)\n",
    "            \n",
    "        for i in range(len(self.image_resized)):\n",
    "            # check if folder exist. if not, create that folder    \n",
    "            folder_path = RESIZED_FOLDER + self.labels[i] + \"/\"\n",
    "            if not os.path.exists(folder_path) :\n",
    "                os.mkdir(folder_path)\n",
    "                \n",
    "            for j in range(len(self.image_resized[i])):\n",
    "                # get image\n",
    "                img = self.image_resized[i][j]\n",
    "\n",
    "                if img is None :\n",
    "                    continue\n",
    "\n",
    "                # check if folder per sample is exist. if not, create that folder    \n",
    "                sample_path = RESIZED_FOLDER + self.labels[i] + \"/\" + \"sample_%03d\" % i + \"/\"\n",
    "                if not os.path.exists(sample_path) :\n",
    "                    os.mkdir(sample_path)\n",
    "\n",
    "                # save image\n",
    "                file_name = \"img_%03d.jpg\" % j\n",
    "                file_path = sample_path + file_name\n",
    "\n",
    "                cv2.imwrite(file_path, img)\n",
    "        self.image_resized = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prepro = Preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prepro.ImageRead()\n",
    "Prepro.RangeTresholding()\n",
    "Prepro.EdgeDetection()\n",
    "Prepro.FindContour()\n",
    "Prepro.FilterContour()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Prepro.CropByContour()\n",
    "Prepro.Resize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prepro.SaveAllImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# 2. Feature Extraction Dataset Tomat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtraction : \n",
    "    def __init__(self, PREPROCESSED_DATASET_FOLDER = \"resized_tomato/\"):\n",
    "        self.labels = []\n",
    "        self.image_list = []\n",
    "        self.statistical_features = []\n",
    "        self.glcm_matrix_list = []\n",
    "        self.color_ch = ['b', 'g', 'r']\n",
    "        self.glcm_feature_list = []\n",
    "        self.texture_feature_labels = ['correlation', 'homogeneity', 'contrast', 'energy']\n",
    "        self.PREPROCESSED_DATASET_FOLDER = PREPROCESSED_DATASET_FOLDER\n",
    "        \n",
    "    def ImageRead(self):\n",
    "        for folder in os.listdir(self.PREPROCESSED_DATASET_FOLDER):\n",
    "            for sample in os.listdir(self.PREPROCESSED_DATASET_FOLDER + folder):\n",
    "                sample_imgs = []\n",
    "                for file in os.listdir(self.PREPROCESSED_DATASET_FOLDER + folder + \"/\" + sample):\n",
    "                    img = cv2.imread(self.PREPROCESSED_DATASET_FOLDER + folder + \"/\" + sample + \"/\" + file)\n",
    "                    sample_imgs.append(img)\n",
    "                self.image_list.append(sample_imgs)\n",
    "                self.labels.append(folder) # append label (name) of image\n",
    "                \n",
    "    def CalcStatisticalFeature(self):\n",
    "        for sample  in self.image_list:\n",
    "            sample_feature = []\n",
    "            for img in sample : \n",
    "                feature_ch = {}\n",
    "                for i in range(len(self.color_ch)):\n",
    "                    feature_ch[self.color_ch[i]] = {\n",
    "                        'mean' : img[:,:,i].mean(),\n",
    "                        'std' : img[:,:,i].std(),\n",
    "                        'skewness' : skew(img[:,:,i].reshape(-1))\n",
    "                    }\n",
    "                sample_feature.append(feature_ch)\n",
    "            self.statistical_features.append(sample_feature)\n",
    "            \n",
    "    def CalcGLCMMatrix(self):\n",
    "        for sample in self.image_list:\n",
    "            sample_matrix = []\n",
    "            for img in sample :\n",
    "                matrix_ch = {}\n",
    "                for i in range(len(self.color_ch)):\n",
    "                    # grab r, g, b channel\n",
    "                    img_ch = img[:,:,i]\n",
    "\n",
    "                    # calculate GLCM \n",
    "                    glcm_img = greycomatrix(img_ch, \n",
    "                                        distances=[1],  # distance 1 pixel\n",
    "                                        angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],  # angel 0, 45, 90, 135 degre\n",
    "                                        levels=256, # number of grey-levels counted in 8 bit grayscale image\n",
    "                                        symmetric=True, \n",
    "                                        normed=True)\n",
    "\n",
    "                    matrix_ch[self.color_ch[i]] = glcm_img\n",
    "                sample_matrix.append(matrix_ch)\n",
    "            self.glcm_matrix_list.append(sample_matrix)\n",
    "            \n",
    "    def CalcGLCMTextureFeature(self):\n",
    "        for sample_matrix in self.glcm_matrix_list:\n",
    "            sample_feature = []\n",
    "            for glcm_matrix in sample_matrix :\n",
    "                feature_ch = {}\n",
    "                for ch in self.color_ch:\n",
    "                    feature_item = {}\n",
    "                    for feature in self.texture_feature_labels:\n",
    "                        out = greycoprops(glcm_matrix[ch], feature)[0]\n",
    "                        feature_item[feature] = out\n",
    "                    feature_ch[ch] = feature_item\n",
    "                sample_feature.append(feature_ch)\n",
    "            self.glcm_feature_list.append(sample_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature = FeatureExtraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature.ImageRead()\n",
    "Feature.CalcStatisticalFeature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature.CalcGLCMMatrix()\n",
    "Feature.CalcGLCMTextureFeature()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# 3. Postprocssing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Postprocessing :\n",
    "    def __init__ (self, statistical_features, glcm_feature_list, labels):\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        self.X_train = []\n",
    "        self.X_test = [] \n",
    "        self.y_train = []\n",
    "        self.y_test = []\n",
    "        self.statistical_features = statistical_features\n",
    "        self.glcm_feature_list = glcm_feature_list\n",
    "        self.labels = labels\n",
    "        self.labels_name = []\n",
    "        self.labels_vec = []\n",
    "        self.test_size = 0.33\n",
    "        \n",
    "        \n",
    "    def transformX(self):\n",
    "        # transform statistical feature to 2D matrix\n",
    "        x1 = []\n",
    "        for sample in self.statistical_features : \n",
    "            sample_x = []\n",
    "            for channel in sample :\n",
    "                x = []\n",
    "                for feature in list(channel.values()) :\n",
    "                    data = list(feature.values())\n",
    "                    x.extend(data)\n",
    "                sample_x.extend(x)\n",
    "            x1.append(sample_x)\n",
    "\n",
    "        # transform GLCM feature to 2D matrix\n",
    "        x2 = []\n",
    "        for sample in self.glcm_feature_list: \n",
    "            sample_x = []\n",
    "            for channel in sample :\n",
    "                x = []\n",
    "                for features in list(channel.values()):\n",
    "                    item_feature = []\n",
    "                    for item in list(features.values()) :\n",
    "                        item_feature.extend(item)\n",
    "                    x.extend(item_feature)\n",
    "                sample_x.extend(x)\n",
    "            x2.append(sample_x)\n",
    "            \n",
    "        # concate 2d Matrix\n",
    "        x1 = np.array(x1).astype(np.float32)\n",
    "        x2 = np.array(x2).astype(np.float32)\n",
    "        self.X = np.concatenate((x1, x2), axis=1)\n",
    "        print(\"X size :\\n\", self.X.shape)\n",
    "        \n",
    "    def transformY(self):\n",
    "        \n",
    "        enc = OneHotEncoder(handle_unknown='ignore')\n",
    "        y = np.array(self.labels).reshape(-1, 1)\n",
    "        enc.fit(y)\n",
    "        self.labels_name = enc.categories_[0]\n",
    "        print(\"labels_name :\\n\", self.labels_name)\n",
    "        self.labels_vec = enc.transform(y).toarray()\n",
    "        print(\"labels_vec unique :\\n\", np.unique(self.labels_vec))\n",
    "        self.y = np.array(self.labels_vec).astype(np.float32)\n",
    "\n",
    "        print(\"y size :\\n\", self.y.shape)\n",
    "        \n",
    "    def splitData(self):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "                                    self.X, self.y, test_size=self.test_size, random_state=42)\n",
    "        print(\"Split size :\\n\", self.X_train.shape, self.X_test.shape, self.y_train.shape, self.y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X size :\n",
      " (30, 342)\n",
      "labels_name :\n",
      " ['Tomat Baik' 'Tomat Buruk']\n",
      "labels_vec unique :\n",
      " [0. 1.]\n",
      "y size :\n",
      " (30, 2)\n",
      "Split size :\n",
      " (20, 342) (10, 342) (20, 2) (10, 2)\n"
     ]
    }
   ],
   "source": [
    "Postpro = Postprocessing(Feature.statistical_features, \n",
    "                         Feature.glcm_feature_list, \n",
    "                         Feature.labels)\n",
    "\n",
    "Postpro.transformX()\n",
    "Postpro.transformY()\n",
    "Postpro.splitData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6 image/sample x 3 channel x 3 stat feature = 54\n",
    "# 6 image/sample x 3 channel x 4 feature x 4 angel = 288\n",
    "\n",
    "6*3*3 + 4*4*3*6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# 4. Training Model Klasifikasi Tomat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingMLP:\n",
    "    def __init__(self, X_train, y_train, X_test, y_test, labels_vec, labels_name, max_iteartion=100, min_accuracy=0.9, input_dim=2):\n",
    "        self.mlp = cv2.ml.ANN_MLP_create()\n",
    "        \n",
    "        input_dim = X_train.shape[1] if X_train is not None else input_dim\n",
    "        output_dim = len(labels_name)\n",
    "        print(\"dim\", input_dim, output_dim)\n",
    "        network_layer = np.array([input_dim, 32, output_dim]).astype(np.uint0)\n",
    "        self.mlp.setLayerSizes(network_layer)\n",
    "        self.mlp.setActivationFunction(cv2.ml.ANN_MLP_SIGMOID_SYM)\n",
    "        self.mlp.setTrainMethod(cv2.ml.ANN_MLP_BACKPROP)\n",
    "        \n",
    "        # set term criteria : maximum 100 iteration or stop when achieve 90% accuracy\n",
    "        self.mlp.setTermCriteria((cv2.TERM_CRITERIA_MAX_ITER + cv2.TERM_CRITERIA_EPS, max_iteartion, min_accuracy))\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.y_pred = []\n",
    "        self.labels_vec = labels_vec\n",
    "        self.labels_name = labels_name\n",
    "        \n",
    "        self.base_path = os.path.expanduser('~/Tomato Grading Systems')\n",
    "        if not os.path.exists(self.base_path):\n",
    "            os.mkdir(self.base_path)\n",
    "        self.model_name = os.path.join(self.base_path, 'klasifikasi_tomat_mlp_model.xml')\n",
    "        \n",
    "    def train(self):\n",
    "        self.mlp.train(self.X_train, cv2.ml.ROW_SAMPLE, self.y_train)\n",
    "        self.mlp.save(self.model_name)\n",
    "        \n",
    "    def validate(self, title='Confusion matrix - Klasifikasi Tomat'):\n",
    "        self.mlp.load(self.model_name)\n",
    "        self.y_pred = self.mlp.predict(self.X_test)[1]\n",
    "        \n",
    "        # Compute confusion matrix\n",
    "        cnf_matrix = confusion_matrix(self.y_test.argmax(axis=1), self.y_pred.argmax(axis=1), labels=np.unique(self.labels_vec))\n",
    "        np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "        # Plot non-normalized confusion matrix\n",
    "        self.plot_confusion_matrix(cnf_matrix, classes=self.labels_name, normalize=False,\n",
    "                              title=title)\n",
    "        \n",
    "        # Print Classification Report\n",
    "        print(classification_report(self.y_test.argmax(axis=1), \n",
    "                                    self.y_pred.argmax(axis=1), \n",
    "                                    target_names=self.labels_name))\n",
    "        \n",
    "        report = classification_report(self.y_test.argmax(axis=1), \n",
    "                                    self.y_pred.argmax(axis=1), \n",
    "                                    target_names=self.labels_name)\n",
    "\n",
    "        report_path = os.path.join(self.base_path, 'Report %s.txt' % title)\n",
    "        with open(report_path, \"w\") as text_file:\n",
    "            text_file.write(report)\n",
    "        \n",
    "        \n",
    "    def plot_confusion_matrix(self, cm, classes,\n",
    "                              normalize=False,\n",
    "                              title='Confusion matrix',\n",
    "                              cmap=plt.cm.Blues):\n",
    "        if normalize:\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "        plt.figure(figsize=(5, 4))\n",
    "\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "        plt.title(title)\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(classes))\n",
    "        plt.xticks(tick_marks, classes, rotation=45)\n",
    "        plt.yticks(tick_marks, classes)\n",
    "\n",
    "        fmt = '.2f' if normalize else 'd'\n",
    "        thresh = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            plt.text(j, i, format(cm[i, j], fmt),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        \n",
    "        cm_path = os.path.join(self.base_path, '%s.png' % title)\n",
    "        plt.savefig(cm_path, bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim 342 2\n"
     ]
    }
   ],
   "source": [
    "mlp_model = TrainingMLP(Postpro.X_train, \n",
    "                      Postpro.y_train, \n",
    "                      Postpro.X_test, \n",
    "                      Postpro.y_test, \n",
    "                      Postpro.labels_vec, \n",
    "                      Postpro.labels_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Tomat Baik       0.80      1.00      0.89         4\n",
      " Tomat Buruk       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.90        10\n",
      "   macro avg       0.90      0.92      0.90        10\n",
      "weighted avg       0.92      0.90      0.90        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp_model.train()\n",
    "mlp_model.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:opencv_env]",
   "language": "python",
   "name": "conda-env-opencv_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
