{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model 1\n",
    "\n",
    "- 1 sample (6 gambar)-> feature extraction + mlp -> 1 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library \n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import skew\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create folder for original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"Original_Dataset_Tomat/\") :\n",
    "    os.mkdir(\"Original_Dataset_Tomat\")\n",
    "if not os.path.exists(\"Original_Dataset_Test/\") :\n",
    "    os.mkdir(\"Original_Dataset_Test\")\n",
    "    if not os.path.exists(\"Original_Dataset_Test/Test\"):\n",
    "        os.mkdir(\"Original_Dataset_Test/Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- move `Tomat Baik/` & `Tomat Buruk/` dataset folder to `Original_Dataset_Tomat/`\n",
    "- move `Tomat Ujicoba/` dataset folder to `Original_Dataset_Test/Test/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Resize Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = [[\"Original_Dataset_Tomat/\", \"Dataset_Tomat/\"], \n",
    "          [\"Original_Dataset_Test/\", \"Dataset_Test/\"]]\n",
    "\n",
    "for DATASET_FOLDER, TARGET_DATASET_FOLDER in FOLDER :\n",
    "    for folder in os.listdir(DATASET_FOLDER):\n",
    "        for sample in os.listdir(DATASET_FOLDER + folder):\n",
    "            for file in os.listdir(DATASET_FOLDER + folder + \"/\" + sample) :\n",
    "                img = cv2.imread(DATASET_FOLDER + folder + \"/\" + sample + \"/\" + file)\n",
    "                h, w, c = img.shape\n",
    "                pad = (h - w)//2\n",
    "                img = img[pad : -1*pad, :, :]\n",
    "                img = cv2.resize(img, (500,500))\n",
    "                target_dir = TARGET_DATASET_FOLDER + folder + \"/\" + sample + \"/\"\n",
    "                if not os.path.exists(target_dir) :\n",
    "                    os.makedirs(target_dir)\n",
    "                cv2.imwrite(target_dir + file, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# 1. Preprocess Dataset Tomat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing : \n",
    "    def __init__(self, DATASET_FOLDER = \"Dataset_Tomat/\"):\n",
    "        self.labels = []\n",
    "        self.image_list = []\n",
    "        self.image_range = []\n",
    "        self.image_edged = []\n",
    "        self.contours_list = []\n",
    "        self.filtered_contours_list = []\n",
    "        self.image_croped = []\n",
    "        self.image_resized = []\n",
    "        self.DATASET_FOLDER = DATASET_FOLDER\n",
    "        \n",
    "        # define range of red color in HSV\n",
    "        self.lower_red = np.array([-10, 75, 50])\n",
    "        self.upper_red = np.array([10, 255, 255])\n",
    "\n",
    "        # define range of green color in HSV\n",
    "        self.lower_green = np.array([35, 100, 50])\n",
    "        self.upper_green = np.array([70, 255, 255])\n",
    "        \n",
    "        # define range of yellow color in HSV\n",
    "        self.lower_yellow = np.array([10, 125, 50])\n",
    "        self.upper_yellow = np.array([35, 255, 255])\n",
    "        \n",
    "        # define range of black color in HSV\n",
    "        self.lower_black = np.array([0, 0, 0])\n",
    "        self.upper_black = np.array([255, 255, 50])\n",
    "        \n",
    "    def ImageRead(self):\n",
    "        for folder in os.listdir(self.DATASET_FOLDER):\n",
    "            for sample in os.listdir(self.DATASET_FOLDER + folder):\n",
    "                sample_imgs = []\n",
    "                for file in os.listdir(self.DATASET_FOLDER + folder + \"/\" + sample) :\n",
    "                    img = cv2.imread(self.DATASET_FOLDER + folder + \"/\" + sample + \"/\" + file)\n",
    "                    sample_imgs.append(img)\n",
    "                self.image_list.append(sample_imgs)\n",
    "                self.labels.append(folder) # append label (name) of image\n",
    "                            \n",
    "    def RangeTresholding(self):\n",
    "        for sample_imgs in self.image_list : \n",
    "            sample_range_imgs = []\n",
    "            for img in sample_imgs :\n",
    "                # convert to hsv\n",
    "                hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "                # apply range thresholding\n",
    "                mask_green = cv2.inRange(hsv.copy(), self.lower_green, self.upper_green)\n",
    "                mask_red = cv2.inRange(hsv.copy(), self.lower_red, self.upper_red)\n",
    "                mask_yellow = cv2.inRange(hsv.copy(), self.lower_yellow, self.upper_yellow)\n",
    "                mask_black = cv2.inRange(hsv.copy(), self.lower_black, self.upper_black)\n",
    "\n",
    "                mask = mask_green + mask_red + mask_yellow + mask_black \n",
    "                res = cv2.bitwise_and(img, img, mask= mask)\n",
    "                sample_range_imgs.append(res)\n",
    "            self.image_range.append(sample_range_imgs)\n",
    "            \n",
    "    def EdgeDetection(self):\n",
    "        for sample_imgs in self.image_range :\n",
    "            sample_eged_imgs = []\n",
    "            for img in sample_imgs :\n",
    "                edged = cv2.Canny(img, 200, 210)\n",
    "                sample_eged_imgs.append(edged)\n",
    "            self.image_edged.append(sample_eged_imgs)\n",
    "            \n",
    "    def FindContour(self):\n",
    "        for sample_imgs in self.image_edged:\n",
    "            sample_contours = []\n",
    "            for img in sample_imgs:\n",
    "                # find contour\n",
    "                contours, hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "                sample_contours.append(contours)\n",
    "            self.contours_list.append(sample_contours)\n",
    "        self.image_edged = []\n",
    "        \n",
    "    def FilterContour(self, min_area=50, min_w=10, min_h=10):\n",
    "        for sample_contours in self.contours_list:\n",
    "            sample_filtered_contours = []\n",
    "            for contours in sample_contours :\n",
    "                filtered_contours = []\n",
    "                for cnt in contours:\n",
    "                    x, y, w, h = cv2.boundingRect(cnt)\n",
    "                    area = w*h\n",
    "                    if not (area < min_area or w < min_w or h < min_h) :\n",
    "                        filtered_contours.append(cnt)\n",
    "                sample_filtered_contours.append(filtered_contours)\n",
    "            self.filtered_contours_list.append(sample_filtered_contours)\n",
    "        \n",
    "    def CropByContour(self):\n",
    "        for i in range(len(self.image_range)): # crop all removed background image by contour \n",
    "            sample_roi = []\n",
    "            for j in range(len(self.image_range[i])):\n",
    "                img = self.image_range[i][j]\n",
    "                cnt = np.concatenate(self.filtered_contours_list[i][j], axis=0) # concate all remaining contour each image\n",
    "                x, y, w, h = cv2.boundingRect(cnt)\n",
    "                roi = img[y:y+h, x:x+w]\n",
    "                sample_roi.append(roi)\n",
    "            self.image_croped.append(sample_roi)\n",
    "        self.image_range = []        \n",
    "        \n",
    "    def Resize(self, size=(172,172)):\n",
    "        for sample_imgs in self.image_croped:\n",
    "            sample_resize = []\n",
    "            for img in sample_imgs :\n",
    "                resized = cv2.resize(img, (size[0], size[1]))\n",
    "                sample_resize.append(resized)\n",
    "            self.image_resized.append(sample_resize)\n",
    "        self.image_croped = []\n",
    "        \n",
    "    def SaveAllImage(self, RESIZED_FOLDER = \"resized_tomato/\"):\n",
    "        if not os.path.exists(RESIZED_FOLDER) :\n",
    "            os.mkdir(RESIZED_FOLDER)    \n",
    "            \n",
    "        try :\n",
    "            shutil.rmtree(RESIZED_FOLDER)\n",
    "            os.mkdir(RESIZED_FOLDER)\n",
    "        except Exception as e:\n",
    "            print(\"[ERROR] \", e)\n",
    "            \n",
    "        for i in range(len(self.image_resized)):\n",
    "            # check if folder exist. if not, create that folder    \n",
    "            folder_path = RESIZED_FOLDER + self.labels[i] + \"/\"\n",
    "            if not os.path.exists(folder_path) :\n",
    "                os.mkdir(folder_path)\n",
    "                \n",
    "            for j in range(len(self.image_resized[i])):\n",
    "                # get image\n",
    "                img = self.image_resized[i][j]\n",
    "\n",
    "                if img is None :\n",
    "                    continue\n",
    "\n",
    "                # check if folder per sample is exist. if not, create that folder    \n",
    "                sample_path = RESIZED_FOLDER + self.labels[i] + \"/\" + \"sample_%03d\" % i + \"/\"\n",
    "                if not os.path.exists(sample_path) :\n",
    "                    os.mkdir(sample_path)\n",
    "\n",
    "                # save image\n",
    "                file_name = \"img_%03d.jpg\" % j\n",
    "                file_path = sample_path + file_name\n",
    "\n",
    "                cv2.imwrite(file_path, img)\n",
    "        self.image_resized = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prepro = Preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prepro.ImageRead()\n",
    "Prepro.RangeTresholding()\n",
    "Prepro.EdgeDetection()\n",
    "Prepro.FindContour()\n",
    "Prepro.FilterContour()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Prepro.CropByContour()\n",
    "Prepro.Resize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prepro.SaveAllImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# 2. Feature Extraction Dataset Tomat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtraction : \n",
    "    def __init__(self, PREPROCESSED_DATASET_FOLDER = \"resized_tomato/\"):\n",
    "        self.labels = []\n",
    "        self.image_list = []\n",
    "        self.statistical_features = []\n",
    "        self.glcm_matrix_list = []\n",
    "        self.color_ch = ['b', 'g', 'r']\n",
    "        self.glcm_feature_list = []\n",
    "        self.texture_feature_labels = ['correlation', 'homogeneity', 'contrast', 'energy']\n",
    "        self.PREPROCESSED_DATASET_FOLDER = PREPROCESSED_DATASET_FOLDER\n",
    "        \n",
    "    def ImageRead(self):\n",
    "        for folder in os.listdir(self.PREPROCESSED_DATASET_FOLDER):\n",
    "            for sample in os.listdir(self.PREPROCESSED_DATASET_FOLDER + folder):\n",
    "                sample_imgs = []\n",
    "                for file in os.listdir(self.PREPROCESSED_DATASET_FOLDER + folder + \"/\" + sample):\n",
    "                    img = cv2.imread(self.PREPROCESSED_DATASET_FOLDER + folder + \"/\" + sample + \"/\" + file)\n",
    "                    sample_imgs.append(img)\n",
    "                self.image_list.append(sample_imgs)\n",
    "                self.labels.append(folder) # append label (name) of image\n",
    "                \n",
    "    def CalcStatisticalFeature(self):\n",
    "        for sample  in self.image_list:\n",
    "            sample_feature = []\n",
    "            for img in sample : \n",
    "                feature_ch = {}\n",
    "                for i in range(len(self.color_ch)):\n",
    "                    feature_ch[self.color_ch[i]] = {\n",
    "                        'mean' : img[:,:,i].mean(),\n",
    "                        'std' : img[:,:,i].std(),\n",
    "                        'skewness' : skew(img[:,:,i].reshape(-1))\n",
    "                    }\n",
    "                sample_feature.append(feature_ch)\n",
    "            self.statistical_features.append(sample_feature)\n",
    "            \n",
    "    def CalcGLCMMatrix(self):\n",
    "        for sample in self.image_list:\n",
    "            sample_matrix = []\n",
    "            for img in sample :\n",
    "                matrix_ch = {}\n",
    "                for i in range(len(self.color_ch)):\n",
    "                    # grab r, g, b channel\n",
    "                    img_ch = img[:,:,i]\n",
    "\n",
    "                    # calculate GLCM \n",
    "                    glcm_img = greycomatrix(img_ch, \n",
    "                                        distances=[1],  # distance 1 pixel\n",
    "                                        angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],  # angel 0, 45, 90, 135 degre\n",
    "                                        levels=256, # number of grey-levels counted in 8 bit grayscale image\n",
    "                                        symmetric=True, \n",
    "                                        normed=True)\n",
    "\n",
    "                    matrix_ch[self.color_ch[i]] = glcm_img\n",
    "                sample_matrix.append(matrix_ch)\n",
    "            self.glcm_matrix_list.append(sample_matrix)\n",
    "            \n",
    "    def CalcGLCMTextureFeature(self):\n",
    "        for sample_matrix in self.glcm_matrix_list:\n",
    "            sample_feature = []\n",
    "            for glcm_matrix in sample_matrix :\n",
    "                feature_ch = {}\n",
    "                for ch in self.color_ch:\n",
    "                    feature_item = {}\n",
    "                    for feature in self.texture_feature_labels:\n",
    "                        out = greycoprops(glcm_matrix[ch], feature)[0]\n",
    "                        feature_item[feature] = out\n",
    "                    feature_ch[ch] = feature_item\n",
    "                sample_feature.append(feature_ch)\n",
    "            self.glcm_feature_list.append(sample_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature = FeatureExtraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature.ImageRead()\n",
    "Feature.CalcStatisticalFeature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature.CalcGLCMMatrix()\n",
    "Feature.CalcGLCMTextureFeature()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# 3. Postprocssing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Postprocessing :\n",
    "    def __init__ (self, statistical_features, glcm_feature_list, labels):\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        self.X_train = []\n",
    "        self.X_test = [] \n",
    "        self.y_train = []\n",
    "        self.y_test = []\n",
    "        self.statistical_features = statistical_features\n",
    "        self.glcm_feature_list = glcm_feature_list\n",
    "        self.labels = labels\n",
    "        self.labels_name = []\n",
    "        self.labels_vec = []\n",
    "        self.test_size = 0.33\n",
    "        \n",
    "        \n",
    "    def transformX(self):\n",
    "        # transform statistical feature to 2D matrix\n",
    "        x1 = []\n",
    "        for sample in self.statistical_features : \n",
    "            sample_x = []\n",
    "            for channel in sample :\n",
    "                x = []\n",
    "                for feature in list(channel.values()) :\n",
    "                    data = list(feature.values())\n",
    "                    x.extend(data)\n",
    "                sample_x.extend(x)\n",
    "            x1.append(sample_x)\n",
    "\n",
    "        # transform GLCM feature to 2D matrix\n",
    "        x2 = []\n",
    "        for sample in self.glcm_feature_list: \n",
    "            sample_x = []\n",
    "            for channel in sample :\n",
    "                x = []\n",
    "                for features in list(channel.values()):\n",
    "                    item_feature = []\n",
    "                    for item in list(features.values()) :\n",
    "                        item_feature.extend(item)\n",
    "                    x.extend(item_feature)\n",
    "                sample_x.extend(x)\n",
    "            x2.append(sample_x)\n",
    "            \n",
    "        # concate 2d Matrix\n",
    "        x1 = np.array(x1).astype(np.float32)\n",
    "        x2 = np.array(x2).astype(np.float32)\n",
    "        self.X = np.concatenate((x1, x2), axis=1)\n",
    "        print(\"X size :\\n\", self.X.shape)\n",
    "        \n",
    "    def transformY(self):\n",
    "        le = LabelEncoder()\n",
    "        le.fit(self.labels)\n",
    "        self.labels_name = le.classes_\n",
    "        print(\"labels_name :\\n\", self.labels_name)\n",
    "        \n",
    "        self.labels_vec = le.transform(self.labels)\n",
    "        self.y = np.array(self.labels_vec).astype(np.float32)\n",
    "        print(\"y size :\\n\", self.y.shape)\n",
    "        \n",
    "    def splitData(self):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "                                    self.X, self.y, test_size=self.test_size, random_state=42)\n",
    "        print(\"Split size :\\n\", self.X_train.shape, self.X_test.shape, self.y_train.shape, self.y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X size :\n",
      " (30, 342)\n",
      "labels_name :\n",
      " ['Tomat Baik' 'Tomat Buruk']\n",
      "y size :\n",
      " (30,)\n",
      "Split size :\n",
      " (20, 342) (10, 342) (20,) (10,)\n"
     ]
    }
   ],
   "source": [
    "Postpro = Postprocessing(Feature.statistical_features, \n",
    "                         Feature.glcm_feature_list, \n",
    "                         Feature.labels)\n",
    "\n",
    "Postpro.transformX()\n",
    "Postpro.transformY()\n",
    "Postpro.splitData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6 image/sample x 3 channel x 3 stat feature = 54\n",
    "# 6 image/sample x 3 channel x 4 feature x 4 angel = 288\n",
    "\n",
    "6*3*3 + 4*4*3*6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# 4. Training Model Klasifikasi Tomat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingMLP:\n",
    "    def __init__(self, X_train, y_train, X_test, y_test, labels_vec, labels_name, max_iteartion=100, min_accuracy=0.9):\n",
    "        self.mlp = cv2.ml.ANN_MLP_create()\n",
    "        \n",
    "        input_dim = X_train.shape[1]\n",
    "        network_layer = np.array([input_dim, 128, 1]).astype(np.uint16)\n",
    "        self.mlp.setLayerSizes(network_layer)\n",
    "        self.mlp.setActivationFunction(cv2.ml.ANN_MLP_SIGMOID_SYM)\n",
    "        self.mlp.setTrainMethod(cv2.ml.ANN_MLP_BACKPROP)\n",
    "        \n",
    "        # set term criteria : maximum 100 iteration or stop when achieve 90% accuracy\n",
    "        self.mlp.setTermCriteria((cv2.TERM_CRITERIA_MAX_ITER + cv2.TERM_CRITERIA_EPS, max_iteartion, min_accuracy))\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.labels_vec = labels_vec\n",
    "        self.labels_name = labels_name\n",
    "        \n",
    "        self.model_name = \"klasifikasi_tomat_mlp_model_1.xml\"\n",
    "        \n",
    "    def train(self):\n",
    "        self.mlp.train(self.X_train, cv2.ml.ROW_SAMPLE, self.y_train)\n",
    "        self.mlp.save(self.model_name)\n",
    "        \n",
    "    def validate(self):\n",
    "        self.mlp.load(self.model_name)\n",
    "        y_pred = self.mlp.predict(self.X_test)[1].round().reshape(-1)\n",
    "        \n",
    "        # Compute confusion matrix\n",
    "        cnf_matrix = confusion_matrix(self.y_test, y_pred, labels=np.unique(self.labels_vec))\n",
    "        np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "        # Plot non-normalized confusion matrix\n",
    "        self.plot_confusion_matrix(cnf_matrix, classes=self.labels_name, normalize=False,\n",
    "                              title='Confusion matrix - Klasifikasi Tomat')\n",
    "        \n",
    "        print(classification_report(self.y_test, \n",
    "                                    y_pred, \n",
    "                                    target_names=self.labels_name))\n",
    "        \n",
    "        \n",
    "    def plot_confusion_matrix(self, cm, classes,\n",
    "                              normalize=False,\n",
    "                              title='Confusion matrix',\n",
    "                              cmap=plt.cm.Blues):\n",
    "        if normalize:\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "        plt.figure(figsize=(6, 6))\n",
    "\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "        plt.title(title)\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(classes))\n",
    "        plt.xticks(tick_marks, classes, rotation=45)\n",
    "        plt.yticks(tick_marks, classes)\n",
    "\n",
    "        fmt = '.2f' if normalize else 'd'\n",
    "        thresh = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            plt.text(j, i, format(cm[i, j], fmt),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = TrainingMLP(Postpro.X_train, \n",
    "                      Postpro.y_train, \n",
    "                      Postpro.X_test, \n",
    "                      Postpro.y_test, \n",
    "                      Postpro.labels_vec, \n",
    "                      Postpro.labels_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Tomat Baik       0.80      1.00      0.89         4\n",
      " Tomat Buruk       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.90        10\n",
      "   macro avg       0.90      0.92      0.90        10\n",
      "weighted avg       0.92      0.90      0.90        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp_model.train()\n",
    "mlp_model.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:opencv_env]",
   "language": "python",
   "name": "conda-env-opencv_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
