{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model 2\n",
    "\n",
    "- 6 gambar (sample) -> feature extraction + mlp -> 6 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library \n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import skew\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create folder for original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"Original_Dataset_Tomat/\") :\n",
    "    os.mkdir(\"Original_Dataset_Tomat\")\n",
    "if not os.path.exists(\"Original_Dataset_Test/\") :\n",
    "    os.mkdir(\"Original_Dataset_Test\")\n",
    "    if not os.path.exists(\"Original_Dataset_Test/Test\"):\n",
    "        os.mkdir(\"Original_Dataset_Test/Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- move `Tomat Baik/` & `Tomat Buruk/` dataset folder to `Original_Dataset_Tomat/`\n",
    "- move `Tomat Ujicoba/` dataset folder to `Original_Dataset_Test/Test/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Resize Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = [[\"Original_Dataset_Tomat/\", \"Dataset_Tomat/\"], \n",
    "          [\"Original_Dataset_Test/\", \"Dataset_Test/\"]]\n",
    "\n",
    "for DATASET_FOLDER, TARGET_DATASET_FOLDER in FOLDER :\n",
    "    for folder in os.listdir(DATASET_FOLDER):\n",
    "        for sample in os.listdir(DATASET_FOLDER + folder):\n",
    "            for file in os.listdir(DATASET_FOLDER + folder + \"/\" + sample) :\n",
    "                img = cv2.imread(DATASET_FOLDER + folder + \"/\" + sample + \"/\" + file)\n",
    "                h, w, c = img.shape\n",
    "                pad = (h - w)//2\n",
    "                img = img[pad : -1*pad, :, :]\n",
    "                img = cv2.resize(img, (500,500))\n",
    "                target_dir = TARGET_DATASET_FOLDER + folder + \"/\" + sample + \"/\"\n",
    "                if not os.path.exists(target_dir) :\n",
    "                    os.makedirs(target_dir)\n",
    "                cv2.imwrite(target_dir + file, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# 1. Preprocess Dataset Tomat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing : \n",
    "    def __init__(self, DATASET_FOLDER = \"Dataset_Tomat/\"):\n",
    "        self.labels = []\n",
    "        self.image_list = []\n",
    "        self.image_range = []\n",
    "        self.image_edged = []\n",
    "        self.contours_list = []\n",
    "        self.filtered_contours_list = []\n",
    "        self.image_croped = []\n",
    "        self.image_resized = []\n",
    "        self.DATASET_FOLDER = DATASET_FOLDER\n",
    "        \n",
    "        # define range of red color in HSV\n",
    "        self.lower_red = np.array([-10, 75, 50])\n",
    "        self.upper_red = np.array([10, 255, 255])\n",
    "\n",
    "        # define range of green color in HSV\n",
    "        self.lower_green = np.array([35, 100, 50])\n",
    "        self.upper_green = np.array([70, 255, 255])\n",
    "        \n",
    "        # define range of yellow color in HSV\n",
    "        self.lower_yellow = np.array([10, 125, 50])\n",
    "        self.upper_yellow = np.array([35, 255, 255])\n",
    "        \n",
    "        # define range of black color in HSV\n",
    "        self.lower_black = np.array([0, 0, 0])\n",
    "        self.upper_black = np.array([255, 255, 50])\n",
    "        \n",
    "    def ImageRead(self):\n",
    "        for folder in os.listdir(self.DATASET_FOLDER):\n",
    "            for sample in os.listdir(self.DATASET_FOLDER + folder):\n",
    "                sample_imgs = []\n",
    "                for file in os.listdir(self.DATASET_FOLDER + folder + \"/\" + sample) :\n",
    "                    img = cv2.imread(self.DATASET_FOLDER + folder + \"/\" + sample + \"/\" + file)\n",
    "                    sample_imgs.append(img)\n",
    "                self.image_list.append(sample_imgs)\n",
    "                self.labels.append(folder) # append label (name) of image\n",
    "                            \n",
    "    def RangeTresholding(self):\n",
    "        for sample_imgs in self.image_list : \n",
    "            sample_range_imgs = []\n",
    "            for img in sample_imgs :\n",
    "                # convert to hsv\n",
    "                hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "                # apply range thresholding\n",
    "                mask_green = cv2.inRange(hsv.copy(), self.lower_green, self.upper_green)\n",
    "                mask_red = cv2.inRange(hsv.copy(), self.lower_red, self.upper_red)\n",
    "                mask_yellow = cv2.inRange(hsv.copy(), self.lower_yellow, self.upper_yellow)\n",
    "                mask_black = cv2.inRange(hsv.copy(), self.lower_black, self.upper_black)\n",
    "\n",
    "                mask = mask_green + mask_red + mask_yellow + mask_black \n",
    "                res = cv2.bitwise_and(img, img, mask= mask)\n",
    "                sample_range_imgs.append(res)\n",
    "            self.image_range.append(sample_range_imgs)\n",
    "            \n",
    "    def EdgeDetection(self):\n",
    "        for sample_imgs in self.image_range :\n",
    "            sample_eged_imgs = []\n",
    "            for img in sample_imgs :\n",
    "                edged = cv2.Canny(img, 200, 210)\n",
    "                sample_eged_imgs.append(edged)\n",
    "            self.image_edged.append(sample_eged_imgs)\n",
    "            \n",
    "    def FindContour(self):\n",
    "        for sample_imgs in self.image_edged:\n",
    "            sample_contours = []\n",
    "            for img in sample_imgs:\n",
    "                # find contour\n",
    "                contours, hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "                sample_contours.append(contours)\n",
    "            self.contours_list.append(sample_contours)\n",
    "        self.image_edged = []\n",
    "        \n",
    "    def FilterContour(self, min_area=50, min_w=10, min_h=10):\n",
    "        for sample_contours in self.contours_list:\n",
    "            sample_filtered_contours = []\n",
    "            for contours in sample_contours :\n",
    "                filtered_contours = []\n",
    "                for cnt in contours:\n",
    "                    x, y, w, h = cv2.boundingRect(cnt)\n",
    "                    area = w*h\n",
    "                    if not (area < min_area or w < min_w or h < min_h) :\n",
    "                        filtered_contours.append(cnt)\n",
    "                sample_filtered_contours.append(filtered_contours)\n",
    "            self.filtered_contours_list.append(sample_filtered_contours)\n",
    "        \n",
    "    def CropByContour(self):\n",
    "        for i in range(len(self.image_range)): # crop all removed background image by contour \n",
    "            sample_roi = []\n",
    "            for j in range(len(self.image_range[i])):\n",
    "                img = self.image_range[i][j]\n",
    "                cnt = np.concatenate(self.filtered_contours_list[i][j], axis=0) # concate all remaining contour each image\n",
    "                x, y, w, h = cv2.boundingRect(cnt)\n",
    "                roi = img[y:y+h, x:x+w]\n",
    "                sample_roi.append(roi)\n",
    "            self.image_croped.append(sample_roi)\n",
    "        self.image_range = []        \n",
    "        \n",
    "    def Resize(self, size=(172,172)):\n",
    "        for sample_imgs in self.image_croped:\n",
    "            sample_resize = []\n",
    "            for img in sample_imgs :\n",
    "                resized = cv2.resize(img, (size[0], size[1]))\n",
    "                sample_resize.append(resized)\n",
    "            self.image_resized.append(sample_resize)\n",
    "        self.image_croped = []\n",
    "        \n",
    "    def SaveAllImage(self, RESIZED_FOLDER = \"resized_tomato/\"):\n",
    "        if not os.path.exists(RESIZED_FOLDER) :\n",
    "            os.mkdir(RESIZED_FOLDER)    \n",
    "            \n",
    "        try :\n",
    "            shutil.rmtree(RESIZED_FOLDER)\n",
    "            os.mkdir(RESIZED_FOLDER)\n",
    "        except Exception as e:\n",
    "            print(\"[ERROR] \", e)\n",
    "            \n",
    "        for i in range(len(self.image_resized)):\n",
    "            # check if folder exist. if not, create that folder    \n",
    "            folder_path = RESIZED_FOLDER + self.labels[i] + \"/\"\n",
    "            if not os.path.exists(folder_path) :\n",
    "                os.mkdir(folder_path)\n",
    "                \n",
    "            for j in range(len(self.image_resized[i])):\n",
    "                # get image\n",
    "                img = self.image_resized[i][j]\n",
    "\n",
    "                if img is None :\n",
    "                    continue\n",
    "\n",
    "                # check if folder per sample is exist. if not, create that folder    \n",
    "                sample_path = RESIZED_FOLDER + self.labels[i] + \"/\" + \"sample_%03d\" % i + \"/\"\n",
    "                if not os.path.exists(sample_path) :\n",
    "                    os.mkdir(sample_path)\n",
    "\n",
    "                # save image\n",
    "                file_name = \"img_%03d.jpg\" % j\n",
    "                file_path = sample_path + file_name\n",
    "\n",
    "                cv2.imwrite(file_path, img)\n",
    "        self.image_resized = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prepro = Preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prepro.ImageRead()\n",
    "Prepro.RangeTresholding()\n",
    "Prepro.EdgeDetection()\n",
    "Prepro.FindContour()\n",
    "Prepro.FilterContour()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Prepro.CropByContour()\n",
    "Prepro.Resize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prepro.SaveAllImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# 2. Feature Extraction Dataset Tomat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtraction : \n",
    "    def __init__(self, PREPROCESSED_DATASET_FOLDER = \"resized_tomato/\"):\n",
    "        self.labels = []\n",
    "        self.image_list = []\n",
    "        self.statistical_features = []\n",
    "        self.glcm_matrix_list = []\n",
    "        self.color_ch = ['b', 'g', 'r']\n",
    "        self.glcm_feature_list = []\n",
    "        self.texture_feature_labels = ['correlation', 'homogeneity', 'contrast', 'energy']\n",
    "        self.PREPROCESSED_DATASET_FOLDER = PREPROCESSED_DATASET_FOLDER\n",
    "        \n",
    "    def ImageRead(self):\n",
    "        for folder in os.listdir(self.PREPROCESSED_DATASET_FOLDER):\n",
    "            for sample in os.listdir(self.PREPROCESSED_DATASET_FOLDER + folder):\n",
    "                sample_imgs = []\n",
    "                for file in os.listdir(self.PREPROCESSED_DATASET_FOLDER + folder + \"/\" + sample):\n",
    "                    img = cv2.imread(self.PREPROCESSED_DATASET_FOLDER + folder + \"/\" + sample + \"/\" + file)\n",
    "                    sample_imgs.append(img)\n",
    "                self.image_list.append(sample_imgs)\n",
    "                self.labels.append(folder) # append label (name) of image\n",
    "                \n",
    "    def CalcStatisticalFeature(self):\n",
    "        for sample  in self.image_list:\n",
    "            sample_feature = []\n",
    "            for img in sample : \n",
    "                feature_ch = {}\n",
    "                for i in range(len(self.color_ch)):\n",
    "                    feature_ch[self.color_ch[i]] = {\n",
    "                        'mean' : img[:,:,i].mean(),\n",
    "                        'std' : img[:,:,i].std(),\n",
    "                        'skewness' : skew(img[:,:,i].reshape(-1))\n",
    "                    }\n",
    "                sample_feature.append(feature_ch)\n",
    "            self.statistical_features.append(sample_feature)\n",
    "            \n",
    "    def CalcGLCMMatrix(self):\n",
    "        for sample in self.image_list:\n",
    "            sample_matrix = []\n",
    "            for img in sample :\n",
    "                matrix_ch = {}\n",
    "                for i in range(len(self.color_ch)):\n",
    "                    # grab r, g, b channel\n",
    "                    img_ch = img[:,:,i]\n",
    "\n",
    "                    # calculate GLCM \n",
    "                    glcm_img = greycomatrix(img_ch, \n",
    "                                        distances=[1],  # distance 1 pixel\n",
    "                                        angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],  # angel 0, 45, 90, 135 degre\n",
    "                                        levels=256, # number of grey-levels counted in 8 bit grayscale image\n",
    "                                        symmetric=True, \n",
    "                                        normed=True)\n",
    "\n",
    "                    matrix_ch[self.color_ch[i]] = glcm_img\n",
    "                sample_matrix.append(matrix_ch)\n",
    "            self.glcm_matrix_list.append(sample_matrix)\n",
    "            \n",
    "    def CalcGLCMTextureFeature(self):\n",
    "        for sample_matrix in self.glcm_matrix_list:\n",
    "            sample_feature = []\n",
    "            for glcm_matrix in sample_matrix :\n",
    "                feature_ch = {}\n",
    "                for ch in self.color_ch:\n",
    "                    feature_item = {}\n",
    "                    for feature in self.texture_feature_labels:\n",
    "                        out = greycoprops(glcm_matrix[ch], feature)[0]\n",
    "                        feature_item[feature] = out\n",
    "                    feature_ch[ch] = feature_item\n",
    "                sample_feature.append(feature_ch)\n",
    "            self.glcm_feature_list.append(sample_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature = FeatureExtraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature.ImageRead()\n",
    "Feature.CalcStatisticalFeature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature.CalcGLCMMatrix()\n",
    "Feature.CalcGLCMTextureFeature()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# 3. Postprocssing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Postprocessing :\n",
    "    def __init__ (self, statistical_features, glcm_feature_list, labels):\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        self.X_train = []\n",
    "        self.X_test = [] \n",
    "        self.y_train = []\n",
    "        self.y_test = []\n",
    "        self.statistical_features = statistical_features\n",
    "        self.glcm_feature_list = glcm_feature_list\n",
    "        self.original_labels = labels\n",
    "        self.labels = []\n",
    "        self.labels_name = []\n",
    "        self.labels_vec = []\n",
    "        self.test_size = 0.25\n",
    "        \n",
    "        \n",
    "    def transformX(self):\n",
    "        # transform statistical feature to 2D matrix\n",
    "        x1 = []\n",
    "        for sample in self.statistical_features : \n",
    "            for channel in sample :\n",
    "                x = []\n",
    "                for feature in list(channel.values()) :\n",
    "                    data = list(feature.values())\n",
    "                    x.extend(data)\n",
    "                x1.append(x)\n",
    "\n",
    "        # transform GLCM feature to 2D matrix\n",
    "        x2 = []\n",
    "        for sample in self.glcm_feature_list: \n",
    "            for channel in sample :\n",
    "                x = []\n",
    "                for features in list(channel.values()):\n",
    "                    item_feature = []\n",
    "                    for item in list(features.values()) :\n",
    "                        item_feature.extend(item)\n",
    "                    x.extend(item_feature)\n",
    "                x2.append(x)\n",
    "            \n",
    "        # concate 2d Matrix\n",
    "        x1 = np.array(x1).astype(np.float32)\n",
    "        x2 = np.array(x2).astype(np.float32)\n",
    "        self.X = np.concatenate((x1, x2), axis=1)\n",
    "        print(\"X size :\\n\", self.X.shape)\n",
    "        \n",
    "    def generate_labels(self):\n",
    "        for sample, curr_label in zip(self.statistical_features, self.original_labels) : \n",
    "            for channel in sample :\n",
    "                self.labels.append(curr_label)\n",
    "                \n",
    "    def transformY(self):\n",
    "        # generate labels from original labels\n",
    "        self.generate_labels()\n",
    "        \n",
    "        le = LabelEncoder()\n",
    "        le.fit(self.labels)\n",
    "        self.labels_name = le.classes_\n",
    "        print(\"labels_name :\\n\", self.labels_name)\n",
    "        \n",
    "        self.labels_vec = le.transform(self.labels)\n",
    "        self.y = np.array(self.labels_vec).astype(np.float32)\n",
    "        print(\"y size :\\n\", self.y.shape)\n",
    "        \n",
    "    def splitData(self):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "                                    self.X, self.y, test_size=self.test_size, random_state=42)\n",
    "        print(\"Split size :\\n\", self.X_train.shape, self.X_test.shape, self.y_train.shape, self.y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X size :\n",
      " (180, 57)\n",
      "labels_name :\n",
      " ['Tomat Baik' 'Tomat Buruk']\n",
      "y size :\n",
      " (180,)\n",
      "Split size :\n",
      " (135, 57) (45, 57) (135,) (45,)\n"
     ]
    }
   ],
   "source": [
    "Postpro = Postprocessing(Feature.statistical_features, \n",
    "                         Feature.glcm_feature_list, \n",
    "                         Feature.labels)\n",
    "\n",
    "Postpro.transformX()\n",
    "Postpro.transformY()\n",
    "Postpro.splitData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 image/sample x 3 channel x 3 stat feature = 9\n",
    "# 1 image/sample x 3 channel x 4 feature x 4 angel = 48\n",
    "\n",
    "1*3*3 + 4*4*3*1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# 4. Training Model Klasifikasi Tomat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingMLP:\n",
    "    def __init__(self, X_train, y_train, X_test, y_test, labels_vec, labels_name, max_iteartion=200, min_accuracy=0.9):\n",
    "        self.mlp = cv2.ml.ANN_MLP_create()\n",
    "        \n",
    "        input_dim = X_train.shape[1]\n",
    "        network_layer = np.array([input_dim, 128, 1]).astype(np.uint16)\n",
    "        self.mlp.setLayerSizes(network_layer)\n",
    "        self.mlp.setActivationFunction(cv2.ml.ANN_MLP_SIGMOID_SYM)\n",
    "        self.mlp.setTrainMethod(cv2.ml.ANN_MLP_BACKPROP)\n",
    "        \n",
    "        # set term criteria : maximum 100 iteration or stop when achieve 90% accuracy\n",
    "        self.mlp.setTermCriteria((cv2.TERM_CRITERIA_MAX_ITER + cv2.TERM_CRITERIA_EPS, max_iteartion, min_accuracy))\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.labels_vec = labels_vec\n",
    "        self.labels_name = labels_name\n",
    "        \n",
    "        self.model_name = \"klasifikasi_tomat_mlp_model_2.xml\"\n",
    "        \n",
    "    def train(self):\n",
    "        self.mlp.train(self.X_train, cv2.ml.ROW_SAMPLE, self.y_train)\n",
    "        self.mlp.save(self.model_name)\n",
    "        \n",
    "    def validate(self):\n",
    "        self.mlp.load(self.model_name)\n",
    "        y_pred = self.mlp.predict(self.X_test)[1].round().reshape(-1)\n",
    "        \n",
    "        # Compute confusion matrix\n",
    "        cnf_matrix = confusion_matrix(self.y_test, y_pred, labels=np.unique(self.labels_vec))\n",
    "        np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "        # Plot non-normalized confusion matrix\n",
    "        self.plot_confusion_matrix(cnf_matrix, classes=self.labels_name, normalize=False,\n",
    "                              title='Confusion matrix - Klasifikasi Tomat')\n",
    "        \n",
    "        print(classification_report(self.y_test, \n",
    "                                    y_pred, \n",
    "                                    target_names=self.labels_name))\n",
    "        \n",
    "        \n",
    "    def plot_confusion_matrix(self, cm, classes,\n",
    "                              normalize=False,\n",
    "                              title='Confusion matrix',\n",
    "                              cmap=plt.cm.Blues):\n",
    "        if normalize:\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "        plt.figure(figsize=(6, 6))\n",
    "\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "        plt.title(title)\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(classes))\n",
    "        plt.xticks(tick_marks, classes, rotation=45)\n",
    "        plt.yticks(tick_marks, classes)\n",
    "\n",
    "        fmt = '.2f' if normalize else 'd'\n",
    "        thresh = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            plt.text(j, i, format(cm[i, j], fmt),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = TrainingMLP(Postpro.X_train, \n",
    "                      Postpro.y_train, \n",
    "                      Postpro.X_test, \n",
    "                      Postpro.y_test, \n",
    "                      Postpro.labels_vec, \n",
    "                      Postpro.labels_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Tomat Baik       0.74      0.87      0.80        23\n",
      " Tomat Buruk       0.83      0.68      0.75        22\n",
      "\n",
      "    accuracy                           0.78        45\n",
      "   macro avg       0.79      0.78      0.77        45\n",
      "weighted avg       0.79      0.78      0.78        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp_model.train()\n",
    "mlp_model.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:opencv_env]",
   "language": "python",
   "name": "conda-env-opencv_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
